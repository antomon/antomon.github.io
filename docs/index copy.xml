<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Random Bits of Knowledge</title>
<link>https://antomon.github.io/index copy.html</link>
<atom:link href="https://antomon.github.io/index copy.xml" rel="self" type="application/rss+xml"/>
<description>Antonio Montano&#39;s Personal Website</description>
<generator>quarto-1.9.14</generator>
<lastBuildDate>Sat, 19 Apr 2025 22:00:00 GMT</lastBuildDate>
<item>
  <title>Architecting Change</title>
  <dc:creator>Antonio Montano</dc:creator>
  <link>https://antomon.github.io/posts/architecting-change-interim-management/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div class="">
<p><img src="https://antomon.github.io/posts/architecting-change-interim-management/antonio.png" class="img-fluid"></p>
</div></div><section id="prologue" class="level2">
<h2 class="anchored" data-anchor-id="prologue">Prologue</h2>
<p>We are living through one of the most exhilarating moments in the history of technology. Every day, breakthroughs in machine learning, data pipelines, automation, and edge computing redefine the boundaries of what‚Äôs possible.</p>
<p>For me, being an <strong>interim manager</strong> in this landscape is not just a job, it‚Äôs a creative calling, a unique opportunity to shape the future of how businesses operate, grow, and thrive.</p>
<p>I don‚Äôt just help companies ‚Äúgo digital.‚Äù I help them reimagine what they <em>can become</em>. My work is about turning vision into architecture, uncertainty into opportunity, and potential into working systems. I bring together <strong>strategy and execution, architecture and operations, culture and code</strong>.</p>
<p>And in this era, where AI reshapes every domain it touches, I see my role as both <strong>builder and guide</strong>‚Äîsomeone who can sketch the future at the enterprise level and then lead the team that gets us there, step by step, sprint by sprint.</p>
<hr>
</section>
<section id="from-architecture-to-transformation" class="level2">
<h2 class="anchored" data-anchor-id="from-architecture-to-transformation">From architecture to transformation</h2>
<p>Enterprise architecture is often misunderstood as a governance-heavy discipline, focused on documentation and frameworks. For me, architecture is a <strong>compass for transformation</strong>.</p>
<p>It‚Äôs the lens that connects <strong>vision to execution</strong>, ensuring that every decision‚Äîfrom data models to ERP rollout, from cloud adoption to cybersecurity posture‚Äîaligns with strategic intent.</p>
<p>Over the years, I‚Äôve blended <strong>TOGAF, ArchiMate, design thinking, Agile, and DevOps</strong> into what I call <em>adaptive architecture</em>: a practical way to drive clarity and momentum without drowning in methodology.</p>
<ul>
<li><p>Architecture, for me, is not just about artifacts. It‚Äôs about <strong>narratives that create alignment</strong>.</p></li>
<li><p>It‚Äôs not just about current and target states. It‚Äôs about <strong>roadmaps that organizations can walk, even in uncertainty</strong>.</p></li>
<li><p>It‚Äôs not just governance. It‚Äôs <strong>transformation scaffolding</strong>, holding complexity in place until change becomes natural.</p></li>
</ul>
<hr>
</section>
<section id="technology-as-a-strategic-multiplier" class="level2">
<h2 class="anchored" data-anchor-id="technology-as-a-strategic-multiplier">Technology as a strategic multiplier</h2>
<p>I see technology as more than tools, it‚Äôs the <strong>force multiplier of strategy</strong>. My strength lies in helping organizations harness the chaos of technological change and channel it into measurable impact.</p>
<section id="ai-and-machine-learning-beyond-automation" class="level3">
<h3 class="anchored" data-anchor-id="ai-and-machine-learning-beyond-automation">AI and machine learning: beyond automation</h3>
<p>Machine learning is not just about automating tasks‚Äîit‚Äôs about enabling <strong>adaptive enterprises</strong>.<br>
I‚Äôve built ML pipelines that act as <strong>24-hour workforces</strong>: anomaly detection in industrial plants, real-time bid optimization in energy trading, predictive maintenance in manufacturing.</p>
<p>These systems don‚Äôt just save costs; they <strong>reshape operating models</strong>, freeing humans to focus on creativity and strategy.</p>
</section>
<section id="erp-as-orchestration-engines" class="level3">
<h3 class="anchored" data-anchor-id="erp-as-orchestration-engines">ERP as orchestration engines</h3>
<p>Modern ERPs are no longer digital ledgers. When designed properly, they become <strong>collaboration engines</strong>.</p>
<p>I‚Äôve led ERP transformations where Dynamics 365 F&amp;O became the <strong>central orchestrator of value streams</strong>: integrating APS scheduling, MES shop-floor execution, and CRM-driven sales planning.</p>
<p>The result wasn‚Äôt ‚Äúprocess automation‚Äù, it was an organization with a <strong>shared nervous system</strong>, making decisions with speed and confidence.</p>
</section>
<section id="cybersecurity-as-enterprise-trust" class="level3">
<h3 class="anchored" data-anchor-id="cybersecurity-as-enterprise-trust">Cybersecurity as enterprise trust</h3>
<p>In sectors under <strong>NIS2, IEC 62443, and ISO 27001</strong>, I reframed compliance as an opportunity: embedding <strong>secure-by-design architectures</strong> that made cybersecurity a competitive advantage.</p>
<p>In energy storage and water treatment, we turned regulatory burden into a roadmap for resilience, trust, and operational excellence.</p>
</section>
<section id="cloud-native-elastic-by-design" class="level3">
<h3 class="anchored" data-anchor-id="cloud-native-elastic-by-design">Cloud-native, elastic by design</h3>
<p>In fintech and edtech, I architected cloud-native platforms using <strong>serverless patterns, event buses, and CI/CD automation</strong>.</p>
<p>The impact wasn‚Äôt only cost efficiency, it was the ability to <strong>pivot in days</strong>, to launch features in sync with market signals. Technology became the engine of business agility.</p>
</section>
<section id="ma-as-a-catalyst" class="level3">
<h3 class="anchored" data-anchor-id="ma-as-a-catalyst">M&amp;A as a catalyst</h3>
<p>In post-acquisition settings, I‚Äôve guided carve-outs and integrations by mapping <strong>application portfolios, capability models, and data flows</strong>.</p>
<p>What could have been disruptive transitions became opportunities to simplify landscapes, modernize architectures, and establish shared digital foundations.</p>
<hr>
</section>
</section>
<section id="frameworks-and-meta-methods" class="level2">
<h2 class="anchored" data-anchor-id="frameworks-and-meta-methods">Frameworks and meta-methods</h2>
<p>What makes transformation sustainable isn‚Äôt inspiration alone‚Äîit‚Äôs <strong>method, adapted to context</strong>.</p>
<p>Over the years, I‚Äôve built a meta-toolkit of frameworks that I adjust to each environment:</p>
<ul>
<li><p><strong>TOGAF &amp; ArchiMate</strong>: Capability mapping, target operating models, application landscapes. Not bureaucracy, but <strong>decision support tools</strong>.</p></li>
<li><p><strong>Agile &amp; DevOps</strong>: Blending <strong>architecture runway</strong> with <strong>squad delivery models</strong>. Agility without losing governance.</p></li>
<li><p><strong>ITIL &amp; service design</strong>: Stability and resilience baked into change. Crucial for utilities, finance, and regulated industries.</p></li>
<li><p><strong>Design thinking &amp; co-creation</strong>: Co-design with executives, developers, and front-line staff to guarantee adoption.</p></li>
<li><p><strong>Zero Trust &amp; secure-by-design</strong>: Cybersecurity as a native layer of architecture, not an afterthought.</p></li>
</ul>
<p>I don‚Äôt impose dogma, I bring <strong>architectural scaffolding</strong> that allows organizations to accelerate safely.</p>
<hr>
</section>
<section id="case-narratives-transformation-in-action" class="level2">
<h2 class="anchored" data-anchor-id="case-narratives-transformation-in-action">Case narratives: transformation in action</h2>
<ul>
<li><p><strong>Energy &amp; Utilities</strong>: Designed OT/IT convergence architectures for battery storage plants, embedding IEC 62443 compliance, segmented networks, and secure SCADA/ERP integration. Result: regulatory approval <em>and</em> operational trust.</p></li>
<li><p><strong>Manufacturing</strong>: Implemented an ERP + APS + MES stack across multiple sites, enabling variant-driven product masters, real-time scheduling, and intercompany flows. Result: a global supply chain that shifted from reactive to predictive.</p></li>
<li><p><strong>Finance</strong>: Delivered cloud-native, API-first platforms for real-time risk monitoring and fraud detection, integrating AI models directly into transaction pipelines. Result: reduced fraud, increased trust.</p></li>
<li><p><strong>Education</strong>: Built scalable edtech platforms using serverless technologies, capable of handling sudden surges in usage (COVID-era). Result: continuity, growth, and user trust at scale.</p></li>
<li><p><strong>M&amp;A</strong>: Guided IT carve-outs and integrations, using architecture to clarify ‚Äúwhat to keep, what to shed, what to transform.‚Äù Result: accelerated stabilization post-deal and smoother cultural alignment.</p></li>
</ul>
<hr>
</section>
<section id="the-human-side-of-architecture" class="level2">
<h2 class="anchored" data-anchor-id="the-human-side-of-architecture">The human side of architecture</h2>
<p>Technology only succeeds when <strong>people believe in it</strong>.</p>
<p>I enter organizations expecting skepticism, resistance, even fear. These are natural responses to disruption. My role is to <strong>translate ambiguity into clarity</strong>, to <strong>connect emotionally as well as technically</strong>.</p>
<ul>
<li><p>I listen actively, sensing emotional undercurrents.</p></li>
<li><p>I adapt communication across the boardroom and the shop floor.</p></li>
<li><p>I lead with empathy, because trust is the only bridge to adoption.</p></li>
</ul>
<p>The invisible work of transformation is this: helping people move from fear to agency, from inertia to momentum.</p>
<hr>
</section>
<section id="why-interim-management" class="level2">
<h2 class="anchored" data-anchor-id="why-interim-management">Why interim management</h2>
<p>Why step into pressure-cooker environments, where expectations are high and time is short? Because this is where architecture matters most.</p>
<p>In moments of urgency‚ÄîM&amp;A, crisis recovery, regulatory deadlines‚Äîorganizations don‚Äôt need theory. They need someone who can <strong>blend frameworks with pragmatism</strong>, who can <strong>architect change under pressure</strong>.</p>
<p>That‚Äôs what I thrive on: delivering clarity, embedding resilience, and leaving behind not only systems, but <strong>capabilities that endure after I exit</strong>.</p>
<hr>
</section>
<section id="toward-enterprise-orchestration" class="level2">
<h2 class="anchored" data-anchor-id="toward-enterprise-orchestration">Toward enterprise orchestration</h2>
<p>Looking forward, I see enterprises evolving into <strong>continuous orchestration systems</strong>.</p>
<ul>
<li><p>ERPs as <strong>headless orchestrators</strong>, feeding APIs and intelligent agents.</p></li>
<li><p>AI models embedded as <strong>first-class enterprise actors</strong>.</p></li>
<li><p>Cybersecurity frameworks as <strong>trust backbones</strong>, enabling resilient ecosystems.</p></li>
<li><p>Human roles shifting toward <strong>stewardship of value streams</strong>, supported by digital agents.</p></li>
</ul>
<p>This is where I position my work: at the frontier where <strong>architecture, leadership, and emerging technology converge</strong>.</p>
<hr>
</section>
<section id="a-call-to-the-bold" class="level2">
<h2 class="anchored" data-anchor-id="a-call-to-the-bold">A call to the bold</h2>
<p>If you‚Äôre a CEO wondering how to navigate the explosion of digital paradigms, or a headhunter searching for someone who blends <strong>strategic clarity with deep technical execution</strong>, let‚Äôs talk.</p>
<p>I thrive in complexity. I build systems and organizations that scale, adapt, and inspire.</p>
<p>The future isn‚Äôt waiting. Let‚Äôs architect it together.</p>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>enterprise architecture</category>
  <category>interim management</category>
  <category>digital transformation</category>
  <category>üá¨üáß</category>
  <guid>https://antomon.github.io/posts/architecting-change-interim-management/</guid>
  <pubDate>Sat, 19 Apr 2025 22:00:00 GMT</pubDate>
  <media:content url="https://antomon.github.io/posts/architecting-change-interim-management/antonio.png" medium="image" type="image/png" height="216" width="144"/>
</item>
<item>
  <title>Simulating Tethered Buoy Dynamics</title>
  <dc:creator>Antonio Montano</dc:creator>
  <link>https://antomon.github.io/posts/tethered-buoy-dynamics/</link>
  <description><![CDATA[ 





<p>A few days ago, I received a fresh citation notification referencing an article titled <a href="https://arxiv.org/abs/2502.10256">‚ÄúOn the use of an advanced Kirchhoff rod model to study mooring lines‚Äù</a>. That small note sparked a surge of memories from the intense period when I was searching for a stable, accurate way to model a tethered buoy system. It seemed like the perfect moment to revisit a project that, for me, was marked by long stretches of frustration and the pure joy of each breakthrough.</p>
<p>It‚Äôs remarkable how twenty years can deepen one‚Äôs perspective on a project as intricate and rewarding as simulating a tethered buoy system. I initially aimed to model a buoy afloat on the ocean surface, secured by a cable so stiff that it scarcely stretched under large tension. Over the years, I‚Äôve watched that early spark of curiosity evolve into a comprehensive understanding of the theoretical and practical details essential to making it all work. Despite countless hours testing equations, running simulations, and honing algorithms, this endeavor remains among the most gratifying I‚Äôve undertaken.</p>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://antomon.github.io/posts/tethered-buoy-dynamics/On-the-use-of-an-advanced-Kirchhoff-rod-model-to-study-mooring-lines.png" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://antomon.github.io/posts/tethered-buoy-dynamics/citation.png" class="img-fluid"></p>
</div>
</div>
</div>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The challenge</h2>
<p>Mixed finite elements emerged as the linchpin for dealing with a cable of extremely high Young‚Äôs modulus. In a more standard approach, tension might be computed strictly as a derivative of displacement, a method prone to severe numerical instability, especially when the model was pushed close to its inextensible limit. By employing a strategy akin to incompressible fluid simulations, in which pressure is treated separately from velocity, we disentangled tension from displacement. This demanded meticulous algebraic checks, careful boundary condition enforcement, and diverse validation tests. Yet the outcome was a stable formulation capable of handling real-world cable stiffness. It often reminded me of fluid mechanics, where treating pressure as an independent variable helps circumvent the pitfalls of near-incompressibility.</p>
<p>Quaternion-based buoy motion posed a similarly unconventional challenge. Large, abrupt rotations from rough seas or vigorous currents made Euler angles precarious‚Äîone intense swing could trigger numerical lockups or cause the entire orientation model to fail. By turning to quaternions, although less common in many engineering circles at the time, we found a smooth, singularity-free representation of every possible orientation in three-dimensional space. We tested the approach with simulations of tempest-level storms and sharp angle changes to confirm that the buoy‚Äôs motion stayed plausible. Repeatedly, quaternions rose to the occasion, allowing the buoy‚Äôs full rotational dynamics to unfold without numerical breakdown.</p>
<p>Implicit time-stepping formed the final cornerstone of our method. A cable on the brink of inextensibility transmits wave forces at high speeds, rendering an explicit solver prohibitively slow due to the tiny time steps required for stability. We chose a backward Euler scheme, tackling a large-scale, nonlinear system at each time increment. To manage the complexity, we turned to a damped Newton method, iterating on a solution guess while tuning the damping for smooth convergence. Though heavier computationally, this allowed for significantly larger time steps and a practical balance between accuracy and runtime. In numerous experiments, once the Newton iterations converged, the results were physically coherent and free of the instabilities we had feared.</p>
</section>
<section id="the-results" class="level2">
<h2 class="anchored" data-anchor-id="the-results">The results</h2>
<p>Armed with these three pillars, we investigated diverse scenarios, from cables so stiff they bordered on rigid to longer, more flexible lines. We included realistic wave heights, wind speeds, and currents typical of commercial mooring installations. Observing the buoy‚Äôs subtle rocking, dramatic heaving, and swirling rotations underscored how the system responded to external forces. Each validation run comparing our data with known behavior reinforced confidence that we had captured the essential physics.</p>
<p>Even when we dialed stiffness to extremes, the simulation avoided catastrophic instability. Our mixed formulation for cable tension and displacement, coupled with an implicit time stepper, maintained a consistent evolution from step to step. Simultaneously, quaternions let us depict conditions ranging from tranquil seas, with mild buoy bobbing, to rough waters involving severe pitching and rolling. Feedback from industry contacts affirmed that these capabilities opened valuable avenues for mooring design, especially under extreme weather or when safeguarding delicate equipment on the buoy deck. By matching simulations to real-world observations‚Äîlike how far a buoy might drift under heavy seas‚Äîwe significantly bolstered trust in our overall approach.</p>
<p>In the end, the model bridged a gap between purely theoretical inquiry and the concrete engineering tasks that oceanographers, marine engineers, and equipment designers face. Running multi-day or even multi-week simulations without exorbitant computational overhead was an exciting prospect. This was no longer a mere academic puzzle; it was a practical tool likely to inform how mooring lines are specified, built, and managed, whether for scientific stations or navigation beacons in high-traffic waters.</p>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/tethered-buoy-dynamics/Resinex-announcement.png" class="img-fluid figure-img"></p>
<figcaption>Announcement of the partnership between MOX and Resinex based on fluid dynamics modeling software, whose principles were described in the scientific article on computational fluid dynamics</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/tethered-buoy-dynamics/resinex-buoy.jpg" class="img-fluid figure-img"></p>
<figcaption>An oceanic buoy manufactured by Resinex</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>This project also unified my engineering approach to physics and mathematics in a problem that originated from a company that, to this day, continues to produce buoys. The challenge wasn‚Äôt just academic; it was a real-world issue that required scientific rigor to solve. The culmination of our work was published in <strong>Computer Methods in Applied Mechanics and Engineering</strong> under the title <strong><a href="https://doi.org/10.1016/j.cma.2007.04.012">Modeling and Numerical Simulation of Tethered Buoy Dynamics</a></strong>, co-authored with Marco Restelli and Riccardo Sacco. The publication validated our approach and demonstrated that tackling practical engineering problems with strong theoretical foundations could yield robust and widely applicable solutions.</p>
<div class="quarto-layout-panel" data-layout-ncol="1">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/tethered-buoy-dynamics/Numerical-simulation-of-tethered-buoy-dynamics.png" class="img-fluid figure-img"></p>
<figcaption>First page of the peer-reviewed article</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="looking-back" class="level2">
<h2 class="anchored" data-anchor-id="looking-back">Looking back</h2>
<p>Reflecting on this project, I‚Äôm amazed at the breadth of expertise required. We merged advanced finite element theories, wave force modeling, buoy geometry, and fluid‚Äìstructure interaction, all in a single system. Yes, we faced frustrating snags‚Äîbug hunts that stretched late into the night or solver conflicts that cropped up unexpectedly‚Äîbut each resolution felt like a tangible stride toward a robust, trustworthy model.</p>
<p>The satisfaction stands out most vividly. Every instance of pushing the model‚Äîtesting bigger waves, trickier cables, or new geometric nuances‚Äîbrought the thrill of seeing it hold firm. The mathematics we‚Äôd nurtured for so long manifested as on-screen visualizations of swirling seawater, with a buoy steadily riding the crests and troughs. It was then that I realized we had transcended theoretical musings, delivering a resource for engineers, researchers, and maritime professionals alike.</p>
<p>Two decades on, I still regard it as a testament to collaboration, persistence, and solid mathematical foundations. Tackling problems of this scope often demands stepping beyond familiar territory, whether by redefining tension as a separate unknown or adopting quaternions for orientation. My hope is that others may glean encouragement from our experiences, confident that even though the road is strewn with roadblocks and late-night coding trials, a thoroughly validated, widely beneficial system makes it all worthwhile.</p>
<p>I should also underline how indispensable the MOX environment at Politecnico di Milano was. The department teemed with resourceful researchers who offered both theoretical knowledge and practical engineering insight. They possessed a rare knack for fusing advanced mathematical techniques with real-world requirements, their open-minded spirit inspiring each brainstorming session. Working there meant a stream of fresh ideas, incisive critiques, and the kind of camaraderie that keeps tough projects alive.</p>
<p>To this day, nothing pleases me more than receiving word of a fresh citation or reference to our work. Each new mention affirms that the methods we pieced together continue to serve those who grapple with similarly challenging scenarios. That ongoing relevance speaks volumes about the enduring value of thorough research, well beyond the date of publication.</p>
<p>You can download a preprint <a href="https://mox.polimi.it/reports-and-books/publication-results/?id=77">here</a>.</p>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>mathematical modeling</category>
  <category>personal</category>
  <category>science</category>
  <category>üá¨üáß</category>
  <guid>https://antomon.github.io/posts/tethered-buoy-dynamics/</guid>
  <pubDate>Wed, 19 Feb 2025 23:00:00 GMT</pubDate>
  <media:content url="https://antomon.github.io/posts/tethered-buoy-dynamics/Numerical-simulation-of-tethered-buoy-dynamics.png" medium="image" type="image/png" height="203" width="144"/>
</item>
<item>
  <title>GPT-4 Anniversary</title>
  <dc:creator>Antonio Montano</dc:creator>
  <link>https://antomon.github.io/posts/gpt-4-anniversary/</link>
  <description><![CDATA[ 





<section id="it-feels-like-a-lifetime-but-its-only-been-a-year" class="level2">
<h2 class="anchored" data-anchor-id="it-feels-like-a-lifetime-but-its-only-been-a-year">It feels like a lifetime, but it‚Äôs only been a year!</h2>
<p>March 2023 marked a turning point in the field of artificial intelligence with the release of <a href="https://openai.com/research/gpt-4">OpenAI‚Äôs GPT-4</a>. This powerful language model, boasting significant advancements over its predecessors, sent shockwaves through various industries and ignited discussions about the future of human-machine interaction. One year later, it‚Äôs clear that GPT-4‚Äôs impact has been wide-ranging and continues to evolve.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/gpt-4-anniversary/sama tweet.png" class="img-fluid figure-img" alt="Sam Altman tweet"></p>
<figcaption>Sam Altman tweet</figcaption>
</figure>
</div>
<p>One of the most notable effects has been the acceleration of AI acceptance. GPT-4‚Äôs ability to perform exceptionally on standardized tests, generate human-quality writing, and integrate seamlessly with multimodal data like images and sound, has fostered a sense of legitimacy for large language models. This has emboldened researchers and businesses to explore AI applications with greater confidence.</p>
<p>In the course of evaluating the competencies of GPT-4, OpenAI subjected the model to a series of standardized academic and professional examinations, including the Uniform Bar Exam, the Law School Admission Test (LSAT), the Graduate Record Examination (GRE) Quantitative section, and assorted Advanced Placement (AP) subject tests. GPT-4 demonstrated proficiency across numerous assessments, achieving scores comparable to those of human test-takers. This implies that, were GPT-4 to be evaluated purely on its capacity to perform on these tests, it would possess the qualifications to gain admission into law schools and a broad range of universities.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/gpt-4-anniversary/gpt-4 exams.png" class="img-fluid figure-img" alt="GPT-4 exams results from the March 2023 announcement"></p>
<figcaption>GPT-4 exams results from the March 2023 announcement</figcaption>
</figure>
</div>
<p>Prior LLMs often struggled with tasks requiring an understanding of context spread across long stretches of text. With a context windows from 8k to 32k tokens, GPT-4 was able to analyze a much larger chunk of text, allowing it to grasp complex relationships between ideas and follow long-range dependencies.</p>
<p>On September 25th, 2023, OpenAI <a href="https://openai.com/research/gpt-4v-system-card">announced</a> the rollout of two new features that extend how people can interact with its recent and most advanced model, GPT-4: the ability to ask questions about images and to use speech as an input to a query. Then, on November 6th, 2023, OpenAI announced API access to GPT-4 with Vision. This functionality marked GPT-4‚Äôs move into being a multimodal model. This means that the model can accept multiple ‚Äúmodalities‚Äù of input ‚Äì text and images ‚Äì and return results based on those inputs.</p>
<p>After a year, GPT-4 remains one of the most advanced LLMs, even though the competition is fierce and with formidable opponents. If the rumors are confirmed, in the coming months we will have an even more powerful version that will continue to amaze us, just like the previous ones.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/gpt-4-anniversary/murati-1y.png" class="img-fluid figure-img" alt="Mira Murati one-year anniversary celebration tweet"></p>
<figcaption>Mira Murati one-year anniversary celebration tweet</figcaption>
</figure>
</div>
</section>
<section id="outstanding-achievements" class="level2">
<h2 class="anchored" data-anchor-id="outstanding-achievements">Outstanding achievements</h2>
<section id="the-turing-test" class="level3">
<h3 class="anchored" data-anchor-id="the-turing-test">The Turing Test</h3>
<section id="what-is-about" class="level4">
<h4 class="anchored" data-anchor-id="what-is-about">What is about</h4>
<p>The Turing Test, introduced by British mathematician and computer scientist Alan Turing in 1950, is a benchmark for evaluating a machine‚Äôs ability to exhibit intelligent behavior indistinguishable from that of a human. In his seminal paper, ‚ÄúComputing Machinery and Intelligence,‚Äù Turing proposed the question, ‚ÄúCan machines think?‚Äù and introduced the concept of the ‚Äúimitation game‚Äù as a criterion for machine intelligence. The test involves a human judge engaging in natural language conversations with both a machine and a human without seeing them. If the judge cannot reliably tell the machine from the human, the machine is said to have passed the Turing Test. This test has become a fundamental concept in the philosophy of artificial intelligence, sparking debates about the nature of intelligence and the potential of machines to emulate human-like consciousness and reasoning.</p>
<p>The Turing Test‚Äôs significance lies in its simplicity and profound implications. It provides a straightforward criterion for intelligence that does not rely on the machine‚Äôs ability to replicate the human brain‚Äôs workings but rather on the outcome of its interactions. Passing the Turing Test is considered a milestone for AI, suggesting that the machine can replicate human-like responses under certain conditions, thereby challenging the distinctions between human and machine intelligence.</p>
</section>
<section id="ocean-big-5" class="level4">
<h4 class="anchored" data-anchor-id="ocean-big-5">OCEAN Big-5</h4>
<p>Expanding on the OCEAN Big-5, also known as the Big Five personality traits, it‚Äôs a model based on common language descriptors of personality. These traits represent broad dimensions of human personality and include:</p>
<ol type="1">
<li><p><strong>Openness to experience</strong>: Characterized by imagination, creativity, and a willingness to try new things. High openness indicates a person who enjoys novelty, variety, and intellectual pursuits. Lower openness may suggest a more conventional and practical orientation.</p></li>
<li><p><strong>Conscientiousness</strong>: Involves self-discipline, orderliness, and a drive for achievement. Highly conscientious individuals are organized and responsible, often with a strong work ethic. Lower scores may indicate a more relaxed or spontaneous approach to life.</p></li>
<li><p><strong>Extraversion</strong>: Denotes sociability, excitement-seeking, and positive emotions. Extroverts are typically energetic and enjoy being around other people, while introverts (lower extraversion) may prefer solitude and more subdued environments.</p></li>
<li><p><strong>Agreeableness</strong>: Reflects a person‚Äôs altruistic, cooperative, and compassionate nature. High agreeableness is associated with trust and helpfulness, whereas lower agreeableness may manifest as skepticism or competitive behavior.</p></li>
<li><p><strong>Neuroticism</strong>: Pertains to emotional stability and the tendency to experience negative emotions. Higher neuroticism scores indicate a greater likelihood of feeling anxious, depressed, or angry, while lower scores suggest a calmer and more resilient disposition.</p></li>
</ol>
<p>These traits provide a framework for understanding human personality and predicting a wide range of behaviors, from academic and occupational success to relationships and well-being. In the context of AI, applying the OCEAN Big-5 to evaluate chatbots like ChatGPT allows researchers to assess how closely these systems mimic human personality traits, contributing to the ongoing exploration of machine ‚Äúpersonality‚Äù and its implications for human-AI interaction.</p>
</section>
<section id="the-research-from-jackson-et-al." class="level4">
<h4 class="anchored" data-anchor-id="the-research-from-jackson-et-al.">The Research from Jackson et al.</h4>
<p>A research consortium led by Matthew Jackson, who holds the William D. Eberle Professorship of Economics within Stanford University‚Äôs School of Humanities and Sciences, conducted an empirical analysis of the behavioral and personality attributes of the AI-driven entities within ChatGPT, employing methodologies derived from psychology and behavioral economics. Their findings, documented in the paper <a href="https://www.pnas.org/doi/10.1073/pnas.2313925121">A Turing test of whether AI chatbots are behaviorally similar to humans</a> published in the Proceedings of the National Academy of Sciences, demonstrated that ChatGPT 4, exhibited indistinguishability from human participants in behavioral assessments. Notably, when the AI opted for atypical human behavioral patterns, it manifested increased levels of cooperativeness and altruism.</p>
<p>This investigative endeavor subjected versions 3 and 4 of ChatGPT to a prevalent personality assessment alongside a series of behavioral experiments designed to forecast socio-economic and ethical decision-making tendencies. These experiments encompassed standardized scenarios that required participants to make choices on dilemmas such as betraying a complicit criminal or allocating monetary resources under various incentive structures. The AI responses were benchmarked against a dataset comprising over 100,000 human participants spanning 50 nations.</p>
<p>Within the OCEAN Big-5, ChatGPT version 4 aligned with the normal human range for these traits but ranked in the lower third percentile in terms of agreeableness compared to the human sample. Despite passing the Turing Test, this level of agreeableness suggests limited social appeal.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/gpt-4-anniversary/pnas.2313925121fig01.jpg" class="img-fluid figure-img" width="600"></p>
<figcaption>‚ÄúBig Five‚Äù personality profiles of ChatGPT-4 and ChatGPT-3 compared with the distributions of human subjects. The blue, orange, and green lines correspond to the median scores of humans, ChatGPT-4, and ChatGPT-3 respectively; the shaded areas represent the middle 95% of the scores, across each of the dimensions. ChatGPT‚Äôs personality profiles are within the range of the human distribution, even though ChatGPT-3 scored noticeably lower in Openness.</figcaption>
</figure>
</div>
<p>Comparative analysis between versions 3 and 4 revealed significant advancements in the latter‚Äôs performance, with version 3 displaying agreeableness and openness to experience at the lower end of the human spectrum, indicative of a lesser capacity for novel ideas and experiences.</p>
<p>The methodology for assessing AI behavior in the experimental games involved calculating the frequency of specific actions (e.g., equitable distribution of funds) among both human participants and the AI. Subsequently, the researchers compared a randomly selected human action to one from the AI sessions to ascertain the likelihood of human origin. In the majority of these exercises, actions taken by version 4 were more consistently aligned with human behavior than those of version 3, which did not meet the Turing Test criteria.</p>
</section>
</section>
<section id="impact-on-work" class="level3">
<h3 class="anchored" data-anchor-id="impact-on-work">Impact on Work</h3>
<p>The study <a href="https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf">Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality</a> by Dell‚ÄôAcqua et al.&nbsp;explores the impact of artificial intelligence (AI), specifically Large Language Models (LLMs) like GPT-4, on the productivity and quality of work among knowledge workers at Boston Consulting Group (BCG). This comprehensive experiment involved 758 consultants and aimed to understand how AI affects complex, knowledge-intensive tasks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/gpt-4-anniversary/Distribution-output-quality.png" class="img-fluid figure-img" alt="Distribution of output quality across all the tasks" width="900"></p>
<figcaption>Distribution of output quality across all the tasks. The blue group did not use AI, the green and red groups used AI, the red group got some additional training on how to use AI</figcaption>
</figure>
</div>
<p>The study introduces the concept of a ‚Äújagged technological frontier,‚Äù suggesting that AI capabilities are uneven across different tasks. Some tasks are significantly enhanced by AI, leading to improved productivity and quality, while others, seemingly similar in difficulty, lie outside AI‚Äôs current capabilities and can lead to decreased performance when AI is utilized.</p>
<p>Participants were divided into three groups: a control group with no AI access, a group with access to GPT-4, and a group with GPT-4 access plus a prompt engineering overview. The findings revealed that for tasks within AI‚Äôs capabilities, the use of AI led to a notable increase in both the quantity and quality of work. Consultants were able to complete more tasks and with better outcomes, demonstrating that AI can be a powerful tool for augmenting human capabilities in knowledge work.</p>
<p>However, for tasks selected to be outside the AI‚Äôs frontier, reliance on AI resulted in a decrease in performance. This highlights the importance of understanding AI‚Äôs limitations and suggests that indiscriminate use of AI can have negative consequences.</p>
<p>The study also observed two distinct patterns of AI integration among successful users: ‚ÄúCentaurs,‚Äù who strategically divided tasks between themselves and AI, and ‚ÄúCyborgs,‚Äù who integrated AI more fully into their workflow. These findings suggest varying approaches to integrating AI into professional tasks, emphasizing the need for users to adapt their strategies based on the task at hand and AI‚Äôs capabilities.</p>
<p>In summary, the study provides empirical evidence on the dual role of AI in enhancing and sometimes detracting from professional knowledge work. It highlights the need for careful consideration of when and how to deploy AI tools, as well as the potential for AI to significantly impact work processes and outcomes within its capabilities. The concept of the jagged technological frontier offers a framework for understanding the complex and evolving relationship between AI and human work, underscoring the importance of navigating this frontier effectively to harness the benefits of AI while mitigating its risks.</p>
</section>
</section>
<section id="march-2024-landscape" class="level2">
<h2 class="anchored" data-anchor-id="march-2024-landscape">March 2024 landscape</h2>
<section id="openai-current-offering" class="level3">
<h3 class="anchored" data-anchor-id="openai-current-offering">OpenAI current offering</h3>
<p>GPT-4 is available in the OpenAI API to <a href="https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4">paying customers</a>. Like <strong><code>gpt-3.5-turbo</code></strong>, GPT-4 is optimized for chat but works well for traditional completions tasks using the <a href="https://platform.openai.com/docs/api-reference/chat">Chat Completions API</a>. Learn how to use GPT-4 in our <a href="https://platform.openai.com/docs/guides/text-generation">text generation guide</a>.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;"><strong>MODEL</strong></th>
<th style="text-align: left;"><strong>DESCRIPTION</strong></th>
<th style="text-align: left;"><strong>CONTEXT WINDOW</strong></th>
<th style="text-align: left;"><strong>TRAINING DATA</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">gpt-4-0125-preview</td>
<td style="text-align: left;"><strong>GPT-4 Turbo</strong><br>
The latest GPT-4 model intended to reduce cases of ‚Äúlaziness‚Äù where the model doesn‚Äôt complete a task. Returns a maximum of 4,096 output tokens. <a href="https://openai.com/blog/new-embedding-models-and-api-updates">Learn more</a>.</td>
<td style="text-align: left;">128,000 tokens</td>
<td style="text-align: left;">Up to Dec 2023</td>
</tr>
<tr class="even">
<td style="text-align: left;">gpt-4-turbo-preview</td>
<td style="text-align: left;">Currently points to <code>gpt-4-0125-preview</code>.</td>
<td style="text-align: left;">128,000 tokens</td>
<td style="text-align: left;">Up to Dec 2023</td>
</tr>
<tr class="odd">
<td style="text-align: left;">gpt-4-1106-preview</td>
<td style="text-align: left;">GPT-4 Turbo model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Returns a maximum of 4,096 output tokens. This is a preview model. <a href="https://openai.com/blog/new-models-and-developer-products-announced-at-devday">Learn more</a>.</td>
<td style="text-align: left;">128,000 tokens</td>
<td style="text-align: left;">Up to Apr 2023</td>
</tr>
<tr class="even">
<td style="text-align: left;">gpt-4-vision-preview</td>
<td style="text-align: left;">GPT-4 with the ability to understand images, in addition to all other GPT-4 Turbo capabilities. Currently points to <code>gpt-4-1106-vision-preview</code>.</td>
<td style="text-align: left;">128,000 tokens</td>
<td style="text-align: left;">Up to Apr 2023</td>
</tr>
<tr class="odd">
<td style="text-align: left;">gpt-4-1106-vision-preview</td>
<td style="text-align: left;">GPT-4 with the ability to understand images, in addition to all other GPT-4 Turbo capabilities. Returns a maximum of 4,096 output tokens. This is a preview model version. <a href="https://openai.com/blog/new-models-and-developer-products-announced-at-devday">Learn more</a>.</td>
<td style="text-align: left;">128,000 tokens</td>
<td style="text-align: left;">Up to Apr 2023</td>
</tr>
<tr class="even">
<td style="text-align: left;">gpt-4</td>
<td style="text-align: left;">Currently points to <code>gpt-4-0613</code>. See <a href="https://platform.openai.com/docs/models/continuous-model-upgrades">continuous model upgrades</a>.</td>
<td style="text-align: left;">8,192 tokens</td>
<td style="text-align: left;">Up to Sep 2021</td>
</tr>
<tr class="odd">
<td style="text-align: left;">gpt-4-0613</td>
<td style="text-align: left;">Snapshot of <code>gpt-4</code> from June 13th 2023 with improved function calling support.</td>
<td style="text-align: left;">8,192 tokens</td>
<td style="text-align: left;">Up to Sep 2021</td>
</tr>
<tr class="even">
<td style="text-align: left;">gpt-4-32k</td>
<td style="text-align: left;">Currently points to <code>gpt-4-32k-0613</code>. See <a href="https://platform.openai.com/docs/models/continuous-model-upgrades">continuous model upgrades</a>. This model was never rolled out widely in favor of GPT-4 Turbo.</td>
<td style="text-align: left;">32,768 tokens</td>
<td style="text-align: left;">Up to Sep 2021</td>
</tr>
<tr class="odd">
<td style="text-align: left;">gpt-4-32k-0613</td>
<td style="text-align: left;">Snapshot of <code>gpt-4-32k</code> from June 13th 2023 with improved function calling support. This model was never rolled out widely in favor of GPT-4 Turbo.</td>
<td style="text-align: left;">32,768 tokens</td>
<td style="text-align: left;">Up to Sep 2021</td>
</tr>
</tbody>
</table>
</section>
<section id="openai-pricing" class="level3">
<h3 class="anchored" data-anchor-id="openai-pricing">OpenAI pricing</h3>
<section id="gpt-4-turbo" class="level4">
<h4 class="anchored" data-anchor-id="gpt-4-turbo"><strong>GPT-4 Turbo</strong></h4>
<table class="caption-top table">
<colgroup>
<col style="width: 38%">
<col style="width: 30%">
<col style="width: 30%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Model</strong></td>
<td><strong>Input</strong></td>
<td><strong>Output</strong></td>
</tr>
<tr class="even">
<td>gpt-4-0125-preview</td>
<td>$10.00&nbsp;/ 1M tokens</td>
<td>$30.00&nbsp;/ 1M tokens</td>
</tr>
<tr class="odd">
<td>gpt-4-1106-preview</td>
<td>$10.00&nbsp;/ 1M tokens</td>
<td>$30.00&nbsp;/ 1M tokens</td>
</tr>
<tr class="even">
<td>gpt-4-1106-vision-preview</td>
<td>$10.00&nbsp;/ 1M tokens</td>
<td>$30.00&nbsp;/ 1M tokens</td>
</tr>
</tbody>
</table>
</section>
<section id="gpt-4" class="level4">
<h4 class="anchored" data-anchor-id="gpt-4"><strong>GPT-4</strong></h4>
<table class="caption-top table">
<tbody>
<tr class="odd">
<td><strong>Model</strong></td>
<td><strong>Input</strong></td>
<td><strong>Output</strong></td>
</tr>
<tr class="even">
<td>gpt-4</td>
<td>$30.00&nbsp;/ 1M tokens</td>
<td>$60.00&nbsp;/ 1M tokens</td>
</tr>
<tr class="odd">
<td>gpt-4-32k</td>
<td>$60.00&nbsp;/ 1M tokens</td>
<td>$120.00&nbsp;/ 1M tokens</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="competitors" class="level3">
<h3 class="anchored" data-anchor-id="competitors">Competitors</h3>
<p>Now in 2024, there is a fierce competition from Anthropic, Cohere, Google, and others.</p>
<section id="anthropic" class="level4">
<h4 class="anchored" data-anchor-id="anthropic">Anthropic</h4>
<p><a href="https://www.anthropic.com/news/claude-3-family" title="Claude 3">Claude 3</a> family of models employ various training methods, such as unsupervised learning and <a href="https://arxiv.org/abs/2212.08073" title="Constitutional AI">Constitutional AI</a>. A key enhancement in the Claude 3 family is multimodal input capabilities with text output, allowing users to upload images (e.g., tables, graphs, photos) along with text prompts for richer context and expanded use cases.</p>
<p>Opus, the most powerful model from Anthropic, outperforms GPT-4, GPT-3.5 and Gemini Ultra on a wide range of benchmarks. This includes topping the leaderboard on academic benchmarks like GSM-8k for mathematical reasoning and MMLU for expert-level knowledge.</p>
<p>Sonnet, the mid-range model, offers businesses a more cost-effective solution for routine data analysis and knowledge work, maintaining high performance without the premium price tag of the flagship model. Meanwhile, Haiku is designed to be swift and economical, suited for applications such as consumer-facing chatbots, where responsiveness and cost are crucial factors.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/gpt-4-anniversary/claude-comparison.webp" class="img-fluid figure-img" alt="Comparison of the Claude 3 with leading models" width="900"></p>
<figcaption>Comparison of the Claude 3 with leading models from the Anthropic announcement</figcaption>
</figure>
</div>
<p>In addition, Claude 3 models demonstrate sophisticated computer vision abilities on par with other state-of-the-art models. This new modality opens up use cases where enterprises need to extract information from images, documents, charts and diagrams.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/gpt-4-anniversary/claude-comparison-vision.webp" class="img-fluid figure-img" width="900"></p>
<figcaption>Comparison of the Claude 3 vision capabilities with leading models from the Anthropic announcement</figcaption>
</figure>
</div>
</section>
<section id="cohere" class="level4">
<h4 class="anchored" data-anchor-id="cohere">Cohere</h4>
<p>While OpenAI has garnered widespread attention through the viral phenomenon of its ChatGPT chatbot, Cohere has adopted a more focused strategy, engaging directly with corporate clients to customize its AI models according to their unique requirements. This approach enables Cohere to achieve greater cost efficiency compared to competitors who aim at broad consumer markets.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 32%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Cohere API Pricing</strong></th>
<th style="text-align: left;"><strong>$ / M input tokens</strong></th>
<th style="text-align: left;"><strong>$ / M output tokens</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Command</td>
<td style="text-align: left;">$1.00</td>
<td style="text-align: left;">$2.00</td>
</tr>
<tr class="even">
<td style="text-align: left;">Command-R</td>
<td style="text-align: left;">$0.50</td>
<td style="text-align: left;">$1.50</td>
</tr>
</tbody>
</table>
<p><a href="https://txt.cohere.com/command-r/?_gl=1*1ckv15z*_ga*MTk1NTk5MTAyLjE3MDg5NzkzNzE.*_ga_CRGS116RZS*MTcxMDY3MTUwNC4zLjEuMTcxMDY3MjI0MC4zMS4wLjA." title="Command-R">Command-R</a> integrates seamlessly with Cohere‚Äôs Embed and Rerank models, providing retrieval-augmented generation (RAG) functionalities. A distinctive feature of Command-R is its ability to provide explicit citations in its outputs, reducing the occurrence of fabrications and facilitating user access to further information from the original sources.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/gpt-4-anniversary/Multilingual-Evals--1--1.png" class="img-fluid figure-img" alt="Multilingual MMLU from Cohere announcement" width="700"></p>
<figcaption>Multilingual MMLU from Cohere announcement</figcaption>
</figure>
</div>
<p>The capability of Command-R to utilize external tools marks a significant advancement for developers in the corporate sector. This feature permits the model to link with external resources such as search engines, APIs, databases, and functions, thereby enriching its functionality through the utilization of data and operations available via these tools. This aspect is especially beneficial for businesses that store a substantial portion of their data in external repositories.</p>
<p>The adoption of tool usage opens the door to a broad spectrum of new applications. For example, developers can instruct Command-R to suggest a specific tool or a combination thereof, along with guidance on their usage. This enables chatbots to interact with customer relationship management (CRM) systems to update deal statuses or to employ Python interpreters for performing data science tasks. Additionally, it allows for the transformation of user inquiries into search commands for vector databases or search engines, empowering work assistants to autonomously navigate through various databases and platforms to gather pertinent information or execute comparative evaluations.</p>
<p>Tool usage with Command-R involves a four-stage process: initially, developers configure which tools the model can access and the format of interactions (e.g., API calls, JSON-formatted instructions). Command-R then judiciously selects the suitable tools and parameters for these interactions. Subsequently, developers execute these tool interactions, obtaining results, which are then fed back into Command-R to generate the final response.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/gpt-4-anniversary/cohere-tool-use.png" class="img-fluid figure-img" alt="Cohere tool usage" width="900"></p>
<figcaption>Cohere tool usage</figcaption>
</figure>
</div>
<p>Beyond its RAG and tool integration features, Command-R benefits from an extended context window capability of up to 128k tokens and offers competitive pricing for Cohere‚Äôs hosted API service. Moreover, the model delivers robust performance across ten primary languages, encompassing English, French, Spanish, Italian, German, Portuguese, Japanese, Korean, Arabic, and Chinese.</p>
</section>
</section>
</section>
<section id="lets-celebrate" class="level2">
<h2 class="anchored" data-anchor-id="lets-celebrate">Let‚Äôs Celebrate!</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/gpt-4-anniversary/1-year-image-prompt.png" class="img-fluid figure-img" alt="ChatGPT self-portrait"></p>
<figcaption>ChatGPT self-portrait</figcaption>
</figure>
</div>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>generative ai</category>
  <category>machine learning</category>
  <category>üá¨üáß</category>
  <guid>https://antomon.github.io/posts/gpt-4-anniversary/</guid>
  <pubDate>Thu, 14 Mar 2024 23:00:00 GMT</pubDate>
  <media:content url="https://antomon.github.io/posts/gpt-4-anniversary/1-year-image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Intervento al DABS Day 2024 - Universit√† Ca‚Äô Foscari</title>
  <dc:creator>Antonio Montano</dc:creator>
  <link>https://antomon.github.io/posts/intervento-dabs-day-2024-ca-foscari/</link>
  <description><![CDATA[ 





<section id="genai-a-venezia" class="level2">
<h2 class="anchored" data-anchor-id="genai-a-venezia">GenAI a Venezia</h2>
<p>Bel pomeriggio presso l‚ÄôUniversit√† Ca‚Äô Foscari di Venezia, ospite del Dipartimento di Economia e dell‚Äôevento DABS Day 2024.</p>
<p>Coll‚Äôintervento di apertura dell‚Äôevento, ho portato una serie di spunti sulla intelligenza artificiale generativa, utili al confronto con i ragazzi, gli altri ospiti e il corpo docente.</p>
<p>Il talk √® stato organizzato in 4 sezioni:</p>
<ol type="1">
<li><p>Il contesto: Aspettative tra alti e bassi. Un breve excursus storico per arrivare alla rivouluzione del deep learning e dei transformer.</p></li>
<li><p>Le promesse: sar√† un estate perenne? La principale promessa della fase storica corrente e cio√® la polivalenza dei nuovi modelli di reti neurali generative.</p></li>
<li><p>Le sfide: grandi guadagni, grandi rischi. La rivoluzione della IA generativa porta con s√© molte sfide, tutte proporzionali alle promesse e alle aspettative suscitate.</p></li>
<li><p>Il futuro: IA importante come fuoco per l‚Äôumanit√†. Difficile trovare una metafora per definire l‚Äôimpatto della IA generativa sull‚Äôumanit√†, ma il fuoco sembra essere la migliore per il CEO di Alphabet (vedi anche mio altro <a href="https://antomon.github.io/posts/ai-important-as-fire/">post</a> sul tema). Quindi, rivolgo uno sguardo alle rivoluzioni tecnologiche precedenti e riporto alcune raccomandazioni per il presente e il futuro prossimo.</p></li>
</ol>
<p>Si possono scaricare le slide in formato <a href="https://github.com/antomon/antomon.github.io/blob/ab2afdffdaa015f1dad52fc0a1de3dd7cc171b35/posts/intervento-dabs-day-2024-ca-foscari/GENAI-TALK-20240311-FULL.pptx" title="PPTX">PPTX</a> (Powerpoint). Presentano delle animazioni, quindi devono essere fruite nella modalit√† di esecuzione di Powerpoint.</p>
<p>Contattami per:</p>
<ol type="1">
<li><p>Stato e trend della GenAI.</p></li>
<li><p>Applicazioni aziendali della GenAI.</p></li>
<li><p>Selezione di strumenti e creazione di team per l‚Äôintroduzione e sfruttamento della GenAI.</p></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/intervento-dabs-day-2024-ca-foscari/brochure.png" class="img-fluid figure-img" alt="Brochure DABS Day"></p>
<figcaption>Brochure DABS Day</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/intervento-dabs-day-2024-ca-foscari/start.png" class="img-fluid figure-img" alt="Si inizia!"></p>
<figcaption>Si inizia!</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://antomon.github.io/posts/intervento-dabs-day-2024-ca-foscari/aspettative.jpg" class="img-fluid figure-img" alt="Le montagne russe delle aspettative della IA!"></p>
<figcaption>Le montagne russe delle aspettative della IA!</figcaption>
</figure>
</div>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>generative ai</category>
  <category>machine learning</category>
  <category>talk</category>
  <category>üáÆüáπ</category>
  <guid>https://antomon.github.io/posts/intervento-dabs-day-2024-ca-foscari/</guid>
  <pubDate>Wed, 13 Mar 2024 23:00:00 GMT</pubDate>
  <media:content url="https://antomon.github.io/posts/intervento-dabs-day-2024-ca-foscari/sangiobbe2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Controllo delle Partite IVA in Excel Tramite il Servizio VIES</title>
  <dc:creator>Antonio Montano</dc:creator>
  <link>https://antomon.github.io/posts/controllo-piva-vies-api/</link>
  <description><![CDATA[ 





<section id="introduzione" class="level2">
<h2 class="anchored" data-anchor-id="introduzione">Introduzione</h2>
<p>Un cliente aveva qualche migliaia di Partite IVA europee da controllare e la sindrome del buon samaritano mi ha costretto a spolverare il VBA per poter sfruttare lo strumento client pi√π amato nelle aziende: Excel!</p>
<p>Questa guida, pertanto, ti mostra come utilizzare un file Excel per controllare la validit√† delle Partite IVA tramite il servizio <a href="https://ec.europa.eu/taxation_customs/vies/#/vat-validation"><strong>VIES</strong></a> (VAT Information Exchange System).</p>
<p>Il post √® diviso in due parti: la prima √® pensata per gli utenti che non hanno esperienza di programmazione, ma hanno un minimo di conoscenza di Excel e la seconda √® per chi ha conoscenze di base in <strong>VBA</strong> e vuole modificare o personalizzare il file Excel o il codice.</p>
</section>
<section id="come-utilizzare-il-file-excel" class="level2">
<h2 class="anchored" data-anchor-id="come-utilizzare-il-file-excel">Come utilizzare il file Excel</h2>
<p>Questa sezione √® per chi vuole semplicemente utilizzare il foglio Excel gi√† predisposto per controllare le Partite IVA senza la necessit√† di modificare il codice.</p>
<section id="esecuzione-del-controllo" class="level3">
<h3 class="anchored" data-anchor-id="esecuzione-del-controllo">Esecuzione del controllo</h3>
<p>Passaggi per eseguire il controllo delle Partite IVA:</p>
<ol type="1">
<li><p><strong>Apri il file Excel</strong>: Assicurati di scaricare e aprire il file <a href="CONTROLLO-PARTITE-IVA-CON-VIES.xlsm">Excel</a>.</p></li>
<li><p><strong>Inserisci i dati delle Partite IVA</strong>:</p>
<ul>
<li><p>Vai al foglio specificato nella cella <strong>B3</strong> del foglio <strong>CONFIGURAZIONE</strong>.</p></li>
<li><p>In questo foglio troverai le seguenti colonne:</p>
<ul>
<li><strong>Colonna A (CODICE PAESE)</strong>: Inserisci il codice del paese (es. IT per Italia, FR per Francia, etc.).</li>
<li><strong>Colonna B (P.IVA)</strong>: Inserisci il numero di Partita IVA da controllare.</li>
<li><strong>Colonna C (ESITO CONTROLLO CON VIES)</strong>: I risultati del controllo effettuato tramite il servizio VIES appariranno qui.</li>
<li><strong>Colonna D (ESITO CONTROLLO SINTATTICO (NON LIMITANTE))</strong>: Qui verr√† riportato il risultato del controllo sintattico della Partita IVA, ovvero se il formato √® valido o meno, basato su una regex (non blocca l‚Äôesecuzione del controllo VIES).</li>
</ul></li>
</ul></li>
<li><p><strong>Clicca sul bottone per eseguire il controllo</strong>:</p>
<ul>
<li><p>Nel foglio <strong>CONFIGURAZIONE</strong>, troverai un bottone a forma di <strong>triangolo nero</strong>, simile al tasto ‚ÄúPlay‚Äù di un lettore multimediale.</p></li>
<li><p><strong>Clicca sul bottone</strong> per avviare il controllo delle Partite IVA.</p></li>
</ul></li>
<li><p><strong>Interpreta i risultati</strong>:</p>
<ul>
<li><p>Una volta avviato il controllo, i risultati verranno visualizzati:</p>
<ul>
<li><strong>Colonna C</strong>: Mostra il risultato del controllo tramite il servizio VIES.</li>
<li><strong>Colonna D</strong>: Mostra se il formato della Partita IVA √® valido o meno (controllo sintattico). Se il controllo sintattico √® positivo, apparir√† ‚ÄúValida‚Äù, se √® negativo apparir√† ‚ÄúNon valida‚Äù.</li>
</ul></li>
<li><p>Alla fine del processo, comparir√† una <strong>finestra di riepilogo</strong> che mostra il numero totale di Partite IVA controllate, quante sono risultate valide o non valide, gli errori riscontrati, e le Partite IVA vuote.</p></li>
</ul></li>
</ol>
</section>
<section id="riepilogo-dei-messaggi" class="level3">
<h3 class="anchored" data-anchor-id="riepilogo-dei-messaggi">Riepilogo dei messaggi</h3>
<p>Al termine dell‚Äôesecuzione, il sistema visualizzer√† una finestra di dialogo che mostrer√† il seguente riepilogo:</p>
<ul>
<li><p><strong>Numero di P.IVA controllate</strong>: Numero totale di Partite IVA processate.</p></li>
<li><p><strong>Valide in VIES</strong>: Partite IVA che risultano valide dopo il controllo con il servizio VIES.</p></li>
<li><p><strong>Non valide in VIES</strong>: Partite IVA che risultano non valide nel servizio VIES (potrebbero non essere registrate o essere errate).</p></li>
<li><p><strong>Errori</strong>: Numero di errori riscontrati durante il controllo (ad esempio, problemi con il servizio VIES o con i dati).</p></li>
<li><p><strong>Vuote</strong>: Numero di righe in cui la Partita IVA non era presente o la cella era vuota.</p></li>
<li><p><strong>Efficienza</strong>: Velocit√† di controllo espressa in Partite IVA per minuto.</p></li>
</ul>
</section>
</section>
<section id="personalizzare-e-modificare-il-codice" class="level2">
<h2 class="anchored" data-anchor-id="personalizzare-e-modificare-il-codice">Personalizzare e modificare il codice</h2>
<p>Questa sezione √® pensata per chi ha gi√† una conoscenza di base di <strong>VBA</strong> e desidera personalizzare o modificare il codice VBA per adattarlo alle proprie necessit√†.</p>
<section id="struttura-del-codice" class="level3">
<h3 class="anchored" data-anchor-id="struttura-del-codice">Struttura del Codice</h3>
<p>Il codice VBA esegue principalmente due controlli:</p>
<ol type="1">
<li><p><strong>Validazione del formato della Partita IVA</strong>: Utilizza un‚Äôespressione regolare (regex) per verificare che il formato della Partita IVA sia conforme alle regole del paese.</p></li>
<li><p><strong>Controllo tramite VIES</strong>: Invia una richiesta al servizio VIES per verificare se la Partita IVA √® valida.</p></li>
</ol>
</section>
<section id="come-modificare-il-codice-vba" class="level3">
<h3 class="anchored" data-anchor-id="come-modificare-il-codice-vba">Come modificare il codice VBA</h3>
<ol type="1">
<li><p><strong>Aprire l‚Äôeditor VBA</strong>:</p>
<ul>
<li><p>Premi <code>ALT + F11</code> per aprire l‚Äôeditor VBA.</p></li>
<li><p>Nel pannello a sinistra, troverai un modulo chiamato <strong>Modulo1</strong> o simile. Qui √® contenuto tutto il codice.</p></li>
</ul></li>
<li><p><strong>Controllo sintattico</strong></p></li>
</ol>
<p>Il controllo sintattico del formato della Partita IVA non blocca il controllo tramite VIES. Anche se il controllo fallisce (ad esempio, se il formato √® errato), la richiesta al servizio VIES verr√† comunque effettuata. Il risultato del controllo sintattico viene inserito nella <strong>Colonna D (ESITO CONTROLLO SINTATTICO (NON LIMITANTE))</strong>. Se il formato √® valido, apparir√† ‚ÄúValida‚Äù, altrimenti ‚ÄúNon valida‚Äù.</p>
</section>
<section id="modifica" class="level3">
<h3 class="anchored" data-anchor-id="modifica">Modifica</h3>
<p>Se desideri modificare o aggiungere una regex per un nuovo paese, segui questi passaggi:</p>
<ol type="1">
<li><p>Vai nel foglio <strong>CONFIGURAZIONE</strong>.</p></li>
<li><p>Inserisci il <strong>codice del paese</strong> nella colonna A (es. ‚ÄúPT‚Äù per il Portogallo).</p></li>
<li><p>Inserisci il pattern <strong>regex</strong> corretto nella colonna B per validare il formato delle Partite IVA del paese specifico (ad esempio, per il Portogallo, potrebbe essere <code>^\d{9}$</code>).</p></li>
<li><p>Salva e chiudi.</p></li>
</ol>
<p>Il codice VBA utilizzer√† automaticamente la regex inserita per validare il formato delle Partite IVA per quel paese.</p>
<p>Altre configurazioni:</p>
<ul>
<li><p><strong>Numero massimo di righe da controllare</strong>: Se nella cella <strong>B1</strong> del foglio <strong>CONFIGURAZIONE</strong> non viene inserito un valore, la macro controller√† tutte le righe con Partite IVA fino alla prima riga vuota. Se viene inserito un numero, controller√† solo quel numero di righe.</p></li>
<li><p><strong>Codice paese predefinito</strong>: Se una Partita IVA non ha un codice paese associato (colonna A vuota), verr√† usato il codice predefinito specificato nella cella <strong>B2</strong> del foglio <strong>CONFIGURAZIONE</strong>.</p></li>
</ul>
</section>
</section>
<section id="riassumendo" class="level2">
<h2 class="anchored" data-anchor-id="riassumendo">Riassumendo</h2>
<p>Questa guida ti permette di utilizzare un file Excel per controllare le Partite IVA europee tramite il servizio VIES. Se sei un utente che non ha familiarit√† con la programmazione, puoi facilmente utilizzare il file cliccando semplicemente su un bottone. Se hai invece conoscenze di VBA, puoi personalizzare il codice o modificare il file per adattarlo meglio alle tue esigenze specifiche, come l‚Äôaggiunta di nuovi paesi o la modifica dei messaggi restituiti.</p>
<p>In questo modo, puoi automatizzare il controllo delle Partite IVA e risparmiare tempo nella gestione dei dati aziendali.</p>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>personal productivity</category>
  <category>üáÆüáπ</category>
  <guid>https://antomon.github.io/posts/controllo-piva-vies-api/</guid>
  <pubDate>Sun, 21 Nov 2021 23:00:00 GMT</pubDate>
  <media:content url="https://antomon.github.io/posts/controllo-piva-vies-api/spreadsheet-checks.webp" medium="image" type="image/webp"/>
</item>
</channel>
</rss>
