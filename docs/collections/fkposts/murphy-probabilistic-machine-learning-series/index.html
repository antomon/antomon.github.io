<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Antonio Montano">
<meta name="dcterms.date" content="2025-04-06">
<meta name="description" content="This article offers an in-depth review of Kevin Murphy’s Probabilistic Machine Learning trilogy, comprising Machine Learning: A Probabilistic Perspective (2012), Probabilistic Machine Learning: An Introduction (2022), and the draft of Probabilistic Machine Learning: Advanced Topics (2025). It begins with an overview of the principles and importance of probabilistic machine learning, then explores the content, structure, and pedagogical goals of each book in the series. The review evaluates the relevance of each volume in light of contemporary trends in machine learning and provides targeted recommendations for students, instructors, researchers, and practitioners. The trilogy is ultimately positioned as a rigorous, forward-thinking curriculum for building machine learning systems that reason under uncertainty.">

<title>Probabilistic Machine Learning - Kevin Murphy – Random Bits of Knowledge</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-1100dc645a9806080dc50effd6ccb0f7.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-efcabdd787298c2db09eab6dea954178.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=663ff7b280d7c0001914e592&amp;product=sticky-share-buttons" async="async"></script>
<script src="https://cdn.jsdelivr.net/npm/typewriter-effect@latest/dist/core.js"></script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="Probabilistic Machine Learning - Kevin Murphy – Random Bits of Knowledge">
<meta property="og:description" content="This article offers an in-depth review of Kevin Murphy’s Probabilistic Machine Learning trilogy, comprising Machine Learning: A Probabilistic Perspective (2012), Probabilistic Machine Learning: An Introduction (2022), and the draft of Probabilistic Machine Learning: Advanced Topics (2025). It begins with an overview of the principles and importance of probabilistic machine learning, then explores the content, structure, and pedagogical goals of each book in the series. The review evaluates the relevance of each volume in light of contemporary trends in machine learning and provides targeted recommendations for students, instructors, researchers, and practitioners. The trilogy is ultimately positioned as a rigorous, forward-thinking curriculum for building machine learning systems that reason under uncertainty.">
<meta property="og:image" content="https://antomon.github.io/collections/fkposts/murphy-probabilistic-machine-learning-series/3.jpg">
<meta property="og:site_name" content="Random Bits of Knowledge">
<meta name="twitter:title" content="Probabilistic Machine Learning - Kevin Murphy – Random Bits of Knowledge">
<meta name="twitter:description" content="This article offers an in-depth review of Kevin Murphy’s Probabilistic Machine Learning trilogy, comprising Machine Learning: A Probabilistic Perspective (2012), Probabilistic Machine Learning: An Introduction (2022), and the draft of Probabilistic Machine Learning: Advanced Topics (2025). It begins with an overview of the principles and importance of probabilistic machine learning, then explores the content, structure, and pedagogical goals of each book in the series. The review evaluates the relevance of each volume in light of contemporary trends in machine learning and provides targeted recommendations for students, instructors, researchers, and practitioners. The trilogy is ultimately positioned as a rigorous, forward-thinking curriculum for building machine learning systems that reason under uncertainty.">
<meta name="twitter:image" content="https://antomon.github.io/collections/fkposts/murphy-probabilistic-machine-learning-series/3.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../favicon.png" alt="AM logo" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Random Bits of Knowledge</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../contents/services.html"> 
<span class="menu-text">Services</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-collections" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Collections</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-collections">    
        <li>
    <a class="dropdown-item" href="../../../collections/bookmarks-inspiration.html">
 <span class="dropdown-text">Bookmarks of Inspiration</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../collections/cabinet-digital-curiosities.html">
 <span class="dropdown-text">Cabinet of Digital Curiosities</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../collections/free-knowledge.html">
 <span class="dropdown-text">Free Knowledge</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://4m4.it/corso-python/"> 
<span class="menu-text">Corso Python</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/montano/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/antomon"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/antomon"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title">Probabilistic Machine Learning - Kevin Murphy</h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="5">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#review" id="toc-review" class="nav-link active" data-scroll-target="#review">Review</a>
  <ul class="collapse">
  <li><a href="#introduction-what-is-probabilistic-machine-learning" id="toc-introduction-what-is-probabilistic-machine-learning" class="nav-link" data-scroll-target="#introduction-what-is-probabilistic-machine-learning">Introduction: what Is probabilistic machine learning?</a></li>
  <li><a href="#the-trilogy" id="toc-the-trilogy" class="nav-link" data-scroll-target="#the-trilogy">The trilogy</a></li>
  <li><a href="#recommendations" id="toc-recommendations" class="nav-link" data-scroll-target="#recommendations">Recommendations</a></li>
  <li><a href="#relation-to-contemporary-trends-in-machine-learning" id="toc-relation-to-contemporary-trends-in-machine-learning" class="nav-link" data-scroll-target="#relation-to-contemporary-trends-in-machine-learning">Relation to contemporary trends in machine learning</a></li>
  <li><a href="#verdict" id="toc-verdict" class="nav-link" data-scroll-target="#verdict">Verdict</a></li>
  </ul></li>
  <li><a href="#info" id="toc-info" class="nav-link" data-scroll-target="#info">Info</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Probabilistic Machine Learning - Kevin Murphy</h1>
<p class="subtitle lead">Rethinking machine learning through the Bayesian lens</p>
  <div class="quarto-categories">
    <div class="quarto-category">machine learning</div>
    <div class="quarto-category">🇬🇧</div>
  </div>
  </div>

<div>
  <div class="description">
    This article offers an in-depth review of Kevin Murphy’s <em>Probabilistic Machine Learning</em> trilogy, comprising <em>Machine Learning: A Probabilistic Perspective</em> (2012), <em>Probabilistic Machine Learning: An Introduction</em> (2022), and the draft of <em>Probabilistic Machine Learning: Advanced Topics</em> (2025). It begins with an overview of the principles and importance of probabilistic machine learning, then explores the content, structure, and pedagogical goals of each book in the series. The review evaluates the relevance of each volume in light of contemporary trends in machine learning and provides targeted recommendations for students, instructors, researchers, and practitioners. The trilogy is ultimately positioned as a rigorous, forward-thinking curriculum for building machine learning systems that reason under uncertainty.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Antonio Montano </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 6, 2025</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">April 19, 2025</p>
    </div>
  </div>
    
  </div>
  


</header>



<div class="no-row-height column-margin column-container"><div class="">
<p><img src="1.jpg" class="img-fluid"></p>
</div><div class="">
<p><img src="2.jpg" class="img-fluid"></p>
</div><div class="">
<p><img src="3.jpg" class="img-fluid"></p>
</div></div>

<section id="review" class="level2">
<h2 class="anchored" data-anchor-id="review">Review</h2>
<section id="introduction-what-is-probabilistic-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="introduction-what-is-probabilistic-machine-learning">Introduction: what Is probabilistic machine learning?</h3>
<p>Machine learning (ML) is the discipline that focuses on designing algorithms that allow computers to learn from data, make predictions, and improve over time without being explicitly programmed for each task. At its core, traditional machine learning can often be understood as a function approximation problem: given inputs <span class="math inline">X</span>, learn a function <span class="math inline">f: X \rightarrow Y</span> that maps those inputs to outputs. Many successful techniques—including decision trees, support vector machines, and deep neural networks—fit this paradigm and have achieved outstanding performance on tasks such as image recognition, language modeling, and game playing.</p>
<p>However, real-world problems are rarely deterministic or noiseless. Uncertainty, ambiguity, and incomplete information are the norm rather than the exception. This is where <strong>probabilistic machine learning (PML)</strong> becomes essential.</p>
<p>Probabilistic machine learning is a subfield of ML that emphasizes modeling uncertainty explicitly. Rather than producing a single output or estimate, a probabilistic model produces a <strong>distribution</strong> over possible outcomes, quantifying the confidence in each prediction. In this paradigm, learning is formulated as a problem of <strong>statistical inference</strong>: given observed data, infer the posterior distribution over unobserved variables (such as model parameters, latent states, or predictions).</p>
<p>At the heart of PML is the application of probability theory to every stage of the learning process:</p>
<ul>
<li>Bayesian reasoning allows incorporation of prior knowledge and principled uncertainty estimation.</li>
<li>Latent variable models capture hidden structure in data.</li>
<li>Graphical models express dependencies between variables clearly and concisely.</li>
<li>Approximate inference methods (e.g., variational inference, MCMC) make complex models computationally tractable.</li>
</ul>
<p>In short, probabilistic machine learning provides a <strong>principled, coherent, and extensible framework</strong> for designing models that reason under uncertainty and adapt to changing data distributions.</p>
<p>While traditional ML methods often prioritize point predictions and empirical accuracy, PML emphasizes:</p>
<ul>
<li>Uncertainty quantification</li>
<li>Interpretability and diagnostics</li>
<li>Robustness to noise and model misspecification</li>
<li>Principled model comparison</li>
<li>Decision-making under uncertainty</li>
</ul>
<p>The rise of large-scale deep learning has produced models that are often opaque and poorly calibrated. As machine learning systems are increasingly used in critical applications—such as healthcare, finance, climate modeling, and autonomous vehicles—the ability to <strong>reason about uncertainty, causality, and decision-making</strong> becomes vital. PML provides the tools to:</p>
<ul>
<li>Assess when a model is unsure or operating out-of-distribution</li>
<li>Build systems that can update beliefs as new evidence arrives</li>
<li>Integrate domain knowledge via priors and structured models</li>
<li>Make robust decisions in the face of uncertainty and risk</li>
</ul>
<p>Modern advances—such as <strong>variational autoencoders</strong>, <strong>normalizing flows</strong>, <strong>Bayesian deep learning</strong>, <strong>causal inference frameworks</strong>, and <strong>probabilistic programming languages</strong>—have dramatically expanded the scope and scalability of PML.</p>
<p>Kevin Murphy’s trilogy of books stands out for presenting the field of machine learning entirely through the probabilistic lens. His work provides a unified view of learning, inference, prediction, and decision-making, making the case that probabilistic modeling is not an alternative to machine learning—it is its natural and rigorous generalization.</p>
</section>
<section id="the-trilogy" class="level3">
<h3 class="anchored" data-anchor-id="the-trilogy">The trilogy</h3>
<section id="machine-learning-a-probabilistic-perspective-2012" class="level4">
<h4 class="anchored" data-anchor-id="machine-learning-a-probabilistic-perspective-2012">1. Machine Learning: A Probabilistic Perspective (2012)</h4>
<p>Murphy’s first book, published in 2012, was a landmark achievement that laid the groundwork for much of the modern probabilistic approach to machine learning. Spanning over 1000 pages, it offers a comprehensive and mathematically rigorous treatment of probabilistic modeling, treating learning as a problem of statistical inference. The book begins with foundational material in probability theory and Bayesian statistics before delving into a broad array of topics such as supervised learning (regression and classification), unsupervised learning (clustering, dimensionality reduction), probabilistic graphical models (Bayesian networks and Markov random fields), and approximate inference techniques (variational inference, Markov Chain Monte Carlo). It also covers expectation-maximization, hidden Markov models, kernel methods, and Gaussian processes. This volume is notable for its unified framework that emphasizes modeling uncertainty, integrating prior knowledge, and reasoning about complex data using structured probabilistic methods.</p>
<p>Core content:</p>
<ul>
<li>Probability theory, Bayesian statistics, decision theory.</li>
<li>Supervised learning: regression, classification, support vector machines.</li>
<li>Unsupervised learning: clustering, dimensionality reduction.</li>
<li>Probabilistic graphical models: Bayesian networks and Markov random fields.</li>
<li>Approximate inference: variational methods, MCMC.</li>
<li>Expectation-maximization (EM), mixture models, and hidden Markov models.</li>
<li>Model comparison, selection, and overfitting.</li>
<li>Kernel methods and Gaussian processes.</li>
</ul>
<p>The book is methodical and mathematically grounded. It doesn’t shy away from complexity but presents concepts in a pedagogically sound manner. It serves both as a textbook and a reference, rich in examples and code snippets (originally in MATLAB/Octave).</p>
<p>While deep learning has dramatically changed the machine learning landscape since 2012, the foundations presented in MLAPP remain critically relevant. The probabilistic treatment of learning, inference, and model uncertainty continues to underpin research in Bayesian deep learning, causal inference, reinforcement learning, and decision-making.</p>
<p>However, the book does not cover recent developments such as generative models (GANs, VAEs, diffusion models), large-scale optimization in neural networks, or probabilistic programming systems, making it less suitable for those primarily focused on modern deep learning pipelines.</p>
</section>
<section id="probabilistic-machine-learning-an-introduction-2022" class="level4">
<h4 class="anchored" data-anchor-id="probabilistic-machine-learning-an-introduction-2022">2. Probabilistic Machine Learning: An Introduction (2022)</h4>
<p>This volume represents a pedagogical reboot and modernization of MLAPP. It revisits many of the same foundational topics but presents them with improved clarity, a more focused scope, and integration with modern tools such as JAX and NumPyro for probabilistic programming. The book begins with the fundamentals of probability theory and statistical inference, emphasizing both Bayesian and frequentist approaches. It then covers key techniques in supervised learning, such as linear and logistic regression, and introduces Gaussian distributions, conjugate priors, and hierarchical models. Latent variable models such as PCA and Gaussian mixture models are explored in accessible terms. Notably, the book introduces approximate inference using variational methods and connects them to probabilistic programming frameworks. It also addresses model evaluation techniques, such as cross-validation and information criteria, and concludes with an overview of Gaussian processes. Overall, this volume offers a solid, modern foundation in probabilistic modeling, suitable for both students and practitioners entering the field.</p>
<p>Core content:</p>
<ul>
<li>Probability and statistics for machine learning.</li>
<li>Bayesian and frequentist inference.</li>
<li>Maximum likelihood estimation, MAP, posterior predictive distributions.</li>
<li>Conjugate priors, hierarchical models, and empirical Bayes.</li>
<li>Gaussian distributions, linear regression, logistic regression.</li>
<li>Gaussian processes (including scalable approximations).</li>
<li>Probabilistic programming and variational inference.</li>
<li>Decision theory and model evaluation (cross-validation, information criteria).</li>
<li>Basic latent variable models: PCA, mixture models, factor analysis.</li>
</ul>
<p>Several pedagogical enhancements that support learning and experimentation are introduced in this book. Readers are provided with runnable Jupyter notebooks, conveniently hosted in Google Colab, which allow for hands-on interaction with code and models. The book’s figures and illustrations are generated directly from these notebooks, enabling a tight integration between theory, visualization, and practice. The writing style emphasizes conceptual clarity without compromising on mathematical rigor, making advanced topics more approachable and easier to internalize for a wide audience.</p>
<p>This book is arguably more relevant than MLAPP for a newcomer or intermediate reader in 2025. It reflects the shift toward integrating probability with scalable modern tools and introduces practical workflows for modeling and inference. While it deliberately avoids diving deep into generative models or reinforcement learning, it sets a strong foundation for those topics.</p>
<p>Importantly, readers do not need to read <em>Machine Learning: A Probabilistic Perspective</em> before tackling this book. <em>Probabilistic Machine Learning: An Introduction</em> is designed to be self-contained and more accessible, making it an ideal starting point for those new to the field or those seeking a practical yet principled approach to probabilistic modeling.</p>
<p>For instructors designing machine learning or probabilistic modeling courses, it is an excellent primary textbook. than MLAPP for a newcomer or intermediate reader in 2025. It reflects the shift toward integrating probability with scalable modern tools and introduces practical workflows for modeling and inference. While it deliberately avoids diving deep into generative models or reinforcement learning, it sets a strong foundation for those topics.</p>
<p>For instructors designing machine learning or probabilistic modeling courses, it is an excellent primary textbook.</p>
</section>
<section id="probabilistic-machine-learning-advanced-topics-2025-draft" class="level4">
<h4 class="anchored" data-anchor-id="probabilistic-machine-learning-advanced-topics-2025-draft">3. Probabilistic Machine Learning: Advanced Topics (2025 Draft)</h4>
<p>The newly released draft of <em>Advanced Topics</em> is the final and most ambitious volume in Murphy’s trilogy. Designed as a natural progression from <em>An Introduction</em>, it targets readers already comfortable with the fundamentals of probabilistic modeling and Bayesian inference. This volume delves into state-of-the-art techniques that define the cutting edge of modern probabilistic machine learning.</p>
<section id="structure" class="level5">
<h5 class="anchored" data-anchor-id="structure">Structure</h5>
<p>The book is structured into six thematic parts:</p>
<ul>
<li><p><strong>Part I (Fundamentals)</strong> provides a deep theoretical base, covering advanced probability, exponential family models, divergence measures, and optimization principles. It also revisits graphical models in greater depth, including conditional random fields and structured representations.</p></li>
<li><p><strong>Part II (Inference)</strong> focuses on modern approximate inference techniques. It presents Gaussian filtering and smoothing (e.g., Kalman filters and their nonlinear extensions), belief propagation on graphs, variational inference (both classic and black-box forms), and a suite of Monte Carlo methods including Hamiltonian Monte Carlo and sequential Monte Carlo.</p></li>
<li><p><strong>Part III (Prediction)</strong> explores models for supervised learning and uncertainty-aware prediction. This includes generalized linear models, Bayesian neural networks, Gaussian processes with deep kernels, and models for handling non-iid data and distributional shift.</p></li>
<li><p><strong>Part IV (Generation)</strong> is devoted to deep generative models. It introduces variational autoencoders, normalizing flows, diffusion models, autoregressive networks, and energy-based models, with careful attention to training objectives, model evaluation, and sampling.</p></li>
<li><p><strong>Part V (Discovery)</strong> addresses unsupervised and representation learning. It covers latent factor models, state-space models, topic models, deep sequence modeling, graph structure discovery, and interpretability through the lens of probabilistic inference.</p></li>
<li><p><strong>Part VI (Action)</strong> focuses on decision-making, reinforcement learning, and causality. Topics include decision theory, active learning, policy search, model-based and model-free reinforcement learning, influence diagrams, and modern approaches to causal inference including do-calculus, instrumental variables, and counterfactual reasoning.</p></li>
</ul>
<p>Throughout, the book maintains a strong emphasis on scalable inference, modern software tools, and connections between theory and real-world applications. It is both technically deep and broad in scope, providing readers with the tools and intuition needed to work on contemporary research problems in probabilistic modeling, decision-making, and AI.</p>
</section>
<section id="technical-depth-and-breadth" class="level5">
<h5 class="anchored" data-anchor-id="technical-depth-and-breadth">Technical depth and breadth</h5>
<p>This volume is the most technically rigorous of the trilogy. It introduces advanced concepts from statistics, stochastic processes, signal processing, and control theory—disciplines that underpin many of today’s most impactful machine learning innovations. Its comprehensive treatment of probabilistic graphical models and information theory lays the groundwork for structured generative models and modern approaches to representation learning. The discussion of variational inference and Monte Carlo techniques directly supports scalable inference in applications such as variational autoencoders and Bayesian neural networks.</p>
<p>Reinforcement learning is explored through a probabilistic lens, emphasizing the “control as inference” paradigm, which has gained traction in contemporary deep reinforcement learning frameworks. The causal inference section equips readers with formal tools like do-calculus and instrumental variables, essential for understanding causality-aware systems now central to policy evaluation and scientific discovery.</p>
<p>Practical applications that embody these methods include: uncertainty quantification in medical diagnostics using Bayesian neural networks; model-based reinforcement learning in robotic control systems; causal effect estimation in healthcare and social science through counterfactual reasoning; high-fidelity image generation using diffusion models; and structural learning in genomics with probabilistic graphical models. These examples demonstrate how the book’s theoretical foundation translates into applied machine learning systems that operate under uncertainty with reliability and interpretability.</p>
<p>Overall, the volume serves as a bridge connecting classical probabilistic theory with the most recent developments in generative AI, causal discovery, and probabilistic decision-making under uncertainty.</p>
</section>
<section id="relevance-today" class="level5">
<h5 class="anchored" data-anchor-id="relevance-today">Relevance today</h5>
<p>Few books capture the breadth and depth of modern probabilistic machine learning like this one. The inclusion of cutting-edge generative models, reinforcement learning frameworks, and causal reasoning makes it highly relevant. The tight integration with the current state of research ensures that the book will remain a key reference for years to come.</p>
<p>However, it is not intended for beginners. It presupposes comfort with advanced probability, linear algebra, and statistical inference, as well as practical fluency with modern ML tools.</p>
</section>
</section>
</section>
<section id="recommendations" class="level3">
<h3 class="anchored" data-anchor-id="recommendations">Recommendations</h3>
<p>The following table is designed to help readers at different levels identify the most appropriate entry point into Kevin Murphy’s trilogy. Whether you’re a student just beginning to explore probabilistic methods or a researcher seeking depth in advanced generative modeling, this summary suggests a tailored path through the books. The guidance considers both the technical demands and the intended pedagogical focus of each volume.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 44%">
<col style="width: 55%">
</colgroup>
<thead>
<tr class="header">
<th>Reader profile</th>
<th>Suggested reading path</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Undergraduate ML student</td>
<td><em>Probabilistic Machine Learning: An Introduction</em></td>
</tr>
<tr class="even">
<td>Graduate student in ML/statistics</td>
<td><em>Introduction</em> → <em>Advanced Topics</em></td>
</tr>
<tr class="odd">
<td>ML instructor or course designer</td>
<td><em>Introduction</em> as textbook, <em>Advanced Topics</em> for graduate seminar</td>
</tr>
<tr class="even">
<td>Probabilistic programming/research engineer</td>
<td><em>Advanced Topics</em> (esp.&nbsp;inference and generative models)</td>
</tr>
<tr class="odd">
<td>Causal inference/decision science researcher</td>
<td><em>Advanced Topics</em>, especially Part VI</td>
</tr>
<tr class="even">
<td>Deep learning expert seeking interpretability and uncertainty tools</td>
<td><em>Advanced Topics</em>, especially Bayesian deep learning and conformal prediction</td>
</tr>
<tr class="odd">
<td>General ML practitioner</td>
<td><em>Introduction</em> for foundation, followed by selected chapters from <em>Advanced Topics</em></td>
</tr>
</tbody>
</table>
</section>
<section id="relation-to-contemporary-trends-in-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="relation-to-contemporary-trends-in-machine-learning">Relation to contemporary trends in machine learning</h3>
<p>Murphy’s trilogy is deeply relevant to the dominant themes and architectures that currently define machine learning research and application. Notably, the series intersects with several state-of-the-art paradigms such as large language models (LLMs), diffusion models, and other generative frameworks that have become increasingly influential.</p>
<p>In the context of LLMs, while Murphy’s books do not focus on transformer architectures directly, they provide the underlying probabilistic theory necessary to reason about uncertainty, representation learning, and approximate inference in high-dimensional models. This is critical for efforts in Bayesian deep learning applied to LLMs, such as uncertainty-aware language generation, model calibration, and adaptive fine-tuning. Additionally, the treatment of autoregressive modeling and structured sequence generation in the <em>Advanced Topics</em> volume aligns closely with the mathematical principles that underlie language models.</p>
<p>Regarding diffusion models—which have become central to generative image and video synthesis—Murphy’s final volume offers one of the few textbook treatments of these architectures from a probabilistic perspective. It places diffusion models in the broader landscape of score-based generative models, stochastic differential equations, and probabilistic denoising. This not only clarifies how these models work but also situates them in a principled framework for likelihood-based training and sampling.</p>
<p>Moreover, the books’ emphasis on latent variable models, variational inference, and probabilistic programming provides essential context for understanding hybrid approaches that combine deterministic deep networks with stochastic components—an increasingly common design in modern ML systems.</p>
<p>In sum, while Murphy’s books are not focused on deep learning trends per se, they offer foundational and theoretical insight that is crucial for interpreting, extending, and critiquing today’s most influential machine learning models.</p>
</section>
<section id="verdict" class="level3">
<h3 class="anchored" data-anchor-id="verdict">Verdict</h3>
<p>Kevin Murphy’s <em>Probabilistic Machine Learning</em> trilogy offers an exceptional and enduring contribution to the field of machine learning. It accomplishes what few educational resources have: it builds a conceptual and mathematical bridge between foundational statistical thinking and the evolving frontier of machine learning research.</p>
<p><em>Machine Learning: A Probabilistic Perspective</em> serves as a deep and comprehensive reference text, best suited to readers with a solid foundation in mathematics and a desire to explore classical probabilistic modeling in depth. Despite its age, it remains highly relevant for understanding the theoretical underpinnings of the field.</p>
<p><em>Probabilistic Machine Learning: An Introduction</em> is the most accessible and pedagogically refined volume. It strikes a balance between formal rigor and practical usability, making it the best entry point for students, practitioners, and instructors aiming to teach or learn probabilistic reasoning in modern contexts.</p>
<p><em>Probabilistic Machine Learning: Advanced Topics</em> is a masterful synthesis of recent innovations, making it a must-read for researchers, PhD students, and experienced engineers interested in state-of-the-art techniques for uncertainty modeling, generative modeling, causality, and decision-making under uncertainty.</p>
<p>Collectively, these volumes are more than just textbooks—they form a modern curriculum for anyone serious about understanding and building intelligent systems capable of reasoning under uncertainty. Whether used in academia, research, or applied settings, Murphy’s trilogy provides the theoretical backbone and practical insight necessary to advance the field of machine learning responsibly and rigorously.</p>
</section>
</section>
<section id="info" class="level2">
<h2 class="anchored" data-anchor-id="info">Info</h2>
<table class="caption-top table">
<tbody>
<tr class="odd">
<td><h1 id="subject">Subject</h1>
<p><strong>Title</strong></p></td>
<td><h1 id="content">Content</h1>
<p>Probabilistic Machine Learning (3-volume series)</p></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><strong>Years</strong></td>
<td>2012 (<em>MLAPP</em>), 2022 (<em>Introduction</em>), 2025 (<em>Advanced Topics</em>, draft)</td>
<td></td>
</tr>
<tr class="even">
<td><strong>Author</strong></td>
<td><a href="https://www.cs.ubc.ca/~murphyk/">Kevin P. Murphy</a></td>
<td></td>
</tr>
<tr class="odd">
<td><strong>Publisher</strong></td>
<td><a href="https://mitpress.mit.edu/">The MIT Press</a></td>
<td></td>
</tr>
<tr class="even">
<td><strong>Language</strong></td>
<td>English</td>
<td></td>
</tr>
<tr class="odd">
<td><strong>Topics</strong></td>
<td>Bayesian statistics, Probabilistic inference, Graphical models, Generative models, Reinforcement learning, Causality</td>
<td></td>
</tr>
<tr class="even">
<td><strong>Downloads</strong></td>
<td><a href="https://probml.github.io/">Books site &amp; code</a> / <a href="https://github.com/probml/pyprobml">GitHub notebooks</a></td>
<td></td>
</tr>
<tr class="odd">
<td><strong>Other links</strong></td>
<td><a href="https://www.cs.ubc.ca/~murphyk/MLbook/">MLAPP (2012) resources</a></td>
<td></td>
</tr>
<tr class="even">
<td><strong>ISBNs</strong></td>
<td>978-0262046824 (<em>Introduction</em>), 978-0262048378 (<em>Advanced Topics</em>)</td>
<td></td>
</tr>
<tr class="odd">
<td><strong>Buy online</strong></td>
<td><a href="https://mitpress.mit.edu/9780262046824/probabilistic-machine-learning/">MIT Press, <em>Introduction</em></a> / <a href="https://mitpress.mit.edu/9780262048439/probabilistic-machine-learning/">MIT Press, <em>Advanced Topics</em></a></td>
<td></td>
</tr>
</tbody>
</table>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/antomon\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Antonio Montano’s Personal Website</p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
<p>About</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../../contents/services.html">
<p>Services</p>
</a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/montano/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/antomon">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/antomon">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 © Antonio Montano, 2022-2025
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>