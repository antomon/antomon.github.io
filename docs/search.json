[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\n\n\n Back to top"
  },
  {
    "objectID": "posts/colors-101/cielab_sampler.html",
    "href": "posts/colors-101/cielab_sampler.html",
    "title": "Nearest sample",
    "section": "",
    "text": "#CIELab Sampler\nInsert the number of samples of CIELab color space you want and an image with all the colors will be produced. When a color is not present in the RGB color space, then an approximation will be given. Change the variable n_samples:\n\nn_samples = 25**3  # Change this value to generate a different number of samples\n\nRun the following cell for the sampling and image generation\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom skimage import color\nimport warnings\nfrom math import ceil\nfrom colormath.color_objects import LabColor, sRGBColor\nfrom colormath.color_conversions import convert_color\nfrom colormath.color_diff import delta_e_cie2000\n\n\ndef generate_uniform_lab_samples(n_samples):\n    \"\"\"\n    Generate uniformly distributed samples in the CIELab color space.\n    \"\"\"\n    # Calculate the number of points per dimension based on the cubic root of the total number of desired samples\n    points_per_dim = int(round(n_samples ** (1 / 3)))\n\n    # Define the ranges for L, a, b in CIELab\n    L_vals = np.linspace(0, 100, points_per_dim)\n    a_vals = np.linspace(-128, 127, points_per_dim)\n    b_vals = np.linspace(-128, 127, points_per_dim)\n\n    # Create a grid of points in the Lab space\n    lab_samples = np.array(np.meshgrid(L_vals, a_vals, b_vals)).T.reshape(-1, 3)\n\n    # If we have more points than we want, randomly sample from the generated points\n    if len(lab_samples) &gt; n_samples:\n        lab_samples = lab_samples[np.random.choice(len(lab_samples), size=n_samples, replace=False)]\n\n    return lab_samples\n\n\ndef lab_to_rgb(lab_arr):\n    \"\"\"Convert a batch of LAB values to RGB and mark approximations.\"\"\"\n    rgb_arr_255 = np.zeros((lab_arr.shape[0], 3), dtype=int)\n    approx_flags = np.zeros(lab_arr.shape[0], dtype=bool)\n\n    # Convert each LAB color to RGB individually and catch warnings\n    for i, lab in enumerate(lab_arr):\n        with warnings.catch_warnings(record=True) as w:\n            warnings.simplefilter(\"always\")\n\n            # Convert LAB to RGB\n            rgb = color.lab2rgb(lab.reshape(1, 1, 3)).reshape(3)\n            rgb_255 = (255 * np.clip(rgb, 0, 1)).astype(int)\n            rgb_arr_255[i, :] = rgb_255\n\n            # Mark the color as approximated if relevant warnings are raised\n            if any(issubclass(warn.category, UserWarning) and \"negative Z values\" in str(warn.message) for warn in w):\n                approx_flags[i] = True\n                print(str(rgb_255) + \" approx\")\n\n    return rgb_arr_255, approx_flags\n\n\ndef rgb_to_lab(rgb):\n    \"\"\"Convert an RGB color to CIELab color space.\"\"\"\n    # Normalize RGB values to 0-1 range if they are in 0-255 range\n    normalized_rgb = [value / 255.0 for value in rgb]\n    srgb_color = sRGBColor(*normalized_rgb, is_upscaled=False)\n    lab_color = convert_color(srgb_color, LabColor)\n\n    return lab_color\n\n\ndef create_color_chart_with_spacing(lab_samples, rgb_samples, approx_flags, square_size_cm=1, spacing_cm=1,\n                                    label_font_size=3, text_spacing_cm=0.5, save_path='color_chart.png'):\n    \"\"\"\n    Create a square image containing color squares with spacing between them.\n    Each square represents a color sample with spacing between the squares.\n    \"\"\"\n    n_samples = len(rgb_samples)\n    side_length = ceil(n_samples ** 0.5)  # Calculate the side length of the square grid\n\n    # Calculate the total image size considering spacing and text space\n    total_size_cm = side_length * (square_size_cm + spacing_cm + text_spacing_cm) - spacing_cm\n\n    # Create a figure and an axis\n    fig, ax = plt.subplots(figsize=(total_size_cm, total_size_cm), dpi=100)\n    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Remove the border around the squares\n\n    # Draw the color squares with spacing\n    for i, ((lab, rgb), approx) in enumerate(zip(zip(lab_samples, rgb_samples), approx_flags)):\n        row, col = divmod(i, side_length)\n        x_pos = col * (square_size_cm + spacing_cm)\n        y_pos = row * (square_size_cm + spacing_cm + text_spacing_cm)\n        rect = Rectangle((x_pos, y_pos), square_size_cm, square_size_cm, color=rgb / 255)\n        ax.add_patch(rect)\n\n        # Add 'approx' to the text if the color is approximated\n        text_label = f\"{lab}\\n{rgb}\"\n        if approx:\n            text_label += \"\\napprox\"\n\n        # Position the text below the square\n        ax.text(x_pos + square_size_cm / 2, y_pos + square_size_cm + text_spacing_cm / 2, text_label,\n                color='black', ha='center', va='center', fontsize=label_font_size)\n\n    # Set limits and hide axes\n    ax.set_xlim(0, total_size_cm)\n    ax.set_ylim(0, total_size_cm)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_aspect('equal')\n\n    plt.gca().invert_yaxis()  # Invert the y-axis to have the origin at the top left\n\n    # Save the image to the specified path\n    plt.savefig(save_path, bbox_inches='tight')\n    plt.close(fig)\n\n\ndef find_nearest_color_lab(target_lab, generated_lab_samples):\n    \"\"\"\n    Find the nearest CIELab color to the target_lab color among the generated samples using Delta E.\n    \"\"\"\n    # Check if target_lab is a LabColor instance, if not, create one\n    if not isinstance(target_lab, LabColor):\n        target_lab_color = LabColor(*target_lab)\n    else:\n        target_lab_color = target_lab\n\n    min_distance = float('inf')\n    nearest_color = None\n\n    for lab in generated_lab_samples:\n        sample_lab_color = LabColor(*lab)\n        delta_e = delta_e_cie2000(target_lab_color, sample_lab_color)\n\n        if delta_e &lt; min_distance:\n            min_distance = delta_e\n            nearest_color = lab\n\n    return nearest_color\n\n\ndef save_comparison_chart(target_lab, nearest_lab, square_size=4, spacing=4, save_path='colors_comparison.png'):\n    \"\"\"\n    Save an image with two squares: one for the target color and one for the nearest CIELab color.\n    \"\"\"\n    # Extract LAB values if target_lab is a LabColor instance\n    if isinstance(target_lab, LabColor):\n        target_lab_values = [target_lab.lab_l, target_lab.lab_a, target_lab.lab_b]\n    else:\n        target_lab_values = target_lab\n\n    if isinstance(nearest_lab, LabColor):\n        nearest_lab_values = [nearest_lab.lab_l, nearest_lab.lab_a, nearest_lab.lab_b]\n    else:\n        nearest_lab_values = nearest_lab\n\n    # Calculate the dimensions of the figure\n    fig_width = 2 * square_size + spacing\n    fig_height = square_size\n    fig, ax = plt.subplots(1, 2, figsize=(fig_width, fig_height), dpi=100)\n\n    # Adjust the position of the subplots\n    plt.subplots_adjust(wspace=(spacing / fig_width) * (fig_width / fig_height))\n\n    # Prepare the LAB colors for conversion\n    target_lab_array = np.array(target_lab_values).reshape(1, 1, 3)\n    nearest_lab_array = np.array(nearest_lab_values).reshape(1, 1, 3)\n\n    # Convert the LAB colors to RGB for display\n    target_rgb = color.lab2rgb(target_lab_array).reshape(3, )\n    nearest_rgb = color.lab2rgb(nearest_lab_array).reshape(3, )\n\n    # Draw the square for the target color\n    rect_target = Rectangle((0, 0), square_size, square_size, color=target_rgb)\n    ax[0].add_patch(rect_target)\n    ax[0].set_title(\"Starting Color:\\n\" + \", \".join([f\"{val:.2f}\" for val in target_lab_values]))\n    ax[0].axis('off')\n\n    # Draw the square for the nearest CIELab color\n    rect_nearest = Rectangle((0, 0), square_size, square_size, color=nearest_rgb)\n    ax[1].add_patch(rect_nearest)\n    ax[1].set_title(\"Nearest Sample:\\n\" + \", \".join([f\"{val:.2f}\" for val in nearest_lab_values]))\n    ax[1].axis('off')\n\n    # Save the image\n    plt.savefig(save_path, bbox_inches='tight')\n    plt.close(fig)\n    \n\n# Samples generation and image generation\nlab_samples = generate_uniform_lab_samples(n_samples)\nrgb_samples, approx_flags = lab_to_rgb(lab_samples)\ncreate_color_chart_with_spacing(lab_samples, rgb_samples, approx_flags,\n                                square_size_cm=1, spacing_cm=1, label_font_size=3,\n                                text_spacing_cm=0.5, save_path=str(n_samples)+'sampled_colors.png')\n\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[ 0 40  0] approx\n[ 0 38  0] approx\n[ 0 35  0] approx\n[ 0 31  0] approx\n[ 0 28  0] approx\n[ 0 24  0] approx\n[ 0 19  0] approx\n[ 0 13  0] approx\n[2 6 0] approx\n[24  0  0] approx\n[35  0  0] approx\n[44  0  0] approx\n[52  0  0] approx\n[58  0  0] approx\n[65  0  0] approx\n[72  0  0] approx\n[80  0  0] approx\n[88  0  0] approx\n[96  0  0] approx\n[104   0   0] approx\n[113   0   0] approx\n[122   0   0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[ 0 40  0] approx\n[ 0 38  0] approx\n[ 0 35  0] approx\n[ 0 31  0] approx\n[ 0 28  0] approx\n[ 0 24  0] approx\n[ 0 19  0] approx\n[ 0 13  0] approx\n[2 6 0] approx\n[24  0  0] approx\n[35  0  0] approx\n[44  0  0] approx\n[52  0  0] approx\n[58  0  0] approx\n[65  0  0] approx\n[72  0  0] approx\n[80  0  0] approx\n[88  0  0] approx\n[96  0  0] approx\n[104   0   0] approx\n[113   0   0] approx\n[122   0   0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 42  0] approx\n[ 0 40  0] approx\n[ 0 37  0] approx\n[ 0 34  0] approx\n[ 0 31  0] approx\n[ 0 27  0] approx\n[ 0 23  0] approx\n[21 18  0] approx\n[34 12  0] approx\n[43  3  0] approx\n[51  0  0] approx\n[58  0  0] approx\n[66  0  0] approx\n[74  0  0] approx\n[82  0  0] approx\n[91  0  0] approx\n[99  0  0] approx\n[108   0   0] approx\n[117   0   0] approx\n[126   0   0] approx\n[135   0   0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 46  0] approx\n[ 0 44  0] approx\n[ 0 42  0] approx\n[ 0 39  0] approx\n[ 0 36  0] approx\n[ 0 33  0] approx\n[19 30  0] approx\n[32 26  0] approx\n[42 22  0] approx\n[50 16  0] approx\n[59  6  0] approx\n[67  0  0] approx\n[76  0  0] approx\n[85  0  0] approx\n[94  0  0] approx\n[103   0   0] approx\n[112   0   0] approx\n[121   0   0] approx\n[130   0   0] approx\n[140   0   0] approx\n[149   0   0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[ 0 40  0] approx\n[ 0 38  0] approx\n[ 0 35  0] approx\n[ 0 31  0] approx\n[ 0 28  0] approx\n[ 0 24  0] approx\n[ 0 19  0] approx\n[ 0 13  0] approx\n[2 6 0] approx\n[24  0  0] approx\n[35  0  0] approx\n[44  0  0] approx\n[52  0  0] approx\n[58  0  0] approx\n[65  0  0] approx\n[72  0  0] approx\n[80  0  0] approx\n[88  0  0] approx\n[96  0  0] approx\n[104   0   0] approx\n[113   0   0] approx\n[122   0   0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 42  0] approx\n[ 0 40  0] approx\n[ 0 37  0] approx\n[ 0 34  0] approx\n[ 0 31  0] approx\n[ 0 27  0] approx\n[ 0 23  0] approx\n[21 18  0] approx\n[34 12  0] approx\n[43  3  0] approx\n[51  0  0] approx\n[58  0  0] approx\n[66  0  0] approx\n[74  0  0] approx\n[82  0  0] approx\n[91  0  0] approx\n[99  0  0] approx\n[108   0   0] approx\n[117   0   0] approx\n[126   0   0] approx\n[135   0   0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 46  0] approx\n[ 0 44  0] approx\n[ 0 42  0] approx\n[ 0 39  0] approx\n[ 0 36  0] approx\n[ 0 33  0] approx\n[19 30  0] approx\n[32 26  0] approx\n[42 22  0] approx\n[50 16  0] approx\n[59  6  0] approx\n[67  0  0] approx\n[76  0  0] approx\n[85  0  0] approx\n[94  0  0] approx\n[103   0   0] approx\n[112   0   0] approx\n[121   0   0] approx\n[130   0   0] approx\n[140   0   0] approx\n[149   0   0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 54  0] approx\n[ 0 52  0] approx\n[ 0 50  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[12 40  0] approx\n[28 38  0] approx\n[39 34  0] approx\n[50 30  0] approx\n[59 24  0] approx\n[69 16  0] approx\n[78  0  0] approx\n[87  0  0] approx\n[97  0  0] approx\n[106   0   0] approx\n[115   0   0] approx\n[125   0   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[154   0   0] approx\n[163   0   0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[ 0 40  0] approx\n[ 0 38  0] approx\n[ 0 35  0] approx\n[ 0 31  0] approx\n[ 0 28  0] approx\n[ 0 24  0] approx\n[ 0 19  0] approx\n[ 0 13  0] approx\n[2 6 0] approx\n[24  0  0] approx\n[35  0  0] approx\n[44  0  0] approx\n[52  0  0] approx\n[58  0  0] approx\n[65  0  0] approx\n[72  0  0] approx\n[80  0  0] approx\n[88  0  0] approx\n[96  0  0] approx\n[104   0   0] approx\n[113   0   0] approx\n[122   0   0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 42  0] approx\n[ 0 40  0] approx\n[ 0 37  0] approx\n[ 0 34  0] approx\n[ 0 31  0] approx\n[ 0 27  0] approx\n[ 0 23  0] approx\n[21 18  0] approx\n[34 12  0] approx\n[43  3  0] approx\n[51  0  0] approx\n[58  0  0] approx\n[66  0  0] approx\n[74  0  0] approx\n[82  0  0] approx\n[91  0  0] approx\n[99  0  0] approx\n[108   0   0] approx\n[117   0   0] approx\n[126   0   0] approx\n[135   0   0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 46  0] approx\n[ 0 44  0] approx\n[ 0 42  0] approx\n[ 0 39  0] approx\n[ 0 36  0] approx\n[ 0 33  0] approx\n[19 30  0] approx\n[32 26  0] approx\n[42 22  0] approx\n[50 16  0] approx\n[59  6  0] approx\n[67  0  0] approx\n[76  0  0] approx\n[85  0  0] approx\n[94  0  0] approx\n[103   0   0] approx\n[112   0   0] approx\n[121   0   0] approx\n[130   0   0] approx\n[140   0   0] approx\n[149   0   0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 54  0] approx\n[ 0 52  0] approx\n[ 0 50  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[12 40  0] approx\n[28 38  0] approx\n[39 34  0] approx\n[50 30  0] approx\n[59 24  0] approx\n[69 16  0] approx\n[78  0  0] approx\n[87  0  0] approx\n[97  0  0] approx\n[106   0   0] approx\n[115   0   0] approx\n[125   0   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[154   0   0] approx\n[163   0   0] approx\n[ 0 65  0] approx\n[ 0 64  0] approx\n[ 0 62  0] approx\n[ 0 61  0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[19 49  0] approx\n[35 47  0] approx\n[47 43  0] approx\n[58 39  0] approx\n[69 33  0] approx\n[79 25  0] approx\n[89 11  0] approx\n[99  0  0] approx\n[109   0   0] approx\n[119   0   0] approx\n[128   0   0] approx\n[138   0   0] approx\n[148   0   0] approx\n[158   0   0] approx\n[168   0   0] approx\n[178   0   0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[ 0 40  0] approx\n[ 0 38  0] approx\n[ 0 35  0] approx\n[ 0 31  0] approx\n[ 0 28  0] approx\n[ 0 24  0] approx\n[ 0 19  0] approx\n[ 0 13  0] approx\n[2 6 0] approx\n[24  0  0] approx\n[35  0  0] approx\n[44  0  0] approx\n[52  0  0] approx\n[58  0  0] approx\n[65  0  0] approx\n[72  0  0] approx\n[80  0  0] approx\n[88  0  0] approx\n[96  0  0] approx\n[104   0   0] approx\n[113   0   0] approx\n[122   0   0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 42  0] approx\n[ 0 40  0] approx\n[ 0 37  0] approx\n[ 0 34  0] approx\n[ 0 31  0] approx\n[ 0 27  0] approx\n[ 0 23  0] approx\n[21 18  0] approx\n[34 12  0] approx\n[43  3  0] approx\n[51  0  0] approx\n[58  0  0] approx\n[66  0  0] approx\n[74  0  0] approx\n[82  0  0] approx\n[91  0  0] approx\n[99  0  0] approx\n[108   0   0] approx\n[117   0   0] approx\n[126   0   0] approx\n[135   0   0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 46  0] approx\n[ 0 44  0] approx\n[ 0 42  0] approx\n[ 0 39  0] approx\n[ 0 36  0] approx\n[ 0 33  0] approx\n[19 30  0] approx\n[32 26  0] approx\n[42 22  0] approx\n[50 16  0] approx\n[59  6  0] approx\n[67  0  0] approx\n[76  0  0] approx\n[85  0  0] approx\n[94  0  0] approx\n[103   0   0] approx\n[112   0   0] approx\n[121   0   0] approx\n[130   0   0] approx\n[140   0   0] approx\n[149   0   0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 54  0] approx\n[ 0 52  0] approx\n[ 0 50  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[12 40  0] approx\n[28 38  0] approx\n[39 34  0] approx\n[50 30  0] approx\n[59 24  0] approx\n[69 16  0] approx\n[78  0  0] approx\n[87  0  0] approx\n[97  0  0] approx\n[106   0   0] approx\n[115   0   0] approx\n[125   0   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[154   0   0] approx\n[163   0   0] approx\n[ 0 65  0] approx\n[ 0 64  0] approx\n[ 0 62  0] approx\n[ 0 61  0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[19 49  0] approx\n[35 47  0] approx\n[47 43  0] approx\n[58 39  0] approx\n[69 33  0] approx\n[79 25  0] approx\n[89 11  0] approx\n[99  0  0] approx\n[109   0   0] approx\n[119   0   0] approx\n[128   0   0] approx\n[138   0   0] approx\n[148   0   0] approx\n[158   0   0] approx\n[168   0   0] approx\n[178   0   0] approx\n[ 0 73  0] approx\n[ 0 72  0] approx\n[ 0 71  0] approx\n[ 0 69  0] approx\n[ 0 68  0] approx\n[ 0 66  0] approx\n[ 0 65  0] approx\n[ 0 63  0] approx\n[ 0 61  0] approx\n[25 59  0] approx\n[42 56  0] approx\n[56 52  0] approx\n[68 48  0] approx\n[79 42  0] approx\n[90 34  0] approx\n[100  23   0] approx\n[111   0   0] approx\n[121   0   0] approx\n[131   0   0] approx\n[142   0   0] approx\n[152   0   0] approx\n[162   0   0] approx\n[172   0   0] approx\n[183   0   0] approx\n[193   0   0] approx\n[ 0 83  0] approx\n[ 0 81  0] approx\n[ 0 80  0] approx\n[ 0 79  0] approx\n[ 0 78  0] approx\n[ 0 77  0] approx\n[ 0 75  0] approx\n[ 0 73  0] approx\n[ 2 71  0] approx\n[33 69  0] approx\n[51 66  0] approx\n[65 62  0] approx\n[78 57  0] approx\n[90 51  0] approx\n[101  44   0] approx\n[112  33   0] approx\n[123  15   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[155   0   0] approx\n[165   0   0] approx\n[176   0   0] approx\n[187   0   0] approx\n[197   0   0] approx\n[208   0   0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[ 0 40  0] approx\n[ 0 38  0] approx\n[ 0 35  0] approx\n[ 0 31  0] approx\n[ 0 28  0] approx\n[ 0 24  0] approx\n[ 0 19  0] approx\n[ 0 13  0] approx\n[2 6 0] approx\n[24  0  0] approx\n[35  0  0] approx\n[44  0  0] approx\n[52  0  0] approx\n[58  0  0] approx\n[65  0  0] approx\n[72  0  0] approx\n[80  0  0] approx\n[88  0  0] approx\n[96  0  0] approx\n[104   0   0] approx\n[113   0   0] approx\n[122   0   0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 42  0] approx\n[ 0 40  0] approx\n[ 0 37  0] approx\n[ 0 34  0] approx\n[ 0 31  0] approx\n[ 0 27  0] approx\n[ 0 23  0] approx\n[21 18  0] approx\n[34 12  0] approx\n[43  3  0] approx\n[51  0  0] approx\n[58  0  0] approx\n[66  0  0] approx\n[74  0  0] approx\n[82  0  0] approx\n[91  0  0] approx\n[99  0  0] approx\n[108   0   0] approx\n[117   0   0] approx\n[126   0   0] approx\n[135   0   0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 46  0] approx\n[ 0 44  0] approx\n[ 0 42  0] approx\n[ 0 39  0] approx\n[ 0 36  0] approx\n[ 0 33  0] approx\n[19 30  0] approx\n[32 26  0] approx\n[42 22  0] approx\n[50 16  0] approx\n[59  6  0] approx\n[67  0  0] approx\n[76  0  0] approx\n[85  0  0] approx\n[94  0  0] approx\n[103   0   0] approx\n[112   0   0] approx\n[121   0   0] approx\n[130   0   0] approx\n[140   0   0] approx\n[149   0   0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 54  0] approx\n[ 0 52  0] approx\n[ 0 50  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[12 40  0] approx\n[28 38  0] approx\n[39 34  0] approx\n[50 30  0] approx\n[59 24  0] approx\n[69 16  0] approx\n[78  0  0] approx\n[87  0  0] approx\n[97  0  0] approx\n[106   0   0] approx\n[115   0   0] approx\n[125   0   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[154   0   0] approx\n[163   0   0] approx\n[ 0 65  0] approx\n[ 0 64  0] approx\n[ 0 62  0] approx\n[ 0 61  0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[19 49  0] approx\n[35 47  0] approx\n[47 43  0] approx\n[58 39  0] approx\n[69 33  0] approx\n[79 25  0] approx\n[89 11  0] approx\n[99  0  0] approx\n[109   0   0] approx\n[119   0   0] approx\n[128   0   0] approx\n[138   0   0] approx\n[148   0   0] approx\n[158   0   0] approx\n[168   0   0] approx\n[178   0   0] approx\n[ 0 73  0] approx\n[ 0 72  0] approx\n[ 0 71  0] approx\n[ 0 69  0] approx\n[ 0 68  0] approx\n[ 0 66  0] approx\n[ 0 65  0] approx\n[ 0 63  0] approx\n[ 0 61  0] approx\n[25 59  0] approx\n[42 56  0] approx\n[56 52  0] approx\n[68 48  0] approx\n[79 42  0] approx\n[90 34  0] approx\n[100  23   0] approx\n[111   0   0] approx\n[121   0   0] approx\n[131   0   0] approx\n[142   0   0] approx\n[152   0   0] approx\n[162   0   0] approx\n[172   0   0] approx\n[183   0   0] approx\n[193   0   0] approx\n[ 0 83  0] approx\n[ 0 81  0] approx\n[ 0 80  0] approx\n[ 0 79  0] approx\n[ 0 78  0] approx\n[ 0 77  0] approx\n[ 0 75  0] approx\n[ 0 73  0] approx\n[ 2 71  0] approx\n[33 69  0] approx\n[51 66  0] approx\n[65 62  0] approx\n[78 57  0] approx\n[90 51  0] approx\n[101  44   0] approx\n[112  33   0] approx\n[123  15   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[155   0   0] approx\n[165   0   0] approx\n[176   0   0] approx\n[187   0   0] approx\n[197   0   0] approx\n[208   0   0] approx\n[ 0 93  0] approx\n[ 0 92  0] approx\n[ 0 91  0] approx\n[ 0 90  0] approx\n[ 0 89  0] approx\n[ 0 87  0] approx\n[ 0 86  0] approx\n[ 0 84  0] approx\n[15 81  0] approx\n[43 79  0] approx\n[60 75  0] approx\n[75 71  0] approx\n[88 66  0] approx\n[101  60   0] approx\n[113  53   0] approx\n[124  43   0] approx\n[135  28   0] approx\n[146   0   0] approx\n[157   0   0] approx\n[168   0   0] approx\n[179   0   0] approx\n[190   0   0] approx\n[201   0   0] approx\n[212   0   0] approx\n[223   0   0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[ 0 40  0] approx\n[ 0 38  0] approx\n[ 0 35  0] approx\n[ 0 31  0] approx\n[ 0 28  0] approx\n[ 0 24  0] approx\n[ 0 19  0] approx\n[ 0 13  0] approx\n[2 6 0] approx\n[24  0  0] approx\n[35  0  0] approx\n[44  0  0] approx\n[52  0  0] approx\n[58  0  0] approx\n[65  0  0] approx\n[72  0  0] approx\n[80  0  0] approx\n[88  0  0] approx\n[96  0  0] approx\n[104   0   0] approx\n[113   0   0] approx\n[122   0   0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 42  0] approx\n[ 0 40  0] approx\n[ 0 37  0] approx\n[ 0 34  0] approx\n[ 0 31  0] approx\n[ 0 27  0] approx\n[ 0 23  0] approx\n[21 18  0] approx\n[34 12  0] approx\n[43  3  0] approx\n[51  0  0] approx\n[58  0  0] approx\n[66  0  0] approx\n[74  0  0] approx\n[82  0  0] approx\n[91  0  0] approx\n[99  0  0] approx\n[108   0   0] approx\n[117   0   0] approx\n[126   0   0] approx\n[135   0   0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 46  0] approx\n[ 0 44  0] approx\n[ 0 42  0] approx\n[ 0 39  0] approx\n[ 0 36  0] approx\n[ 0 33  0] approx\n[19 30  0] approx\n[32 26  0] approx\n[42 22  0] approx\n[50 16  0] approx\n[59  6  0] approx\n[67  0  0] approx\n[76  0  0] approx\n[85  0  0] approx\n[94  0  0] approx\n[103   0   0] approx\n[112   0   0] approx\n[121   0   0] approx\n[130   0   0] approx\n[140   0   0] approx\n[149   0   0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 54  0] approx\n[ 0 52  0] approx\n[ 0 50  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[12 40  0] approx\n[28 38  0] approx\n[39 34  0] approx\n[50 30  0] approx\n[59 24  0] approx\n[69 16  0] approx\n[78  0  0] approx\n[87  0  0] approx\n[97  0  0] approx\n[106   0   0] approx\n[115   0   0] approx\n[125   0   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[154   0   0] approx\n[163   0   0] approx\n[ 0 65  0] approx\n[ 0 64  0] approx\n[ 0 62  0] approx\n[ 0 61  0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[19 49  0] approx\n[35 47  0] approx\n[47 43  0] approx\n[58 39  0] approx\n[69 33  0] approx\n[79 25  0] approx\n[89 11  0] approx\n[99  0  0] approx\n[109   0   0] approx\n[119   0   0] approx\n[128   0   0] approx\n[138   0   0] approx\n[148   0   0] approx\n[158   0   0] approx\n[168   0   0] approx\n[178   0   0] approx\n[ 0 73  0] approx\n[ 0 72  0] approx\n[ 0 71  0] approx\n[ 0 69  0] approx\n[ 0 68  0] approx\n[ 0 66  0] approx\n[ 0 65  0] approx\n[ 0 63  0] approx\n[ 0 61  0] approx\n[25 59  0] approx\n[42 56  0] approx\n[56 52  0] approx\n[68 48  0] approx\n[79 42  0] approx\n[90 34  0] approx\n[100  23   0] approx\n[111   0   0] approx\n[121   0   0] approx\n[131   0   0] approx\n[142   0   0] approx\n[152   0   0] approx\n[162   0   0] approx\n[172   0   0] approx\n[183   0   0] approx\n[193   0   0] approx\n[ 0 83  0] approx\n[ 0 81  0] approx\n[ 0 80  0] approx\n[ 0 79  0] approx\n[ 0 78  0] approx\n[ 0 77  0] approx\n[ 0 75  0] approx\n[ 0 73  0] approx\n[ 2 71  0] approx\n[33 69  0] approx\n[51 66  0] approx\n[65 62  0] approx\n[78 57  0] approx\n[90 51  0] approx\n[101  44   0] approx\n[112  33   0] approx\n[123  15   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[155   0   0] approx\n[165   0   0] approx\n[176   0   0] approx\n[187   0   0] approx\n[197   0   0] approx\n[208   0   0] approx\n[ 0 93  0] approx\n[ 0 92  0] approx\n[ 0 91  0] approx\n[ 0 90  0] approx\n[ 0 89  0] approx\n[ 0 87  0] approx\n[ 0 86  0] approx\n[ 0 84  0] approx\n[15 81  0] approx\n[43 79  0] approx\n[60 75  0] approx\n[75 71  0] approx\n[88 66  0] approx\n[101  60   0] approx\n[113  53   0] approx\n[124  43   0] approx\n[135  28   0] approx\n[146   0   0] approx\n[157   0   0] approx\n[168   0   0] approx\n[179   0   0] approx\n[190   0   0] approx\n[201   0   0] approx\n[212   0   0] approx\n[223   0   0] approx\n[  0 104   0] approx\n[  0 103   0] approx\n[  0 102   0] approx\n[  0 101   0] approx\n[  0 100   0] approx\n[ 0 98  0] approx\n[ 0 96  0] approx\n[ 0 94  0] approx\n[28 92  0] approx\n[53 89  0] approx\n[70 85  0] approx\n[85 81  0] approx\n[99 76  0] approx\n[112  70   0] approx\n[124  63   0] approx\n[136  53   0] approx\n[148  40   0] approx\n[159  17   0] approx\n[171   0   0] approx\n[182   0   0] approx\n[193   0   0] approx\n[204   0   0] approx\n[215   0   0] approx\n[227   0   0] approx\n[238   0   0] approx\n[  0 116   0] approx\n[  0 115   0] approx\n[  0 114   0] approx\n[  0 113   0] approx\n[  0 111   0] approx\n[  0 109   0] approx\n[  0 107   0] approx\n[  0 105   0] approx\n[ 40 102   0] approx\n[63 99  0] approx\n[81 95  0] approx\n[96 91  0] approx\n[111  86   0] approx\n[124  80   0] approx\n[136  72   0] approx\n[149  63   0] approx\n[161  51   0] approx\n[173  33   0] approx\n[184   0   0] approx\n[196   0   0] approx\n[207   0   0] approx\n[219   0   0] approx\n[230   0   0] approx\n[242   0   0] approx\n[253   0   0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[ 0 40  0] approx\n[ 0 38  0] approx\n[ 0 35  0] approx\n[ 0 31  0] approx\n[ 0 28  0] approx\n[ 0 24  0] approx\n[ 0 19  0] approx\n[ 0 13  0] approx\n[2 6 0] approx\n[24  0  0] approx\n[35  0  0] approx\n[44  0  0] approx\n[52  0  0] approx\n[58  0  0] approx\n[65  0  0] approx\n[72  0  0] approx\n[80  0  0] approx\n[88  0  0] approx\n[96  0  0] approx\n[104   0   0] approx\n[113   0   0] approx\n[122   0   0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 42  0] approx\n[ 0 40  0] approx\n[ 0 37  0] approx\n[ 0 34  0] approx\n[ 0 31  0] approx\n[ 0 27  0] approx\n[ 0 23  0] approx\n[21 18  0] approx\n[34 12  0] approx\n[43  3  0] approx\n[51  0  0] approx\n[58  0  0] approx\n[66  0  0] approx\n[74  0  0] approx\n[82  0  0] approx\n[91  0  0] approx\n[99  0  0] approx\n[108   0   0] approx\n[117   0   0] approx\n[126   0   0] approx\n[135   0   0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 46  0] approx\n[ 0 44  0] approx\n[ 0 42  0] approx\n[ 0 39  0] approx\n[ 0 36  0] approx\n[ 0 33  0] approx\n[19 30  0] approx\n[32 26  0] approx\n[42 22  0] approx\n[50 16  0] approx\n[59  6  0] approx\n[67  0  0] approx\n[76  0  0] approx\n[85  0  0] approx\n[94  0  0] approx\n[103   0   0] approx\n[112   0   0] approx\n[121   0   0] approx\n[130   0   0] approx\n[140   0   0] approx\n[149   0   0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 54  0] approx\n[ 0 52  0] approx\n[ 0 50  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[12 40  0] approx\n[28 38  0] approx\n[39 34  0] approx\n[50 30  0] approx\n[59 24  0] approx\n[69 16  0] approx\n[78  0  0] approx\n[87  0  0] approx\n[97  0  0] approx\n[106   0   0] approx\n[115   0   0] approx\n[125   0   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[154   0   0] approx\n[163   0   0] approx\n[ 0 65  0] approx\n[ 0 64  0] approx\n[ 0 62  0] approx\n[ 0 61  0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[19 49  0] approx\n[35 47  0] approx\n[47 43  0] approx\n[58 39  0] approx\n[69 33  0] approx\n[79 25  0] approx\n[89 11  0] approx\n[99  0  0] approx\n[109   0   0] approx\n[119   0   0] approx\n[128   0   0] approx\n[138   0   0] approx\n[148   0   0] approx\n[158   0   0] approx\n[168   0   0] approx\n[178   0   0] approx\n[ 0 73  0] approx\n[ 0 72  0] approx\n[ 0 71  0] approx\n[ 0 69  0] approx\n[ 0 68  0] approx\n[ 0 66  0] approx\n[ 0 65  0] approx\n[ 0 63  0] approx\n[ 0 61  0] approx\n[25 59  0] approx\n[42 56  0] approx\n[56 52  0] approx\n[68 48  0] approx\n[79 42  0] approx\n[90 34  0] approx\n[100  23   0] approx\n[111   0   0] approx\n[121   0   0] approx\n[131   0   0] approx\n[142   0   0] approx\n[152   0   0] approx\n[162   0   0] approx\n[172   0   0] approx\n[183   0   0] approx\n[193   0   0] approx\n[ 0 83  0] approx\n[ 0 81  0] approx\n[ 0 80  0] approx\n[ 0 79  0] approx\n[ 0 78  0] approx\n[ 0 77  0] approx\n[ 0 75  0] approx\n[ 0 73  0] approx\n[ 2 71  0] approx\n[33 69  0] approx\n[51 66  0] approx\n[65 62  0] approx\n[78 57  0] approx\n[90 51  0] approx\n[101  44   0] approx\n[112  33   0] approx\n[123  15   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[155   0   0] approx\n[165   0   0] approx\n[176   0   0] approx\n[187   0   0] approx\n[197   0   0] approx\n[208   0   0] approx\n[ 0 93  0] approx\n[ 0 92  0] approx\n[ 0 91  0] approx\n[ 0 90  0] approx\n[ 0 89  0] approx\n[ 0 87  0] approx\n[ 0 86  0] approx\n[ 0 84  0] approx\n[15 81  0] approx\n[43 79  0] approx\n[60 75  0] approx\n[75 71  0] approx\n[88 66  0] approx\n[101  60   0] approx\n[113  53   0] approx\n[124  43   0] approx\n[135  28   0] approx\n[146   0   0] approx\n[157   0   0] approx\n[168   0   0] approx\n[179   0   0] approx\n[190   0   0] approx\n[201   0   0] approx\n[212   0   0] approx\n[223   0   0] approx\n[  0 104   0] approx\n[  0 103   0] approx\n[  0 102   0] approx\n[  0 101   0] approx\n[  0 100   0] approx\n[ 0 98  0] approx\n[ 0 96  0] approx\n[ 0 94  0] approx\n[28 92  0] approx\n[53 89  0] approx\n[70 85  0] approx\n[85 81  0] approx\n[99 76  0] approx\n[112  70   0] approx\n[124  63   0] approx\n[136  53   0] approx\n[148  40   0] approx\n[159  17   0] approx\n[171   0   0] approx\n[182   0   0] approx\n[193   0   0] approx\n[204   0   0] approx\n[215   0   0] approx\n[227   0   0] approx\n[238   0   0] approx\n[  0 116   0] approx\n[  0 115   0] approx\n[  0 114   0] approx\n[  0 113   0] approx\n[  0 111   0] approx\n[  0 109   0] approx\n[  0 107   0] approx\n[  0 105   0] approx\n[ 40 102   0] approx\n[63 99  0] approx\n[81 95  0] approx\n[96 91  0] approx\n[111  86   0] approx\n[124  80   0] approx\n[136  72   0] approx\n[149  63   0] approx\n[161  51   0] approx\n[173  33   0] approx\n[184   0   0] approx\n[196   0   0] approx\n[207   0   0] approx\n[219   0   0] approx\n[230   0   0] approx\n[242   0   0] approx\n[253   0   0] approx\n[  0 128   0] approx\n[  0 127   0] approx\n[  0 126   0] approx\n[  0 124   0] approx\n[  0 122   0] approx\n[  0 120   0] approx\n[  0 118   0] approx\n[ 10 116   0] approx\n[ 52 113   0] approx\n[ 74 109   0] approx\n[ 92 105   0] approx\n[108 101   0] approx\n[122  96   0] approx\n[136  89   0] approx\n[149  82   0] approx\n[161  73   0] approx\n[174  62   0] approx\n[186  46   0] approx\n[198  18   0] approx\n[210   0   0] approx\n[222   0   0] approx\n[233   0   0] approx\n[245   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[ 0 40  0] approx\n[ 0 38  0] approx\n[ 0 35  0] approx\n[ 0 31  0] approx\n[ 0 28  0] approx\n[ 0 24  0] approx\n[ 0 19  0] approx\n[ 0 13  0] approx\n[2 6 0] approx\n[24  0  0] approx\n[35  0  0] approx\n[44  0  0] approx\n[52  0  0] approx\n[58  0  0] approx\n[65  0  0] approx\n[72  0  0] approx\n[80  0  0] approx\n[88  0  0] approx\n[96  0  0] approx\n[104   0   0] approx\n[113   0   0] approx\n[122   0   0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 42  0] approx\n[ 0 40  0] approx\n[ 0 37  0] approx\n[ 0 34  0] approx\n[ 0 31  0] approx\n[ 0 27  0] approx\n[ 0 23  0] approx\n[21 18  0] approx\n[34 12  0] approx\n[43  3  0] approx\n[51  0  0] approx\n[58  0  0] approx\n[66  0  0] approx\n[74  0  0] approx\n[82  0  0] approx\n[91  0  0] approx\n[99  0  0] approx\n[108   0   0] approx\n[117   0   0] approx\n[126   0   0] approx\n[135   0   0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 46  0] approx\n[ 0 44  0] approx\n[ 0 42  0] approx\n[ 0 39  0] approx\n[ 0 36  0] approx\n[ 0 33  0] approx\n[19 30  0] approx\n[32 26  0] approx\n[42 22  0] approx\n[50 16  0] approx\n[59  6  0] approx\n[67  0  0] approx\n[76  0  0] approx\n[85  0  0] approx\n[94  0  0] approx\n[103   0   0] approx\n[112   0   0] approx\n[121   0   0] approx\n[130   0   0] approx\n[140   0   0] approx\n[149   0   0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 54  0] approx\n[ 0 52  0] approx\n[ 0 50  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[12 40  0] approx\n[28 38  0] approx\n[39 34  0] approx\n[50 30  0] approx\n[59 24  0] approx\n[69 16  0] approx\n[78  0  0] approx\n[87  0  0] approx\n[97  0  0] approx\n[106   0   0] approx\n[115   0   0] approx\n[125   0   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[154   0   0] approx\n[163   0   0] approx\n[ 0 65  0] approx\n[ 0 64  0] approx\n[ 0 62  0] approx\n[ 0 61  0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[19 49  0] approx\n[35 47  0] approx\n[47 43  0] approx\n[58 39  0] approx\n[69 33  0] approx\n[79 25  0] approx\n[89 11  0] approx\n[99  0  0] approx\n[109   0   0] approx\n[119   0   0] approx\n[128   0   0] approx\n[138   0   0] approx\n[148   0   0] approx\n[158   0   0] approx\n[168   0   0] approx\n[178   0   0] approx\n[ 0 73  0] approx\n[ 0 72  0] approx\n[ 0 71  0] approx\n[ 0 69  0] approx\n[ 0 68  0] approx\n[ 0 66  0] approx\n[ 0 65  0] approx\n[ 0 63  0] approx\n[ 0 61  0] approx\n[25 59  0] approx\n[42 56  0] approx\n[56 52  0] approx\n[68 48  0] approx\n[79 42  0] approx\n[90 34  0] approx\n[100  23   0] approx\n[111   0   0] approx\n[121   0   0] approx\n[131   0   0] approx\n[142   0   0] approx\n[152   0   0] approx\n[162   0   0] approx\n[172   0   0] approx\n[183   0   0] approx\n[193   0   0] approx\n[ 0 83  0] approx\n[ 0 81  0] approx\n[ 0 80  0] approx\n[ 0 79  0] approx\n[ 0 78  0] approx\n[ 0 77  0] approx\n[ 0 75  0] approx\n[ 0 73  0] approx\n[ 2 71  0] approx\n[33 69  0] approx\n[51 66  0] approx\n[65 62  0] approx\n[78 57  0] approx\n[90 51  0] approx\n[101  44   0] approx\n[112  33   0] approx\n[123  15   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[155   0   0] approx\n[165   0   0] approx\n[176   0   0] approx\n[187   0   0] approx\n[197   0   0] approx\n[208   0   0] approx\n[ 0 93  0] approx\n[ 0 92  0] approx\n[ 0 91  0] approx\n[ 0 90  0] approx\n[ 0 89  0] approx\n[ 0 87  0] approx\n[ 0 86  0] approx\n[ 0 84  0] approx\n[15 81  0] approx\n[43 79  0] approx\n[60 75  0] approx\n[75 71  0] approx\n[88 66  0] approx\n[101  60   0] approx\n[113  53   0] approx\n[124  43   0] approx\n[135  28   0] approx\n[146   0   0] approx\n[157   0   0] approx\n[168   0   0] approx\n[179   0   0] approx\n[190   0   0] approx\n[201   0   0] approx\n[212   0   0] approx\n[223   0   0] approx\n[  0 104   0] approx\n[  0 103   0] approx\n[  0 102   0] approx\n[  0 101   0] approx\n[  0 100   0] approx\n[ 0 98  0] approx\n[ 0 96  0] approx\n[ 0 94  0] approx\n[28 92  0] approx\n[53 89  0] approx\n[70 85  0] approx\n[85 81  0] approx\n[99 76  0] approx\n[112  70   0] approx\n[124  63   0] approx\n[136  53   0] approx\n[148  40   0] approx\n[159  17   0] approx\n[171   0   0] approx\n[182   0   0] approx\n[193   0   0] approx\n[204   0   0] approx\n[215   0   0] approx\n[227   0   0] approx\n[238   0   0] approx\n[  0 116   0] approx\n[  0 115   0] approx\n[  0 114   0] approx\n[  0 113   0] approx\n[  0 111   0] approx\n[  0 109   0] approx\n[  0 107   0] approx\n[  0 105   0] approx\n[ 40 102   0] approx\n[63 99  0] approx\n[81 95  0] approx\n[96 91  0] approx\n[111  86   0] approx\n[124  80   0] approx\n[136  72   0] approx\n[149  63   0] approx\n[161  51   0] approx\n[173  33   0] approx\n[184   0   0] approx\n[196   0   0] approx\n[207   0   0] approx\n[219   0   0] approx\n[230   0   0] approx\n[242   0   0] approx\n[253   0   0] approx\n[  0 128   0] approx\n[  0 127   0] approx\n[  0 126   0] approx\n[  0 124   0] approx\n[  0 122   0] approx\n[  0 120   0] approx\n[  0 118   0] approx\n[ 10 116   0] approx\n[ 52 113   0] approx\n[ 74 109   0] approx\n[ 92 105   0] approx\n[108 101   0] approx\n[122  96   0] approx\n[136  89   0] approx\n[149  82   0] approx\n[161  73   0] approx\n[174  62   0] approx\n[186  46   0] approx\n[198  18   0] approx\n[210   0   0] approx\n[222   0   0] approx\n[233   0   0] approx\n[245   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[  0 140   0] approx\n[  0 139   0] approx\n[  0 137   0] approx\n[  0 136   0] approx\n[  0 134   0] approx\n[  0 132   0] approx\n[  0 129   0] approx\n[ 32 126   0] approx\n[ 64 123   0] approx\n[ 86 120   0] approx\n[103 116   0] approx\n[119 111   0] approx\n[134 106   0] approx\n[148  99   0] approx\n[161  92   0] approx\n[174  83   0] approx\n[187  73   0] approx\n[200  59   0] approx\n[212  37   0] approx\n[224   0   0] approx\n[236   0   0] approx\n[248   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[  0 152   0] approx\n[  0 151   0] approx\n[  0 149   0] approx\n[  0 147   0] approx\n[  0 145   0] approx\n[  0 143   0] approx\n[  0 140   0] approx\n[ 48 137   0] approx\n[ 76 134   0] approx\n[ 97 130   0] approx\n[115 126   0] approx\n[131 121   0] approx\n[146 116   0] approx\n[161 110   0] approx\n[174 102   0] approx\n[188  94   0] approx\n[200  83   0] approx\n[213  70   0] approx\n[226  52   0] approx\n[238  16   0] approx\n[250   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[ 0 40  0] approx\n[ 0 38  0] approx\n[ 0 35  0] approx\n[ 0 31  0] approx\n[ 0 28  0] approx\n[ 0 24  0] approx\n[ 0 19  0] approx\n[ 0 13  0] approx\n[2 6 0] approx\n[24  0  0] approx\n[35  0  0] approx\n[44  0  0] approx\n[52  0  0] approx\n[58  0  0] approx\n[65  0  0] approx\n[72  0  0] approx\n[80  0  0] approx\n[88  0  0] approx\n[96  0  0] approx\n[104   0   0] approx\n[113   0   0] approx\n[122   0   0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 42  0] approx\n[ 0 40  0] approx\n[ 0 37  0] approx\n[ 0 34  0] approx\n[ 0 31  0] approx\n[ 0 27  0] approx\n[ 0 23  0] approx\n[21 18  0] approx\n[34 12  0] approx\n[43  3  0] approx\n[51  0  0] approx\n[58  0  0] approx\n[66  0  0] approx\n[74  0  0] approx\n[82  0  0] approx\n[91  0  0] approx\n[99  0  0] approx\n[108   0   0] approx\n[117   0   0] approx\n[126   0   0] approx\n[135   0   0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[ 0 49  0] approx\n[ 0 46  0] approx\n[ 0 44  0] approx\n[ 0 42  0] approx\n[ 0 39  0] approx\n[ 0 36  0] approx\n[ 0 33  0] approx\n[19 30  0] approx\n[32 26  0] approx\n[42 22  0] approx\n[50 16  0] approx\n[59  6  0] approx\n[67  0  0] approx\n[76  0  0] approx\n[85  0  0] approx\n[94  0  0] approx\n[103   0   0] approx\n[112   0   0] approx\n[121   0   0] approx\n[130   0   0] approx\n[140   0   0] approx\n[149   0   0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 54  0] approx\n[ 0 52  0] approx\n[ 0 50  0] approx\n[ 0 47  0] approx\n[ 0 45  0] approx\n[ 0 43  0] approx\n[12 40  0] approx\n[28 38  0] approx\n[39 34  0] approx\n[50 30  0] approx\n[59 24  0] approx\n[69 16  0] approx\n[78  0  0] approx\n[87  0  0] approx\n[97  0  0] approx\n[106   0   0] approx\n[115   0   0] approx\n[125   0   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[154   0   0] approx\n[163   0   0] approx\n[ 0 65  0] approx\n[ 0 64  0] approx\n[ 0 62  0] approx\n[ 0 61  0] approx\n[ 0 59  0] approx\n[ 0 57  0] approx\n[ 0 55  0] approx\n[ 0 53  0] approx\n[ 0 51  0] approx\n[19 49  0] approx\n[35 47  0] approx\n[47 43  0] approx\n[58 39  0] approx\n[69 33  0] approx\n[79 25  0] approx\n[89 11  0] approx\n[99  0  0] approx\n[109   0   0] approx\n[119   0   0] approx\n[128   0   0] approx\n[138   0   0] approx\n[148   0   0] approx\n[158   0   0] approx\n[168   0   0] approx\n[178   0   0] approx\n[ 0 73  0] approx\n[ 0 72  0] approx\n[ 0 71  0] approx\n[ 0 69  0] approx\n[ 0 68  0] approx\n[ 0 66  0] approx\n[ 0 65  0] approx\n[ 0 63  0] approx\n[ 0 61  0] approx\n[25 59  0] approx\n[42 56  0] approx\n[56 52  0] approx\n[68 48  0] approx\n[79 42  0] approx\n[90 34  0] approx\n[100  23   0] approx\n[111   0   0] approx\n[121   0   0] approx\n[131   0   0] approx\n[142   0   0] approx\n[152   0   0] approx\n[162   0   0] approx\n[172   0   0] approx\n[183   0   0] approx\n[193   0   0] approx\n[ 0 83  0] approx\n[ 0 81  0] approx\n[ 0 80  0] approx\n[ 0 79  0] approx\n[ 0 78  0] approx\n[ 0 77  0] approx\n[ 0 75  0] approx\n[ 0 73  0] approx\n[ 2 71  0] approx\n[33 69  0] approx\n[51 66  0] approx\n[65 62  0] approx\n[78 57  0] approx\n[90 51  0] approx\n[101  44   0] approx\n[112  33   0] approx\n[123  15   0] approx\n[134   0   0] approx\n[144   0   0] approx\n[155   0   0] approx\n[165   0   0] approx\n[176   0   0] approx\n[187   0   0] approx\n[197   0   0] approx\n[208   0   0] approx\n[ 0 93  0] approx\n[ 0 92  0] approx\n[ 0 91  0] approx\n[ 0 90  0] approx\n[ 0 89  0] approx\n[ 0 87  0] approx\n[ 0 86  0] approx\n[ 0 84  0] approx\n[15 81  0] approx\n[43 79  0] approx\n[60 75  0] approx\n[75 71  0] approx\n[88 66  0] approx\n[101  60   0] approx\n[113  53   0] approx\n[124  43   0] approx\n[135  28   0] approx\n[146   0   0] approx\n[157   0   0] approx\n[168   0   0] approx\n[179   0   0] approx\n[190   0   0] approx\n[201   0   0] approx\n[212   0   0] approx\n[223   0   0] approx\n[  0 104   0] approx\n[  0 103   0] approx\n[  0 102   0] approx\n[  0 101   0] approx\n[  0 100   0] approx\n[ 0 98  0] approx\n[ 0 96  0] approx\n[ 0 94  0] approx\n[28 92  0] approx\n[53 89  0] approx\n[70 85  0] approx\n[85 81  0] approx\n[99 76  0] approx\n[112  70   0] approx\n[124  63   0] approx\n[136  53   0] approx\n[148  40   0] approx\n[159  17   0] approx\n[171   0   0] approx\n[182   0   0] approx\n[193   0   0] approx\n[204   0   0] approx\n[215   0   0] approx\n[227   0   0] approx\n[238   0   0] approx\n[  0 116   0] approx\n[  0 115   0] approx\n[  0 114   0] approx\n[  0 113   0] approx\n[  0 111   0] approx\n[  0 109   0] approx\n[  0 107   0] approx\n[  0 105   0] approx\n[ 40 102   0] approx\n[63 99  0] approx\n[81 95  0] approx\n[96 91  0] approx\n[111  86   0] approx\n[124  80   0] approx\n[136  72   0] approx\n[149  63   0] approx\n[161  51   0] approx\n[173  33   0] approx\n[184   0   0] approx\n[196   0   0] approx\n[207   0   0] approx\n[219   0   0] approx\n[230   0   0] approx\n[242   0   0] approx\n[253   0   0] approx\n[  0 128   0] approx\n[  0 127   0] approx\n[  0 126   0] approx\n[  0 124   0] approx\n[  0 122   0] approx\n[  0 120   0] approx\n[  0 118   0] approx\n[ 10 116   0] approx\n[ 52 113   0] approx\n[ 74 109   0] approx\n[ 92 105   0] approx\n[108 101   0] approx\n[122  96   0] approx\n[136  89   0] approx\n[149  82   0] approx\n[161  73   0] approx\n[174  62   0] approx\n[186  46   0] approx\n[198  18   0] approx\n[210   0   0] approx\n[222   0   0] approx\n[233   0   0] approx\n[245   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[  0 140   0] approx\n[  0 139   0] approx\n[  0 137   0] approx\n[  0 136   0] approx\n[  0 134   0] approx\n[  0 132   0] approx\n[  0 129   0] approx\n[ 32 126   0] approx\n[ 64 123   0] approx\n[ 86 120   0] approx\n[103 116   0] approx\n[119 111   0] approx\n[134 106   0] approx\n[148  99   0] approx\n[161  92   0] approx\n[174  83   0] approx\n[187  73   0] approx\n[200  59   0] approx\n[212  37   0] approx\n[224   0   0] approx\n[236   0   0] approx\n[248   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[  0 152   0] approx\n[  0 151   0] approx\n[  0 149   0] approx\n[  0 147   0] approx\n[  0 145   0] approx\n[  0 143   0] approx\n[  0 140   0] approx\n[ 48 137   0] approx\n[ 76 134   0] approx\n[ 97 130   0] approx\n[115 126   0] approx\n[131 121   0] approx\n[146 116   0] approx\n[161 110   0] approx\n[174 102   0] approx\n[188  94   0] approx\n[200  83   0] approx\n[213  70   0] approx\n[226  52   0] approx\n[238  16   0] approx\n[250   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[  0 164   0] approx\n[  0 163   0] approx\n[  0 161   0] approx\n[  0 159   0] approx\n[  0 157   0] approx\n[  0 154   0] approx\n[  7 152   0] approx\n[ 62 149   0] approx\n[ 88 145   0] approx\n[109 141   0] approx\n[127 137   0] approx\n[143 132   0] approx\n[159 126   0] approx\n[173 120   0] approx\n[187 113   0] approx\n[201 104   0] approx\n[214  94   0] approx\n[227  82   0] approx\n[240  65   0] approx\n[253  40   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n[255   0   0] approx\n\n\n\nNearest sample\nGet the nearest sample from a new color in CIELab. Change value in variable target_lab:\n\ntarget_lab = [40., 10., 30.]  # Target CIELab color. Make sure the values are float or it returns black\n\nRun the following cell to retrieve the nearest sample\n\n# Find the nearest CIELab color for a given CIELab and RGB color\nnearest_lab = find_nearest_color_lab(target_lab, lab_samples)\nprint(\"Nearest CIELab color of \", str(target_lab), \" is: \", nearest_lab)\n\nsave_comparison_chart(target_lab, nearest_lab, save_path='lab_approx.png')\n\nNearest CIELab color of  [40.0, 10.0, 30.0]  is:  [41.66666667 10.125      31.375     ]\n\n\nGet the nearest sample from a new color in RGB. Change value in variable target_rgb:\n\ntarget_rgb = [120., 65., 200.]  # Target RGB color\n\nRun the following cell to retrieve the nearest sample\n\n# Find the nearest CIELab color for a given CIELab and RGB color\ntarget_lab_from_rgb = rgb_to_lab(target_rgb)\nnearest_lab_from_rgb = find_nearest_color_lab(target_lab_from_rgb, lab_samples)\nprint(\"Nearest CIELab color of RGB \", str(target_rgb), \" is: \", nearest_lab_from_rgb)\n\nsave_comparison_chart(target_lab_from_rgb, nearest_lab_from_rgb, save_path='rgb_approx.png')\n\nNearest CIELab color of RGB  [120.0, 65.0, 200.0]  is:  [ 41.66666667  52.625      -64.25      ]\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/colors-101/index.html",
    "href": "posts/colors-101/index.html",
    "title": "Colors 101",
    "section": "",
    "text": "Let’s break down the concept of a color space into simple terms first, and then delve into the technical aspects.\n\n\nImagine you have a huge box of crayons with every color you can think of. A color space is like picking a smaller box from this huge collection. This smaller box contains a specific range of colors that you can use for a particular purpose, like drawing a picture or printing a photograph.\nJust like you can’t use the colors outside your chosen crayon box, a color space defines the range of colors (or ‘gamut’) that can be represented or reproduced in a medium, whether it’s a computer screen, a camera, or a printed page. Different color spaces are like different sets of crayons, each suited for different tasks or equipment.\n\n\n\nA color space is a specific organization of colors, which in a more formal setting can be described by the mathematics of color models. It’s a three-dimensional model where each color is represented by a unique point within a coordinate system.\nTechnically, a color space maps out a range of colors in terms of intensity values across different channels (like red, green, blue in RGB color space). It provides a standard by which we can define and reproduce colors across different devices and mediums.\nComponents of a color space are:\n\nPrimary Colors: These are the reference colors used in a color model. For example, RGB uses red, green, and blue as primary colors.\nGamut: This is the complete subset of colors that can be accurately represented within a given color space.\nColor model: The underlying mathematical model describing the way colors can be represented as tuples of numbers (e.g., RGB, CMYK, HSL).\nPerceptual uniformity: Some color spaces (like CIELab) are designed to be perceptually uniform. This means that a change of the same amount in a color value should produce a change of about the same visual importance.\nDevice-dependent vs device-independent: Color spaces can be device-dependent (like Adobe RGB, specific to monitors and printers) or device-independent (like CIELab), which abstracts color definitions from specific devices, allowing for consistent color reproduction across different devices.\nStandardization: Standards such as sRGB are established to ensure uniform color representation across different digital devices and platforms, crucial in digital media and web content.\n\nIn essence, a color space is a framework that allows for consistent and precise color representation, ensuring that the colors you see and use are the same across various devices and mediums."
  },
  {
    "objectID": "posts/colors-101/index.html#color-spaces",
    "href": "posts/colors-101/index.html#color-spaces",
    "title": "Colors 101",
    "section": "",
    "text": "Let’s break down the concept of a color space into simple terms first, and then delve into the technical aspects.\n\n\nImagine you have a huge box of crayons with every color you can think of. A color space is like picking a smaller box from this huge collection. This smaller box contains a specific range of colors that you can use for a particular purpose, like drawing a picture or printing a photograph.\nJust like you can’t use the colors outside your chosen crayon box, a color space defines the range of colors (or ‘gamut’) that can be represented or reproduced in a medium, whether it’s a computer screen, a camera, or a printed page. Different color spaces are like different sets of crayons, each suited for different tasks or equipment.\n\n\n\nA color space is a specific organization of colors, which in a more formal setting can be described by the mathematics of color models. It’s a three-dimensional model where each color is represented by a unique point within a coordinate system.\nTechnically, a color space maps out a range of colors in terms of intensity values across different channels (like red, green, blue in RGB color space). It provides a standard by which we can define and reproduce colors across different devices and mediums.\nComponents of a color space are:\n\nPrimary Colors: These are the reference colors used in a color model. For example, RGB uses red, green, and blue as primary colors.\nGamut: This is the complete subset of colors that can be accurately represented within a given color space.\nColor model: The underlying mathematical model describing the way colors can be represented as tuples of numbers (e.g., RGB, CMYK, HSL).\nPerceptual uniformity: Some color spaces (like CIELab) are designed to be perceptually uniform. This means that a change of the same amount in a color value should produce a change of about the same visual importance.\nDevice-dependent vs device-independent: Color spaces can be device-dependent (like Adobe RGB, specific to monitors and printers) or device-independent (like CIELab), which abstracts color definitions from specific devices, allowing for consistent color reproduction across different devices.\nStandardization: Standards such as sRGB are established to ensure uniform color representation across different digital devices and platforms, crucial in digital media and web content.\n\nIn essence, a color space is a framework that allows for consistent and precise color representation, ensuring that the colors you see and use are the same across various devices and mediums."
  },
  {
    "objectID": "posts/colors-101/index.html#rgb-and-srgb-color-spaces",
    "href": "posts/colors-101/index.html#rgb-and-srgb-color-spaces",
    "title": "Colors 101",
    "section": "RGB and sRGB Color Spaces",
    "text": "RGB and sRGB Color Spaces\nThe RGB color space, foundational in the realm of digital imaging and display technologies, represents colors through the additive combination of the red (R), green (G), and blue (B) primary colors. For instance, combining red and green light produces yellow, red and blue produce magenta, and green and blue create cyan.\nThe intensity of each primary color, typically represented by a value ranging from 0 to 255 in digital systems, combines to produce a wide spectrum of colors. This model is intrinsically linked to the way human vision perceives color through cone cells sensitive to these three color wavelengths.\nIn the digital context, the RGB color space is device-dependent, meaning the exact color rendition can vary across different devices like monitors, cameras, and scanners. This variation stems from differences in how devices are manufactured and the specific characteristics of their RGB color filters. As a result, a color seen on one RGB device might not look exactly the same on another, leading to inconsistencies in color reproduction.\nsRGB, which stands for standard Red Green Blue, emerged as a standardization effort to tackle these inconsistencies, especially pertinent in consumer electronics and online content. Developed jointly by HP and Microsoft in 1996, sRGB provides a specific implementation of the RGB color space with well-defined chromaticities for the red, green, and blue primaries. It also specifies a transfer function (or gamma curve), which defines how the numerical values of R, G, and B map to actual luminance levels. In sRGB, this curve is a piecewise function: a linear segment in the darkest shades and a power function in the rest of the range, with a gamma value of approximately 2.2, which is close to the perceptual linearization of human vision.\nOne of the limitations of sRGB is its relatively narrow color gamut compared to other color spaces like Adobe RGB or ProPhoto RGB. This limitation is particularly evident in highly saturated colors, where sRGB can fail to reproduce the vibrancy seen in the real world or in wider-gamut color spaces. However, its ubiquity and standardization across a wide array of devices and software make it the default choice for web content, consumer electronics, and standard digital photography. Its compatibility and predictability across different platforms ensure that colors rendered in sRGB appear reasonably consistent on most modern displays, which are typically calibrated to this color space.\nIn current usage, while professional-grade equipment and applications might opt for wider-gamut color spaces like Adobe RGB, sRGB remains the principal color space for web-based content, ensuring that colors are represented uniformly across different viewing platforms. In essence, while RGB lays the foundation for digital color representation, sRGB standardizes this representation for widespread and consistent use in digital media.\n\nNumber of Colors\nIn both RGB and sRGB color spaces, the total number of colors that can be represented depends on the bit depth per channel. In typical scenarios where each of the RGB channels (Red, Green, Blue) is allocated 8 bits (which is quite common in consumer electronics and digital imagery), each channel can represent 2^8 or 256 distinct levels of intensity.\nSince RGB and sRGB both use three channels, the total number of representable colors is calculated by multiplying the number of possibilities in each channel. So, the calculation would be:\n\n256 (Red) x 256 (Green) x 256 (Blue) = 16,777,216 total colors\n\nTherefore, both RGB and sRGB color spaces can represent approximately 16.7 million different colors when using an 8-bit per channel system. It’s important to note that this count is the same for both RGB and sRGB because the difference between these two spaces lies not in the number of colors they can represent but in how they interpret these colors (i.e., the color gamut and the mapping of color values to actual colors on a screen).\nFor images with higher bit depth per channel (like 10-bit, 12-bit, etc.), the total number of representable colors increases exponentially, allowing for a much richer and more nuanced color representation. However, the standard in most common digital applications remains 8-bit per channel.\nHere are some examples of how certain colors are represented within this range:\n\nRed: Pure red is represented as (255, 0, 0). This means the red channel is at its maximum, while green and blue are at their minimum.\nGreen: Pure green is (0, 255, 0), with the green channel at maximum and the others at minimum.\nBlue: Pure blue appears as (0, 0, 255), with the blue channel at its maximum.\nYellow: Yellow is a mix of red and green, so it’s represented as (255, 255, 0).\nCyan: Cyan is a mix of green and blue, shown as (0, 255, 255).\nMagenta: Magenta combines red and blue, represented as (255, 0, 255).\nBlack: Black is the absence of color in the RGB space, so all channels are at their minimum: (0, 0, 0).\nWhite: White is the combination of all colors at their maximum intensity, so it’s (255, 255, 255).\nGray: Shades of gray are created when all three channels have equal intensity. For example, a medium gray might be (128, 128, 128).\nOrange: Orange can vary in shade but is generally a mix of red and some green, such as (255, 165, 0).\n\nThese examples provide a basic understanding of how different colors are represented in the RGB color space. By adjusting the intensity values of the red, green, and blue channels, a wide range of colors can be created.\n\n\nDisplay Standards\nThe standard for most consumer TVs and monitors is typically an 8-bit per channel RGB color system. This means that each of the three color channels (Red, Green, Blue) can display 256 levels of intensity (from 0 to 255), resulting in 16,777,216 possible colors (256^3 = 16,777,216). This is often referred to as “True Color” or “24-bit color” (8 bits x 3 channels).\nHowever, there is an increasing trend towards higher bit depths in newer, higher-end TVs and monitors, especially those geared towards professional use or high-quality entertainment experiences. These include:\n\n10-bit color depth: With 10 bits per channel, a display can produce 1,024 levels of intensity per channel, resulting in a total of about 1.07 billion colors (1,024^3). This is significant for professional-grade monitors used in color-critical tasks like photo and video editing.\n12-bit color depth: Some very high-end and specialized monitors and TVs offer 12-bit color, with 4,096 levels per channel, totaling around 68.7 billion colors (4,096^3). These are less common and are typically used in professional and cinematic settings.\nHDR (high dynamic range): Modern high-end TVs and some monitors support HDR standards like HDR10, Dolby Vision, or HDR10+, which often use a 10-bit or even 12-bit color depth. HDR doesn’t just increase the number of colors; it also enhances the contrast and brightness, leading to a more dynamic and realistic image.\nWide color gamut: Apart from bit depth, many newer displays also support a wider color gamut (such as DCI-P3 or Rec. 2020), meaning they can display a broader range of colors than the traditional sRGB gamut.\n\nIt’s important to note that to fully utilize these higher color depths and wider gamuts, the content being displayed (like movies, TV shows, or games) must also be created to support these standards, and the device’s hardware and software must be compatible with these advanced color features.\n\n\nComplementary Colors\nA complementary color is defined as a color that, when combined with a given color, produces a neutral color (white, gray, or black). Complementary colors are positioned opposite each other on the color wheel, a tool used to represent the relationships between colors.\nIn the RGB model, which is used for light-emitting sources like computer screens, the primary colors are red, green, and blue. The complementary color of red is cyan (a mix of green and blue), green’s complementary color is magenta (a mix of red and blue), and blue’s complementary color is yellow (a mix of red and green). When combined in this model, a color and its complementary produce white light. For example, combining red light with cyan light will result in white light."
  },
  {
    "objectID": "posts/colors-101/index.html#cmy-and-cmyk-color-spaces",
    "href": "posts/colors-101/index.html#cmy-and-cmyk-color-spaces",
    "title": "Colors 101",
    "section": "CMY and CMYK Color Spaces",
    "text": "CMY and CMYK Color Spaces\nThe CMY and CMYK color models are primarily used in color printing and are fundamentally different from the RGB color model, which is used in electronic displays. Both CMY and CMYK are based on the subtractive color model, unlike the additive nature of RGB.\n\nCMY\nCMY operates on the subtractive principle where colors are created by subtracting light. This model is based on the way light is absorbed and reflected off surfaces. It uses cyan, magenta, and yellow as its primary colors. These are the complementary colors of red, green, and blue (RGB), respectively.\nIn CMY, colors are created by partially or entirely subtracting the primary colors of light. For example, subtracting green from white light leaves magenta, subtracting red gives cyan, and subtracting blue yields yellow.\nCMY is used in color printing. By combining varying amounts of cyan, magenta, and yellow, a wide range of colors can be reproduced. When all three colors are combined at their full intensity, they theoretically produce black, but in practice, they produce a muddy dark brown or gray.\n\n\nCMYK\nCMYK adds a fourth component, “key” (black), to the CMY model. The ‘K’ component is used because pure black cannot be created reliably through the combination of CMY inks due to imperfections in ink pigments. Adding black ink allows for deeper, more accurate, and consistent blacks.\nCMYK creates colors through a subtractive process by layering different amounts of cyan, magenta, yellow, and black ink on paper. The more ink used, the darker the color becomes. Black ink in CMYK is also more economical and provides better shadow detail than CMY, making it a more efficient color model for full-color printing.\n\n\nDifferences with RGB\nThe most important difference is that RGB is an additive color model used in electronic displays, where colors are created by combining light. CMY and CMYK are subtractive, used in printing, where colors are created by subtracting light. Or, with different words, RGB is used for digital screens like monitors, TVs, and cameras, where light is emitted directly. CMY and CMYK are used in printing on physical media, where light is reflected.\nIn RGB, black is the absence of light, while in CMYK, black is a separate ink component for deeper and more uniform blacks."
  },
  {
    "objectID": "posts/colors-101/index.html#hsl-and-hsv-color-spaces",
    "href": "posts/colors-101/index.html#hsl-and-hsv-color-spaces",
    "title": "Colors 101",
    "section": "HSL and HSV Color Spaces",
    "text": "HSL and HSV Color Spaces\nBoth HSL (hue, saturation, lightness) and HSV (hue, saturation, value) are color models used to represent the RGB color space in terms that are more intuitive for humans to understand and manipulate. These models describe colors in terms of their shade (hue), intensity (saturation), and brightness (lightness/value):\n\nHSL:\n\nHue: Represents the type of color, or the color itself. It is typically measured in degrees around a color wheel, with red at 0°, green at 120°, and blue at 240°.\nSaturation: Indicates the intensity or purity of the color. In HSL, saturation ranges from 0%, which is a shade of gray, to 100%, which is the full color.\nLightness: Also known as luminance, lightness defines how light or dark a color is. A lightness of 0% is black, 50% is the true color, and 100% is white.\n\nHSV:\n\nHue: Similar to HSL, it defines the color itself.\nSaturation: Measures the intensity or vibrancy of the color. It ranges from 0%, which is completely unsaturated (gray), to 100%, which is the most saturated form of the color.\nValue: Also known as brightness, it represents the brightness or darkness of the color. A value of 0% is black, and 100% is the brightest form of the color.\n\n\n\nDifferences with RGB\nRGB represents colors by specifying the intensity of each primary color, making it less intuitive for tasks like adjusting brightness or saturation. HSL and HSV are transformations of the RGB color model designed to be more intuitive for human perception. They allow for easier adjustments of color properties like shade, intensity, and brightness.\nHSL and HSV are often used in color picker tools in graphic design software because they offer a more user-friendly way to select and manipulate colors. Moreover, they separate the chromatic information (hue and saturation) from the achromatic information (lightness/value), unlike RGB where all three parameters mix chromatic and achromatic components.\nWhile RGB is suited for electronic displays and color mixing with light, HSL and HSV are more suited for tasks that involve adjusting and fine-tuning colors, like in graphic design and photo editing. In essence, HSL and HSV are used to represent the same colors as RGB but in a way that aligns more closely with how people think about and perceive colors. This makes them particularly useful in interfaces and applications where users need to make precise adjustments to color properties."
  },
  {
    "objectID": "posts/colors-101/index.html#other-notations-for-rgb-color-space",
    "href": "posts/colors-101/index.html#other-notations-for-rgb-color-space",
    "title": "Colors 101",
    "section": "Other Notations for RGB Color Space",
    "text": "Other Notations for RGB Color Space\n\nHEX\nHEX color notation is a staple in web and digital design, providing a succinct way to represent RGB colors. It encodes RGB values into a 6-digit hexadecimal number, prefaced by a hash symbol. Each pair of digits in this format, ranging from 00 to FF, corresponds to the red, green, and blue components of a color. This compact and efficient representation makes HEX particularly popular in coding and digital design environments.\n\n\nDecimal\nDecimal color notation is another way to describe RGB colors, similar to HEX but using decimal numbers. It presents colors with three values, each ranging from 0 to 255, for the red, green, and blue components. This approach is particularly user-friendly in programming and digital contexts, where working with decimal numbers is common."
  },
  {
    "objectID": "posts/colors-101/index.html#cie-color-spaces",
    "href": "posts/colors-101/index.html#cie-color-spaces",
    "title": "Colors 101",
    "section": "CIE Color Spaces",
    "text": "CIE Color Spaces\nThe International Commission on Illumination, known as CIE (Commission Internationale de l’Éclairage), is a significant organization in the field of color and lighting standards. CIE has introduced several critical color spaces, including XYZ, CIELab, and CIELCh, each serving unique purposes in color science.\n\nXYZ\nThe CIE XYZ color space, established in 1931, is foundational in the field of colorimetry. It’s a device-independent model representing color perceptions of a standard observer. In XYZ, ‘X’ represents a mix of cone response curves, ‘Y’ denotes luminance, and ‘Z’ corresponds to blue stimulation. This color space serves as a reference, allowing for the translation of colors between different systems and devices. The gamut of XYZ encompasses all perceivable colors, making it a comprehensive standard for color representation.\n\n\nCIELab\nThe CIELab (or Lab) color space, introduced in 1976, with its broad gamut and perceptually uniform characteristics, is designed to encompass the entire range of colors visible to the human eye. This extensive gamut means it can represent colors that are outside the range of many display systems and printers.\nIn CIELab:\n\nThe ‘L’ component (lightness) ranges from 0 to 100, where 0 represents black, and 100 represents white. This vertical axis accounts for the luminance of colors.\nThe ‘a’ component operates on a green to red axis. Negative values of ‘a’ indicate green, while positive values indicate red.\nThe ‘b’ component works on a blue to yellow axis, with negative values representing blue and positive values indicating yellow.\n\nThis structure allows for a precise and detailed representation of colors. For example:\n\nA strong green might be denoted as (L=50, a=-50, b=50), representing a mid-level lightness with a strong green component and a touch of yellow.\nA deep red could be represented as (L=40, a=60, b=30), indicating a darker shade (lower lightness) with a dominant red component and some yellow.\n\nThe notation in CIELab is quite distinct from RGB. While RGB specifies the intensity of red, green, and blue light to create colors (like RGB(255, 0, 0) for bright red), CIELab describes colors in terms of lightness and color-opponent dimensions, which align more closely with the human perception of colors.\nThis perceptual uniformity – where a given numerical change corresponds to a roughly equal perceptual change in color – is a key feature of CIELab. It ensures that when colors are altered or compared in this space, the perceived differences are consistent across the color spectrum.\nCIELab’s broad gamut and perceptual uniformity make it a preferred choice in industries where accurate color differentiation and measurement are critical, like paint manufacturing, textile production, and quality control in various product design processes. It’s also commonly used in digital imaging and photography for color correction and editing, as it offers more intuitive control over color adjustments than RGB.\nA classic example of colors that can be represented in CIELab but are often outside the gamut of many RGB devices are certain highly saturated cyans and blues. For instance, a very bright, saturated cyan might be represented in CIELab as something like (L=90, a=-40, b=-15). This color would be extremely vivid and might not be accurately displayed on a standard RGB monitor, which would struggle to reproduce its intensity and saturation. Similarly, some extremely bright and saturated yellows and greens can also fall outside the typical RGB gamut. These colors are so vivid that they can only be seen under intense lighting conditions, such as direct sunlight, and cannot be fully replicated on standard digital displays.\n\n\nCIELCh\nCIELCh is a color space closely related to CIELab but represented in cylindrical coordinates instead of Cartesian ones. It’s derived from the CIELab color space and is designed to represent color in a way that’s more intuitive and aligned with how humans perceive color changes.\nIn CIELCh, the components represent:\n\nL (lightness): Just like in CIELab, ‘L’ in CIELCh represents the lightness of the color, with 0 being black and 100 being white.\nC (chroma): This is essentially the saturation of the color. Chroma in CIELCh is derived from the a* and b* components of CIELab. It represents the vividness or intensity of the color. Higher chroma values indicate more intense, vivid colors, while lower chroma values result in duller, more washed-out colors.\nh (hue angle): Instead of using the a* and b* Cartesian coordinates to define the hue, CIELCh uses an angle in a cylindrical space. This hue angle starts from the positive a* axis and is usually measured in degrees (0° to 360°). Different values correspond to different hues (colors), similar to positions on a traditional color wheel. For example, 0° or 360° represents red/magenta, 90° represents yellow, 180° represents green, and 270° represents blue.\n\nThe transformation from CIELab to CIELCh is a conversion from Cartesian to cylindrical coordinates. The lightness (L) remains the same, but the a* and b* values in CIELab are converted to chroma (C) and hue (h) in CIELCh. The formulae for these conversions involve trigonometric functions where chroma (C) is calculated as the square root of (a*^2 + b*^2), and the hue angle (h) is calculated using the arctan function.\nCIELCh is useful in various applications that require intuitive color adjustment and selection. The cylindrical representation makes it easier to understand and manipulate hue and saturation independently of lightness, which aligns more closely with how people think about and use color, especially in fields like graphic design, painting, and digital media.\nThis color space is particularly favored for tasks where color harmony and balance are important, as it allows for a straightforward manipulation of color relationships and contrasts.\n\n\nCIELUV\nCIELUV is a color space introduced by the International Commission on Illumination (CIE) to enable more effective color communication, especially for light emitting or reflecting surfaces. It’s part of the CIE 1976 color spaces, which also include CIELab.\nThe name CIELUV comes from the CIE Luv* color space. It’s designed similarly to CIELab, with ‘L’ representing lightness. However, while CIELab uses ‘a’ and ‘b’ for color-opponent dimensions, CIELUV uses ‘u*’ and ‘v*’ for chromaticity. These dimensions are based on the CIE 1960 u-v chromaticity diagram, which is a projection of the CIE XYZ color space.\nCIELUV is particularly useful for applications like lighting design, video, and other emissive display applications where color gamut is crucial. One of its strengths lies in its ability to accurately represent highly saturated colors, a limitation in the CIELab color space.\nIn terms of technical details, the ‘L’ in CIELUV represents the perceived lightness, similar to CIELab. The ‘u*’ and ‘v*’ coordinates, however, are calculated differently, focusing on chromaticity. This difference stems from the way the two color spaces project the XYZ space into the color-opponent dimensions. In CIELUV, these projections are designed to better represent the way we perceive color in light-emitting sources.\nWhen comparing CIELUV to CIELab, the key difference lies in their treatment of chromaticity and the types of applications they’re best suited for. CIELab is generally preferred for surface colors (like paint or ink), where color is a result of light reflecting off an object. In contrast, CIELUV is more suited for light-emitting sources (like displays or lights), where color is produced by light itself.\nBoth color spaces derive from the XYZ model and share the lightness dimension (L*). However, their approach to chromaticity makes them suitable for different applications and types of color processing. CIELUV’s emphasis on chromaticity makes it a valuable tool in industries dealing with light sources, displays, and environments where the light’s color itself is the primary concern.\n\n\nLCH(ab)\nThe LCH(ab) color space, often simply referred to as LCH, is a color model derived from the CIELab color space. It represents colors in a more intuitive way compared to the Cartesian coordinates (a* and b*) used in CIELab. The LCH color model is based on cylindrical coordinates rather than Cartesian coordinates and consists of three components:\n\nLightness (L): Similar to the L* in CIELab, it represents the lightness of the color, where 0 is black, 100 is white, and values in between represent various shades of gray.\nChroma (C): Chroma in LCH is analogous to saturation in other color models. It represents the intensity or purity of the color. Higher chroma values indicate more vibrant colors, while lower values result in more muted tones.\nHue (H): Hue is represented as an angle (in degrees) around a color wheel. It defines the type of color (such as red, blue, green, yellow, etc.). In LCH, hue starts at 0 degrees for red and moves through the spectrum, with green at 120 degrees, blue at 240 degrees, and so forth.\n\nThe LCH color space is particularly useful in applications where understanding and manipulating the color relationships and harmonies are important. It’s often used in graphic design, painting, and digital media for this reason. By separating the color components in this way, LCH allows designers to adjust hue and chroma independently of lightness, which can be more intuitive than working with the a* and b* coordinates in CIELab.\nIn essence, LCH(ab) offers a perceptually-based approach to color representation, aligning closely with how humans perceive and interpret color differences, making it a valuable tool in color-sensitive work.\n\n\nYIQ and YUV Color Spaces\nYIQ and YUV are color spaces primarily used in the broadcasting industry, particularly in television systems. Both are designed to split a color signal into luminance and chrominance components, but they are used in different television standards.\nThe YIQ color space was predominantly used in the NTSC color television system, mainly in North America. In YIQ, ‘Y’ stands for the luminance component, which represents the brightness of the image. The ‘I’ and ‘Q’ components represent the chrominance or color information. ‘I’ carries information about the orange-cyan range, while ‘Q’ carries information about the green-magenta range. The separation of luminance and chrominance in YIQ allowed NTSC broadcasts to be compatible with black-and-white televisions. Luminance (Y) could be displayed by black-and-white TVs, while color TVs could use all three components (Y, I, Q) to display the full color image.\nYUV is similar to YIQ in that it also separates the color signal into luminance (Y) and two chrominance components (U and V). YUV is used in the PAL and SECAM color television systems, prevalent in Europe and other parts of the world. The ‘Y’ component, like in YIQ, represents the image brightness. ‘U’ represents the blue-luminance difference, and ‘V’ represents the red-luminance difference. This separation was also designed for compatibility with black-and-white TVs, with the added advantage of better color quality compared to NTSC, although at a slightly lower resolution.\nBoth YIQ and YUV were developed to maximize the efficiency of color transmission in broadcasting and to ensure backward compatibility with black-and-white television systems. They differ from RGB, which is used in electronic displays and combines red, green, and blue light to produce colors. While RGB is more straightforward for generating colors electronically, YIQ and YUV are more efficient for broadcasting purposes because they separate the brightness of the image from the color information, which can be more efficiently compressed and transmitted.\nThe use of YIQ has declined with the shift towards digital broadcasting, which often uses other color spaces like YCbCr. YUV, on the other hand, is still relevant in many video processing applications and is closely related to the YCbCr color space used in digital video."
  },
  {
    "objectID": "posts/colors-101/index.html#color-space-as-a-mathematical-space-subset",
    "href": "posts/colors-101/index.html#color-space-as-a-mathematical-space-subset",
    "title": "Colors 101",
    "section": "Color Space as a Mathematical Space Subset",
    "text": "Color Space as a Mathematical Space Subset\nThe concept of whether color spaces are subsets of integer or real mathematical spaces can be understood in terms of how they represent color values and the precision with which they operate.\n\nRGB: RGB, commonly used in digital displays and imaging, typically uses integer values in practical applications, especially in 8-bit per channel systems where each color (Red, Green, Blue) is represented by an integer from 0 to 255. However, in more precise applications, such as high dynamic range (HDR) imaging or in professional color grading, RGB values can be represented in a floating-point format (real numbers), allowing for a finer gradation and a wider range of color intensities.\nCIELab and CIELuv: Both CIELab and CIELuv are part of the CIE 1976 color space. They are generally considered to be subsets of the real number space. The L*, a*, b* (CIELab) and L*, u*, v* (CIELuv) coordinates are typically represented as real numbers to allow for a high degree of precision, which is crucial in color matching and colorimetric applications. This representation aligns with their design as perceptually uniform spaces, where small changes in values correspond to consistent perceptual differences in color.\nHEX: The HEX color notation, used predominantly in web design, is based on integer values. It is essentially a hexadecimal representation of RGB values, where each color channel is represented by two hexadecimal digits, corresponding to an integer value between 0 and 255.\nCIE XYZ: The CIE XYZ color space, which serves as a foundation for many other color spaces, including CIELab and CIELuv, represents colors using real numbers. This representation allows for a high degree of precision and is important for scientific and industrial applications where accurate color measurement and reproduction are necessary.\nYIQ, YUV, and others: Used primarily in broadcasting and video processing, these color spaces often use real numbers for greater precision, especially in professional applications. However, for standard television broadcast and consumer electronics, these values are typically quantized into integer values.\n\nIn summary, while practical implementations of these color spaces in digital devices often use integer values for ease of processing and storage, the theoretical models of most advanced color spaces, especially those used in colorimetry and professional applications, rely on real numbers for greater precision and a more accurate representation of color."
  },
  {
    "objectID": "posts/colors-101/index.html#color-spaces-conversion-libraries",
    "href": "posts/colors-101/index.html#color-spaces-conversion-libraries",
    "title": "Colors 101",
    "section": "Color Spaces Conversion Libraries",
    "text": "Color Spaces Conversion Libraries\n\npython-colormath\npython-colormath is a simple Python module that spares the user from directly dealing with color math. Some features include:\n\nSupport for a wide range of color spaces. A good chunk of the CIE spaces, RGB, HSL/HSV, CMY/CMYK, and many more.\nConversions between the various color spaces. For example, XYZ to sRGB, Spectral to XYZ, CIELab to Adobe RGB.\nCalculation of color difference. All CIE Delta E functions, plus CMC.\nChromatic adaptations (changing illuminants).\nRGB to hex and vice-versa.\n16-bit RGB support.\nRuns on Python 2.7 and Python 3.3+.\n\nTo convert a color from sRGB to CIELab using the Python colormath library, you first need to ensure that colormath is installed in your Python environment. You can install it using pip:\npip install colormath\nOnce colormath is installed, you can use it to perform the conversion. Here’s a simple example:\nfrom colormath.color_objects import sRGBColor, LabColor, XYZColor, \\\n                                    LCHabColor, LCHuvColor, HSVColor, \\\n                                    CMYColor, CMYKColor\nfrom colormath.color_conversions import convert_color\n\n# Define an sRGB color (is_upscaled=True if you're using 0-255 range)\n1rgb = sRGBColor(128., 0., 128., is_upscaled=True)\n\n# Convert the sRGB color to other color spaces\n2lab = convert_color(rgb, LabColor)      # CIELab\nxyz = convert_color(rgb, XYZColor)      # XYZ \nlch_ab = convert_color(rgb, LCHabColor) # LCH(ab)\nlch_uv = convert_color(rgb, LCHuvColor) # LCH(uv)\nhsv = convert_color(rgb, HSVColor)      # HSV\ncmy = convert_color(rgb, CMYColor)      # CMY\ncmyk = convert_color(rgb, CMYKColor)    # CMYK\n\n# Print the colors in different color spaces  \n3print(\"CIELab: \", lab)\n# CIELab:  LabColor (lab_l:29.7843 lab_a:58.9285 lab_b:-36.4932) \nprint(\"XYZ: \", xyz)         \n# XYZ:  XYZColor (xyz_x:0.1280 xyz_y:0.0615 xyz_z:0.2093)\nprint(\"LCH(ab): \", lch_ab)  \n# LCH(ab):  LCHabColor (lch_l:29.7843 lch_c:69.3132 lch_h:328.2310)\nprint(\"LCH(uv): \", lch_uv)  \n# LCH(uv):  LCHuvColor (lch_l:29.7843 lch_c:67.8446 lch_h:307.7154)\nprint(\"HSV: \", hsv)         \n# HSV:  HSVColor (hsv_h:300.0000 hsv_s:1.0000 hsv_v:0.5020)\nprint(\"CMY: \", cmy)         \n# CMY:  CMYColor (cmy_c:0.4980 cmy_m:1.0000 cmy_y:0.4980)\nprint(\"CMYK: \", cmyk)       \n# CMYK:  CMYKColor (cmyk_c:0.0000 cmyk_m:1.0000 cmyk_y:0.0000 cmyk_k:0.4980)\n\n1\n\nAn sRGB color is defined with the red, green, and blue components. If you’re using values in the 0-255 range, set is_upscaled=True so that colormath knows to scale them down to 0-1.\n\n2\n\nThe convert_color function is used to convert the defined sRGB color to the CIELab color space.\n\n3\n\nFinally, the resulting CIELab color is printed out. Other conversions follow.\n\n\nThe output will be the CIELab representation of the given sRGB color. Keep in mind that colormath handles these conversions assuming standard conditions and may not account for specific display or lighting characteristics unless explicitly specified.\n\n\nOther Libraries\nThere are several other libraries in Python and other programming languages that can be used to convert between color spaces. Here are a few notable ones:\n\nOpenCV (Python, C++, Java): Primarily known for its extensive functionalities in computer vision, OpenCV also offers color space conversion functions. It can handle conversions between various color spaces, including RGB, HSV, CIELab, and more.\nPillow (Python): The Pillow library, which is an extension of the Python Imaging Library (PIL), includes functions for converting images between different color spaces.\nColor.js (JavaScript): A JavaScript library for color conversion and manipulation, it supports a wide range of color spaces and is particularly useful for web development.\nD3.js (JavaScript): While primarily a library for producing interactive data visualizations, D3.js also includes methods for color space conversion, useful in the context of web design and visualizations.\nTinycolor (JavaScript): A small, fast library for color manipulation and conversion in JavaScript. It supports RGB, HSV, HSL, and HEX formats.\nColorspacious (Python): A Python library designed to convert and manipulate various color spaces with a focus on perceptual uniformity and color difference calculations.\nMatplotlib (Python): Although mainly a plotting library, Matplotlib in Python can convert colors between RGB and other color spaces as part of its plotting functionalities.\n\nEach of these libraries has its own set of features and strengths, and the choice of library can depend on the specific requirements of your project, such as the programming language you’re using, the color spaces you need to work with, and the level of precision or control you need over the color conversion process."
  },
  {
    "objectID": "posts/colors-101/index.html#code",
    "href": "posts/colors-101/index.html#code",
    "title": "Colors 101",
    "section": "Code",
    "text": "Code\nDownload the Jupyter notebook or open it in Colab (click on the badge below) to sample the CIELab space and get the nearest sample of a given color."
  },
  {
    "objectID": "posts/colors-101/index.html#references",
    "href": "posts/colors-101/index.html#references",
    "title": "Colors 101",
    "section": "References",
    "text": "References\nCIE website: International Commission on Illumination official website\nBruce Justin Lindbloom’s website: useful for color spaces conversion formulas\nJohn the Math Guy’s website: outstanding resource for color theory"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Antonio Montano’s Personal Blog",
    "section": "",
    "text": "Nearest sample\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColors 101\n\n\nAll you ever wanted to know about colors\n\n\n30 min\n\n\n\ntheory\n\n\npython\n\n\nanalysis\n\n\n\nThe evolution of color spaces is a testament to the intersection of art, science, and technology. Each color space has been developed to meet specific needs - from artistic…\n\n\n\nAntonio Montano\n\n\nJan 27, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  }
]