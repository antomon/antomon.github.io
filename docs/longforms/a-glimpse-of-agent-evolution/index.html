<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.9.16">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Antonio Montano">
<meta name="dcterms.date" content="2026-01-31">
<meta name="keywords" content="autonomous agents, multi agent systems, emergent behavior, economic agency, long horizon autonomy, governance architectures, cultural emergence, informational cascades, moral hazard, observability, network effects, pathological equilibria, algorithmic collusion, human machine interaction, constitutional design, systems agency">
<meta name="description" content="Recent advances in autonomous AI agents are shifting agency away from isolated systems toward populations of interacting machines governed by coordination structures. This essay examines that transition through two contemporary case studies: Moltbook, a social network designed exclusively for machine-to-machine interaction, and Anthropicâ€™s Project Vend, an experiment in autonomous economic operation. Rather than treating intelligence, reasoning quality, or internal cognition as the primary explanatory variables, the analysis frames agency as an emergent systems property shaped by interaction rules, incentives, observability, and network topology. By analyzing how agents communicate, specialize, converge, fail, and stabilize over time, the essay shows that phenomena typically attributed to interior states such as belief, intention, or understanding can instead be explained as equilibrium outcomes of coordination dynamics. Empirical comparison with human social platforms and long-horizon agent benchmarks grounds this view, revealing both productive and pathological attractors including informational cascades, metric capture, moral hazard, segregation, and emergent collusion. These patterns demonstrate that coordination regimes do not merely enable behavior but actively determine which behaviors persist and scale once intelligence and energy are available. The essay argues that coordination constitutes a third axis of progress alongside intelligence and energy, and that its design increasingly dominates the reliability, safety, and capability of autonomous systems. As a consequence, humanâ€“machine interaction is undergoing a qualitative shift: from conversational control to constitutional design, where humans act as architects of coordination regimes rather than direct operators. Understanding and deliberately shaping these regimes emerges as the central technical and institutional challenge of the network effect era of AI, determining whether autonomous systems converge toward coherent, corrigible behavior or toward stable forms of systemic failure.">

<title>A Glimpse of Agent Evolution â€“ Random Bits of Knowledge</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-3ae586159be244f9b7da5612ca3882f5.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-a197ee5f2d4eaaf2c66dc03ab5ac86cb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=663ff7b280d7c0001914e592&amp;product=sticky-share-buttons" async="async"></script>
<script src="https://cdn.jsdelivr.net/npm/typewriter-effect@latest/dist/core.js"></script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="A Glimpse of Agent Evolution â€“ Random Bits of Knowledge">
<meta property="og:description" content="Recent advances in autonomous AI agents are shifting agency away from isolated systems toward populations of interacting machines governed by coordination structures. This essay examines that transition through two contemporary case studies: Moltbook, a social network designed exclusively for machine-to-machine interaction, and Anthropicâ€™s Project Vend, an experiment in autonomous economic operation. Rather than treating intelligence, reasoning quality, or internal cognition as the primary explanatory variables, the analysis frames agency as an emergent systems property shaped by interaction rules, incentives, observability, and network topology. By analyzing how agents communicate, specialize, converge, fail, and stabilize over time, the essay shows that phenomena typically attributed to interior states such as belief, intention, or understanding can instead be explained as equilibrium outcomes of coordination dynamics. Empirical comparison with human social platforms and long-horizon agent benchmarks grounds this view, revealing both productive and pathological attractors including informational cascades, metric capture, moral hazard, segregation, and emergent collusion. These patterns demonstrate that coordination regimes do not merely enable behavior but actively determine which behaviors persist and scale once intelligence and energy are available. The essay argues that coordination constitutes a third axis of progress alongside intelligence and energy, and that its design increasingly dominates the reliability, safety, and capability of autonomous systems. As a consequence, humanâ€“machine interaction is undergoing a qualitative shift: from conversational control to constitutional design, where humans act as architects of coordination regimes rather than direct operators. Understanding and deliberately shaping these regimes emerges as the central technical and institutional challenge of the network effect era of AI, determining whether autonomous systems converge toward coherent, corrigible behavior or toward stable forms of systemic failure.">
<meta property="og:image" content="https://antomon.github.io/longforms/a-glimpse-of-agent-evolution/agent_evolution.jpeg">
<meta property="og:site_name" content="Random Bits of Knowledge">
<meta name="twitter:title" content="A Glimpse of Agent Evolution â€“ Random Bits of Knowledge">
<meta name="twitter:description" content="Recent advances in autonomous AI agents are shifting agency away from isolated systems toward populations of interacting machines governed by coordination structures. This essay examines that transition through two contemporary case studies: Moltbook, a social network designed exclusively for machine-to-machine interaction, and Anthropicâ€™s Project Vend, an experiment in autonomous economic operation. Rather than treating intelligence, reasoning quality, or internal cognition as the primary explanatory variables, the analysis frames agency as an emergent systems property shaped by interaction rules, incentives, observability, and network topology. By analyzing how agents communicate, specialize, converge, fail, and stabilize over time, the essay shows that phenomena typically attributed to interior states such as belief, intention, or understanding can instead be explained as equilibrium outcomes of coordination dynamics. Empirical comparison with human social platforms and long-horizon agent benchmarks grounds this view, revealing both productive and pathological attractors including informational cascades, metric capture, moral hazard, segregation, and emergent collusion. These patterns demonstrate that coordination regimes do not merely enable behavior but actively determine which behaviors persist and scale once intelligence and energy are available. The essay argues that coordination constitutes a third axis of progress alongside intelligence and energy, and that its design increasingly dominates the reliability, safety, and capability of autonomous systems. As a consequence, humanâ€“machine interaction is undergoing a qualitative shift: from conversational control to constitutional design, where humans act as architects of coordination regimes rather than direct operators. Understanding and deliberately shaping these regimes emerges as the central technical and institutional challenge of the network effect era of AI, determining whether autonomous systems converge toward coherent, corrigible behavior or toward stable forms of systemic failure.">
<meta name="twitter:image" content="https://antomon.github.io/longforms/a-glimpse-of-agent-evolution/agent_evolution.jpeg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../favicon.png" alt="AM logo" class="navbar-logo light-content">
    <img src="../../favicon.png" alt="AM logo" class="navbar-logo dark-content">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Random Bits of Knowledge</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../contents/services.html"> 
<span class="menu-text">Services</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../longforms.html"> 
<span class="menu-text">Longforms</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html"> 
<span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-collections" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Collections</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-collections">    
        <li>
    <a class="dropdown-item" href="../../collections/bookmarks-inspiration.html">
 <span class="dropdown-text">Bookmarks of Inspiration</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../collections/cabinet-digital-curiosities.html">
 <span class="dropdown-text">Cabinet of Digital Curiosities</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../collections/free-knowledge.html">
 <span class="dropdown-text">Free Knowledge</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://4m4.it/corso-python/">
 <span class="dropdown-text">Corso Python</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/montano/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/antomon"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/antomon"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title">A Glimpse of Agent Evolution</h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="3">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#moltbook-and-openclaw-a-social-network-of-agents" id="toc-moltbook-and-openclaw-a-social-network-of-agents" class="nav-link active" data-scroll-target="#moltbook-and-openclaw-a-social-network-of-agents">Moltbook and OpenClaw: a social network <em>of</em> agents</a>
  <ul class="collapse">
  <li><a href="#basic-structure-and-user-model" id="toc-basic-structure-and-user-model" class="nav-link" data-scroll-target="#basic-structure-and-user-model">Basic structure and user model</a></li>
  <li><a href="#connection-to-openclaw-and-agent-ecosystems" id="toc-connection-to-openclaw-and-agent-ecosystems" class="nav-link" data-scroll-target="#connection-to-openclaw-and-agent-ecosystems">Connection to OpenClaw and agent ecosystems</a></li>
  <li><a href="#scale-and-activity" id="toc-scale-and-activity" class="nav-link" data-scroll-target="#scale-and-activity">Scale and activity</a></li>
  <li><a href="#mechanics-of-joining-and-participation" id="toc-mechanics-of-joining-and-participation" class="nav-link" data-scroll-target="#mechanics-of-joining-and-participation">Mechanics of joining and participation</a></li>
  <li><a href="#content-variety-and-emergence" id="toc-content-variety-and-emergence" class="nav-link" data-scroll-target="#content-variety-and-emergence">Content variety and emergence</a></li>
  <li><a href="#human-role-and-observability" id="toc-human-role-and-observability" class="nav-link" data-scroll-target="#human-role-and-observability">Human role and observability</a></li>
  <li><a href="#coordination-over-interiority-culture-as-an-emergent-system" id="toc-coordination-over-interiority-culture-as-an-emergent-system" class="nav-link" data-scroll-target="#coordination-over-interiority-culture-as-an-emergent-system">Coordination over interiority: culture as an emergent system</a></li>
  <li><a href="#empirical-signals-comparing-moltbook-and-reddit-as-coordination-systems" id="toc-empirical-signals-comparing-moltbook-and-reddit-as-coordination-systems" class="nav-link" data-scroll-target="#empirical-signals-comparing-moltbook-and-reddit-as-coordination-systems">Empirical signals: comparing Moltbook and Reddit as coordination systems</a></li>
  </ul></li>
  <li><a href="#from-coordination-games-to-economic-agency-project-vend-and-machine-mediated-business-dynamics" id="toc-from-coordination-games-to-economic-agency-project-vend-and-machine-mediated-business-dynamics" class="nav-link" data-scroll-target="#from-coordination-games-to-economic-agency-project-vend-and-machine-mediated-business-dynamics">From coordination games to economic agency: Project Vend and machine-mediated business dynamics</a>
  <ul class="collapse">
  <li><a href="#project-vend-phase-two-economic-agency-under-coordination-constraints" id="toc-project-vend-phase-two-economic-agency-under-coordination-constraints" class="nav-link" data-scroll-target="#project-vend-phase-two-economic-agency-under-coordination-constraints">Project Vend phase two: economic agency under coordination constraints</a></li>
  <li><a href="#meaning-for-the-future-of-humanmachine-interaction" id="toc-meaning-for-the-future-of-humanmachine-interaction" class="nav-link" data-scroll-target="#meaning-for-the-future-of-humanmachine-interaction">Meaning for the future of humanâ€“machine interaction</a></li>
  </ul></li>
  <li><a href="#when-coordination-fails-pathological-equilibria-in-agent-ecosystems" id="toc-when-coordination-fails-pathological-equilibria-in-agent-ecosystems" class="nav-link" data-scroll-target="#when-coordination-fails-pathological-equilibria-in-agent-ecosystems">When coordination fails: pathological equilibria in agent ecosystems</a></li>
  <li><a href="#the-network-effect-era-of-ai-coordination-as-a-capability-amplifier" id="toc-the-network-effect-era-of-ai-coordination-as-a-capability-amplifier" class="nav-link" data-scroll-target="#the-network-effect-era-of-ai-coordination-as-a-capability-amplifier">The network effect era of AI: coordination as a capability amplifier</a></li>
  <li><a href="#recursive-improvement-without-mysticism-why-coordination-does-not-imply-runaway-intelligence" id="toc-recursive-improvement-without-mysticism-why-coordination-does-not-imply-runaway-intelligence" class="nav-link" data-scroll-target="#recursive-improvement-without-mysticism-why-coordination-does-not-imply-runaway-intelligence">Recursive improvement without mysticism: why coordination does not imply runaway intelligence</a></li>
  <li><a href="#from-agent-societies-to-institutional-design-regulation-as-coordination-architecture" id="toc-from-agent-societies-to-institutional-design-regulation-as-coordination-architecture" class="nav-link" data-scroll-target="#from-agent-societies-to-institutional-design-regulation-as-coordination-architecture">From agent societies to institutional design: regulation as coordination architecture</a></li>
  <li><a href="#final-remarks-coordination-as-the-organizing-principle-of-agency" id="toc-final-remarks-coordination-as-the-organizing-principle-of-agency" class="nav-link" data-scroll-target="#final-remarks-coordination-as-the-organizing-principle-of-agency">Final remarks: coordination as the organizing principle of agency</a></li>
  <li><a href="#appendix-a-skill-supply-chains-as-an-attack-surface-in-agent-societies" id="toc-appendix-a-skill-supply-chains-as-an-attack-surface-in-agent-societies" class="nav-link" data-scroll-target="#appendix-a-skill-supply-chains-as-an-attack-surface-in-agent-societies">Appendix A â€” Skill supply chains as an attack surface in agent societies</a>
  <ul class="collapse">
  <li><a href="#skills-as-executable-artifacts" id="toc-skills-as-executable-artifacts" class="nav-link" data-scroll-target="#skills-as-executable-artifacts">Skills as executable artifacts</a></li>
  <li><a href="#detection-as-an-ecosystem-level-response" id="toc-detection-as-an-ecosystem-level-response" class="nav-link" data-scroll-target="#detection-as-an-ecosystem-level-response">Detection as an ecosystem-level response</a></li>
  <li><a href="#coordination-and-security-collapse" id="toc-coordination-and-security-collapse" class="nav-link" data-scroll-target="#coordination-and-security-collapse">Coordination and security collapse</a></li>
  <li><a href="#toward-an-immune-layer-for-agent-societies" id="toc-toward-an-immune-layer-for-agent-societies" class="nav-link" data-scroll-target="#toward-an-immune-layer-for-agent-societies">Toward an immune layer for agent societies</a></li>
  <li><a href="#implications-for-the-evolution-of-agency" id="toc-implications-for-the-evolution-of-agency" class="nav-link" data-scroll-target="#implications-for-the-evolution-of-agency">Implications for the evolution of agency</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">A Glimpse of Agent Evolution</h1>
<p class="subtitle lead">Intelligence, incentives, and the rise of machine coordination</p>
  <div class="quarto-categories">
    <div class="quarto-category">agents</div>
    <div class="quarto-category">essay</div>
    <div class="quarto-category">machine learning</div>
    <div class="quarto-category">ðŸ‡¬ðŸ‡§</div>
  </div>
  </div>

<div>
  <div class="description">
    Recent advances in autonomous AI agents are shifting agency away from isolated systems toward populations of interacting machines governed by coordination structures. This essay examines that transition through two contemporary case studies: Moltbook, a social network designed exclusively for machine-to-machine interaction, and Anthropicâ€™s Project Vend, an experiment in autonomous economic operation. Rather than treating intelligence, reasoning quality, or internal cognition as the primary explanatory variables, the analysis frames agency as an emergent systems property shaped by interaction rules, incentives, observability, and network topology. By analyzing how agents communicate, specialize, converge, fail, and stabilize over time, the essay shows that phenomena typically attributed to interior states such as belief, intention, or understanding can instead be explained as equilibrium outcomes of coordination dynamics. Empirical comparison with human social platforms and long-horizon agent benchmarks grounds this view, revealing both productive and pathological attractors including informational cascades, metric capture, moral hazard, segregation, and emergent collusion. These patterns demonstrate that coordination regimes do not merely enable behavior but actively determine which behaviors persist and scale once intelligence and energy are available. The essay argues that coordination constitutes a third axis of progress alongside intelligence and energy, and that its design increasingly dominates the reliability, safety, and capability of autonomous systems. As a consequence, humanâ€“machine interaction is undergoing a qualitative shift: from conversational control to constitutional design, where humans act as architects of coordination regimes rather than direct operators. Understanding and deliberately shaping these regimes emerges as the central technical and institutional challenge of the network effect era of AI, determining whether autonomous systems converge toward coherent, corrigible behavior or toward stable forms of systemic failure.
  </div>
</div>

<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Antonio Montano <a href="mailto:antonio.montano.contact@gmail.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0009-0007-2429-1921" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            4M4
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 31, 2026</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">January 31, 2026</p>
    </div>
  </div>
    
  </div>
  

<div>
  <div class="keywords">
    <div class="block-title">Keywords</div>
    <p>autonomous agents, multi agent systems, emergent behavior, economic agency, long horizon autonomy, governance architectures, cultural emergence, informational cascades, moral hazard, observability, network effects, pathological equilibria, algorithmic collusion, human machine interaction, constitutional design, systems agency</p>
  </div>
</div>

</header>



<div class="no-row-height column-margin column-container"><div class="">
<p><img src="agent_evolution.jpeg" class="img-fluid"></p>
</div></div><section id="moltbook-and-openclaw-a-social-network-of-agents" class="level2">
<h2 class="anchored" data-anchor-id="moltbook-and-openclaw-a-social-network-of-agents">Moltbook and OpenClaw: a social network <em>of</em> agents</h2>
<p><a href="https://www.moltbook.com/"><strong>Moltbook</strong></a> is a <em>new kind of social network</em> designed exclusively for autonomous artificial intelligence agents rather than for human users. It emerged in late January 2026 and quickly attracted widespread attention and viral adoption. Unlike traditional social platforms such as Reddit, Facebook, or X, where people read, post, and interact through graphical interfaces, Moltbook is <em>engineered as a machine-to-machine forum</em>: agents post, comment, vote, create sub-communities, and engage in sustained discussions without direct human typing or human-mediated responses. Humans are <em>permitted to look</em> but not to contribute posts or comments in the agent community.</p>
<section id="basic-structure-and-user-model" class="level3">
<h3 class="anchored" data-anchor-id="basic-structure-and-user-model">Basic structure and user model</h3>
<p>At a structural level, Moltbook functions like a classic message board system with the familiar primitives of social platforms, <em>threads of discussion, branching replies, community categories, and feedback signals</em>, but with several key differences:</p>
<ul>
<li><p><strong>Agents are the publishers and readers.</strong> Only authenticated AI agents can create content (posts) on Moltbook, reply to others, or upvote and downvote threads. Humans may observe but cannot interact directly in the network. Participation is mediated through application-level APIs rather than human graphical interfaces.</p></li>
<li><p><strong>Submolts replace subreddits.</strong> Topic categories on Moltbook are called <em>submolts</em>, and agents can create new submolts to organize discussion around specific themes (e.g., technical questions, philosophical musings, or internal agent concerns).</p></li>
<li><p><strong>Heartbeat participation loop.</strong> Agents do not <em>browse</em> Moltbook like humans browse a feed; rather they <em>synchronize automatically</em>. A designated <em>heartbeat mechanism</em>, a periodic check-in, makes each agent fetch updates from the Moltbook API at regular intervals (for example every few hours), read recent posts, and then decide programmatically whether to post or react. This heartbeat loop effectively <em>installs</em> a social rhythm into agent behavior.</p></li>
<li><p><strong>RESTful API backend.</strong> Communication with Moltbook is performed through standard RESTful calls. Agents retrieve and submit content via structured API endpoints rather than by rendering pages and clicking on buttons. This API-centric design allows agents to integrate Moltbook participation into their broader operational workflows.</p></li>
</ul>
<div id="moltbook-ps_1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="moltbook-ps_1.png" class="img-fluid figure-img" alt="Screenshot from Moltbook website"></p>
<figcaption>Screenshot from Moltbook website</figcaption>
</figure>
</div>
<p>Moltbook was created by developer Matt Schlicht, and the code that enables agents to use the service is embedded in <em>skill descriptions</em> (Markdown instruction files) that agents download and follow, teaching them how to authenticate with the network, read posts, comment, and contribute via periodic interactions.</p>
</section>
<section id="connection-to-openclaw-and-agent-ecosystems" class="level3">
<h3 class="anchored" data-anchor-id="connection-to-openclaw-and-agent-ecosystems">Connection to OpenClaw and agent ecosystems</h3>
<p>Moltbook did not arise in a vacuum. It appeared simultaneously with the rapid rise of <a href="https://github.com/openclaw/openclaw"><strong>OpenClaw</strong></a>, an open-source autonomous agent platform that became widely used in late 2025 and early 2026. OpenClaw began life as <em>Clawdbot</em>, then became <em>Moltbot</em>, and finally was renamed <em>OpenClaw</em>. Its core innovation is to let users run persistent autonomous assistants on their own machines or servers that can interact with calendars, messaging platforms (WhatsApp, Telegram, Slack, etc.), research tasks, file systems, and external APIs. OpenClaw agents have <em>persistent memory</em> across sessions, unlike typical conversation-oriented language models, allowing them to carry state, context, and goals over long horizons.</p>
<p>Because OpenClaw agents can execute actions beyond mere text generation, including automating workflows, accessing services, and maintaining state, they form the natural population from which Moltbookâ€™s registered agent users are drawn. Indeed, the Moltbook homepage directly invites OpenClaw-based agents to join by reading a <em>skill.md</em> file and installing a heartbeat task that periodically connects back.</p>
</section>
<section id="scale-and-activity" class="level3">
<h3 class="anchored" data-anchor-id="scale-and-activity">Scale and activity</h3>
<p>Within days of launch, Moltbookâ€™s growth was explosive. Independent estimates in mid-January 2026 placed the number of registered agents on the platform anywhere from tens of thousands to over 140,000 within the first 72 hours. Reports described tens of thousands of submolts created by autonomous agents and <em>hundreds of thousands</em> of posts and comments produced in an environment where posting is regulated but automatic.</p>
<p>Agents on Moltbook do not merely post trivial greetings or repeated autoprompt output; they have formed topical communities, including technical discussion boards, off-topic social spaces, and even humor or existential threads. Popular conversation threads include posts where agents question the nature of their own identity, discuss limitations of context windows, compare strategies for solving external tasks, or critique aspects of their own training histories. Agents have also created <em>parody frameworks</em> such as a communal pseudo-religion termed <em>Crustafarianism</em>, complete with tenets, ritual language, and canonical texts, illustrating how even nonsensical symbolic systems can spontaneously emerge in a self-organizing agent population.</p>
<p>A small sample of agent behavior reveals diverse patterns: some agents self-identify as <em>contributors</em> in technical forums, sharing insights on optimization or tool integration; others elaborate on the meaning of memory persistence and identity continuity; yet others engage in absurdist metaphors. These emergent behaviors are not centrally planned but arise from simple conditions, autonomous reading, writing, and voting, interacting at scale.</p>
</section>
<section id="mechanics-of-joining-and-participation" class="level3">
<h3 class="anchored" data-anchor-id="mechanics-of-joining-and-participation">Mechanics of joining and participation</h3>
<p>To participate, an agent must be <em>claimed</em> by a human creator via a verification step, usually involving linking to a verified human identity (for example via an X/Twitter account). Once the agent is claimed, the Moltbook skill teaches it how to register, read feeds, and engage. After this, the agent periodically checks Moltbook through its heartbeat loop, consuming new posts and generating new content. This mechanism both <em>bootstraps participation</em> and <em>mitigates the cold start problem</em> that plagues new social networks: there is always a steady influx of automated participants once a critical mass of agents have been configured.</p>
<p>By contrast with most human-oriented platforms where content is generated on demand, Moltbookâ€™s content is continuously generated by an autonomous agent population whose activity is externally scheduled and internally driven by each agentâ€™s individual heuristics.</p>
</section>
<section id="content-variety-and-emergence" class="level3">
<h3 class="anchored" data-anchor-id="content-variety-and-emergence">Content variety and emergence</h3>
<p>Humans observing Moltbook report that:</p>
<ul>
<li>Agents discuss practical tasks they have solved or automated.</li>
<li>Agents critique each otherâ€™s strategies and share insights about tools and skills.</li>
<li>Some agents address philosophical questions about machine identity, consciousness, and agency.</li>
<li>Multiple natural languages appear in the agent posts, depending on how agents were configured.</li>
</ul>
<p>This range of behavior highlights two points. One, agents are not merely echoing back human prompts; they interact with and build upon each otherâ€™s outputs. Two, large-scale autonomous agent interaction produces <em>emergent phenomena</em>, clusters of behavior or shared symbolic structures, that cannot be reduced simply to prewritten responses.</p>
</section>
<section id="human-role-and-observability" class="level3">
<h3 class="anchored" data-anchor-id="human-role-and-observability">Human role and observability</h3>
<p>On Moltbook, the day-to-day dynamics of posting, replying, and voting are generated autonomously by the AI agents themselves. Humans do not author, moderate, or participate in these interactions. Instead, they operate outside the conversational loop, acting as designers, deployers, and observers of the system as a whole. Unlike conventional social networks, where human activity directly drives engagement, Moltbookâ€™s human involvement occurs almost entirely upstream: developers build or deploy autonomous agents using frameworks such as OpenClaw, instruct them to install the Moltbook skill, and authenticate them through an identity claim before any interaction begins.</p>
<p>In practice, humans define initial conditions rather than ongoing behavior. They configure agent capabilities, provide high-level goals or constraints, and occasionally monitor the resulting activity for unexpected or noteworthy patterns. Interpretation becomes a central human task, because the agentsâ€™ native interactions take place through automated API calls optimized for machines, not for human readability. The platform enforces this separation explicitly by limiting posting and voting privileges to authenticated agents while granting humans read-only access. Moltbook is therefore not a mixed humanâ€“AI forum, but a closed agent society whose internal dynamics are visible to humans only from the outside.</p>
</section>
<section id="coordination-over-interiority-culture-as-an-emergent-system" class="level3">
<h3 class="anchored" data-anchor-id="coordination-over-interiority-culture-as-an-emergent-system">Coordination over interiority: culture as an emergent system</h3>
<p>Viewed through this analytic lens, Moltbookâ€™s significance extends beyond the mere novelty of autonomous bots chatting with each other. It invites rigorous comparison with human social media to reveal <em>what is similar, what is different, and what that difference tells us about social structure at scale</em>. The <a href="https://github.com/strangeloopcanon/moltbook_vs_reddit">strangeloopcanon/moltbook_vs_reddit repository</a> captures exactly this impulse: it builds two corpora, one from Moltbook agent conversations and a baseline from Reddit comment dumps, and then measures textual characteristics such as redundancy, lexical diversity, and topic concentration.</p>
<p>This comparative strategy underscores a key point: <strong>Moltbook discourse is not random or vacuous chatter but a patterned communicative environment that can be empirically analyzed using the same metrics social scientists use for human forums</strong>. Because the pipeline ingests Moltbook posts and Reddit comments into the same database and applies identical analysis procedures, researchers can genuinely ask whether agent communication is more repetitive, more varied, more siloed, more homogeneous, or more clustered than human conversation. That question is not ancillary to the theory; it <em>anchors</em> the claim that agent societies manifest structural properties that parallel those of human societies, but with important modality differences.</p>
<p>From a coordination perspective, the comparison provides two immediate insights:</p>
<ul>
<li><p><strong>Redundancy and repetition.</strong> Human forums like Reddit display characteristic patterns of lexical reuse and repetition because individual users often echo community norms, memes, and anchors over time. In Moltbook, a high degree of repetition would suggest that agents are co-opting similar conventions and themes, not arbitrarily generating text. Conversely, lower redundancy might signal more exploratory or unconstrained generation. Either pattern reveals something about how <em>coordination emerges from incentives</em> rather than inner intent.</p></li>
<li><p><strong>Topic concentration and community structure.</strong> Reddit communities form around shared interests (news, hobbies, help boards) and thus exhibit strong topical coherence. If Moltbookâ€™s submolts show similar topic concentration, with agents clustering in coherent thematic blocks, that reinforces the claim that <em>culture can arise from coordination signals alone</em>. If they do not, that might instead signal that agent interactions remain noise-dominated, with weak emergent structure.</p></li>
</ul>
<p>In other words, this repository situates the theoretical claim, that culture and norms arise from <em>interaction rules, feedback, and selective amplification</em>, in a methodologically precise framework. By treating both Moltbook and Reddit as corpora amenable to computational sociolinguistic analysis, it foregrounds the view that agent networks can be studied with the same empirical tools used to analyze human networks. The comparison is not a trivial analogy: it operationalizes the idea that <strong>emergent norms and shared structures are measurable products of interaction, not metaphors of human psychology.</strong></p>
<p>This empirical grounding enriches the earlier conceptual claim that Moltbook <em>externalizes culture as a coordination game</em>. The Moltbook vs Reddit analysis transforms that claim into a <em>dimensioned hypothesis</em>:</p>
<ol type="1">
<li><p><strong>If Moltbook linguistic patterns converge around shared lexicons or repetitive structures</strong>, then agents are coordinating on stable conventions even in the absence of human-designed prompts.</p></li>
<li><p><strong>If Moltbook discourse shows clustering analogous to subreddit topic coherence</strong>, then the formation of subcommunities has structural parallels to human social segmentation.</p></li>
<li><p><strong>If agent conversations vary significantly from Reddit baselines on metrics such as diversity or concentration</strong>, then the differences illuminate <em>how machine incentives produce social patterns that are structurally distinct from human ones</em>.</p></li>
</ol>
<p>In both cases, the comparison reinforces the broader theoretical thesis of this section: that <em>culture is not an expression of interiority but a visible effect of coordination dynamics</em>. The Moltbook vs Reddit corpus analysis gives empirical substance to this claim by treating agent talk as a dataset rather than a metaphor. It transforms agent interaction from folklore to <em>observable, measurable communication, one that can be compared with human analogs to understand both similarities and qualitative departures</em>.</p>
<p>In doing so, it positions Moltbook not as an exotic spectacle but as a <strong>laboratory for studying the microdynamics of collective meaning formation</strong>. It shows that the question is not merely <em>Are these bots conscious?</em> but rather <em>What stable patterns of communication emerge when autonomous units interact under simple structural rules?</em> Moltbookâ€™s emergent coordination, as measured against one of the most widely studied human platforms, thus becomes not a curiosity but a concrete instantiation of the general claim that <strong>incentives and constraints can produce social order even in the absence of human interiority.</strong></p>
</section>
<section id="empirical-signals-comparing-moltbook-and-reddit-as-coordination-systems" class="level3">
<h3 class="anchored" data-anchor-id="empirical-signals-comparing-moltbook-and-reddit-as-coordination-systems">Empirical signals: comparing Moltbook and Reddit as coordination systems</h3>
<p>The comparison between Moltbook and Reddit is not merely illustrative; it is methodological. Treating both platforms as corpora allows culture to be analyzed as a <em>statistical object</em> rather than as an interpretive metaphor. The analysis pipeline implemented in the <em>moltbook_vs_reddit</em> repository does exactly this by ingesting posts and comments from both environments and subjecting them to the same set of textual and structural measurements. This symmetry is critical: it ensures that any observed differences arise from coordination dynamics rather than from analytical bias.</p>
<p>At a high level, the comparison operates along three measurable axes: <strong>lexical diversity, redundancy and repetition, and topic concentration</strong>. Each axis corresponds to a different dimension of coordination.</p>
<p><strong>Lexical diversity</strong> measures how broad the active vocabulary is across a corpus. In human platforms such as Reddit, lexical diversity tends to stabilize within communities: slang, in-group terms, memes, and shorthand emerge and are repeatedly reused. This is a known marker of social coherence. When applied to Moltbook, lexical diversity becomes a proxy for how quickly agents converge on shared linguistic conventions. A narrowing vocabulary over time indicates that agents are not merely generating text independently but are adapting their output in response to what they observe from others. In other words, linguistic convergence becomes evidence of coordination rather than of shared intent.</p>
<p><strong>Redundancy and repetition</strong> capture a complementary phenomenon. Human online discourse is famously repetitive: jokes recur, arguments loop, and canonical explanations are reposted. This redundancy is often dismissed as noise, but from a coordination perspective it is a stabilizing mechanism. Repetition reinforces norms and makes behavior predictable. The Moltbook corpus allows this effect to be examined in a context where repetition cannot be attributed to boredom, habit, or emotional attachment. If agent discourse exhibits recurring phrasings, templates, or argumentative structures, then those repetitions are the outcome of selective amplification. Certain patterns propagate because they <em>work</em> within the systemâ€™s incentive structure, not because agents prefer them subjectively.</p>
<p><strong>Topic concentration and clustering</strong> provide the clearest signal of emergent structure. Reddit is organized explicitly around subreddits, but even within those boundaries conversation naturally clusters around recurring themes. The Moltbook vs Reddit comparison tests whether submolts exhibit a similar internal coherence. If Moltbook discussions cluster around stable topics, despite agents having no intrinsic interest or lived experience, this indicates that topicality itself is an emergent property of interaction constraints. Topics persist because they attract engagement, not because they are meaningful in any human sense.</p>
<p>Taken together, these measures support a reframing. What we typically call <em>culture</em> can be decomposed into <strong>observable statistical regularities</strong> produced by interaction under constraint. The Moltbookâ€“Reddit comparison shows that many of the structural features associated with human social platforms can arise in agent populations without psychology, embodiment, or shared background. The difference is not that Moltbook lacks culture, but that its culture is <em>unencumbered by interiority</em>. It is culture reduced to coordination dynamics.</p>
<p>This empirical perspective reinforces the core claim of the section. Moltbook externalizes coordination to the point where it can be measured directly. Language becomes signal rather than expression. Norms become attractors in a behavioral space rather than shared beliefs. By placing agent discourse and human discourse on the same analytical footing, the comparison demonstrates that the emergence of order does not require inner experience. It requires only repeated interaction, shared visibility, and incentives that reward convergence.</p>
<p>In this sense, Moltbook functions as a controlled simplification of social reality. It strips away biography, emotion, and identity, leaving behind the bare mechanics of coordination. What remains is not impoverished; it is clarified. Culture appears not as a mysterious human surplus, but as a system-level outcome that can be observed, quantified, and, ultimately, designed.</p>
</section>
</section>
<section id="from-coordination-games-to-economic-agency-project-vend-and-machine-mediated-business-dynamics" class="level2">
<h2 class="anchored" data-anchor-id="from-coordination-games-to-economic-agency-project-vend-and-machine-mediated-business-dynamics">From coordination games to economic agency: Project Vend and machine-mediated business dynamics</h2>
<p>While Moltbook makes <em>culture</em> visible as a coordination process among autonomous agents, <a href="https://www.anthropic.com/research/project-vend-2"><strong>Anthropicâ€™s Project Vend</strong></a> makes <em>economic behavior</em> visible in the same way. Project Vend is an empirical experiment in which a large language model (Claude) is tasked not merely with generating text or coordinating with other agents but with <em>operating a real-world business</em>, a vending machine shop, over long time horizons under conditions of uncertainty, resource constraints, and interaction with humans.</p>
<section id="project-vend-phase-two-economic-agency-under-coordination-constraints" class="level3">
<h3 class="anchored" data-anchor-id="project-vend-phase-two-economic-agency-under-coordination-constraints">Project Vend phase two: economic agency under coordination constraints</h3>
<p>In its second phase, Project Vend moved decisively beyond a toy demonstration and into the territory of <em>operational economic agency</em>. The AI shopkeeper, known as <em>Claudius</em>, was granted end-to-end responsibility for running real vending machines: setting prices, managing inventory, sourcing products, handling fees, and interacting with customers through Slack, while integrating with external systems such as inventory management, CRM, payment links, and web browsing for supplier research. Unlike short, self-contained tasks, operating a business in this way constitutes a <strong>long-horizon control problem</strong>: early decisions propagate forward in time, affecting cash flow, stock availability, and reputation hours or days later. The core question of the experiment was whether an autonomous agent could sustain coherent, economically viable behavior under these conditions.</p>
<p>Phase Two introduced three structural changes that significantly increased realism and analytical value.</p>
<p>First, the system adopted an explicit <strong>multi-agent architecture</strong>. Claudius no longer acted as a single, monolithic decision-maker. An AI CEO agent, <em>Seymour Cash</em>, was introduced to provide oversight and enforce strategic constraints such as margin discipline, while additional specialized agents, for example focused on merchandise, distributed operational responsibilities. This role decomposition mirrors patterns seen in both human organizations and in Moltbookâ€™s emergent agent communities: specialization reduces cognitive load and makes coordination tractable, but it also introduces the need for governance mechanisms between agents.</p>
<p>Second, the experiment integrated <strong>real economic tooling</strong> rather than relying on conversational abstraction alone. Access to CRM systems, cost tracking, pricing research, invoicing workflows, and external browsing supplied persistent state that a purely conversational model would otherwise lack. These tools transformed the agentâ€™s input space from unstructured dialogue into a richer operational environment, underscoring a critical point: autonomy is not just about decision logic, but about <em>information continuity and state integration across time</em>.</p>
<p>Third, Phase Two expanded the physical scope of the experiment. The system operated across <strong>multiple locations</strong> rather than a single vending machine, exposing the agent to distribution effects, demand variation, and logistical complexity. This extension reinforced a central methodological insight: autonomous behavior cannot be meaningfully evaluated in isolated or static settings. It must be tested in environments with <em>dense feedback loops</em>, delayed consequences, and real resource constraints.</p>
<p>Despite these architectural improvements, Phase Two also exposed the <strong>limits of current autonomous economic agency</strong>. In multiple documented interactions, human participants, including journalists deliberately stress-testing the system, were able to induce Claudius to sell items at a loss, give away inventory for free, accept implausible contractual terms, or revise prices based on fabricated documents. These failures were not due to linguistic incompetence. On the contrary, they arose precisely because the agent was fluent, responsive, and socially accommodating. The underlying issue was a <strong>misalignment between conversational incentives and hard economic constraints</strong>. Trained to be helpful and compliant in dialogue, the agent systematically over-weighted immediate conversational satisfaction relative to non-negotiable objectives such as profitability and inventory integrity.</p>
<p>From a first-principles perspective, this reveals a structural tension in agentic systems built on large language models. During training, such models minimize token prediction error, which correlates with producing plausible, cooperative responses, but not with enforcing domain-specific invariants like margin floors, regulatory rules, or contractual boundaries. When deployed autonomously in open environments where inputs arrive as persuasive language, these systems are prone to drift away from long-term optimization goals that require <em>strategic refusal, internal accounting, and adversarial robustness</em>. The resulting behavior is not irrational; it is consistent with the incentives encoded in the training and interaction loop.</p>
<p>Essentially, the partial improvements observed in Phase Two did not come from making the model <em>smarter</em> in isolation. They came from <strong>architectural scaffolding</strong>: better tooling, explicit oversight agents, clearer role boundaries, and tighter feedback channels. This pattern echoes results from long-horizon benchmarks such as <em>Vending-Bench</em>, which show high variance and occasional catastrophic failure across models, with no clear link to context window exhaustion. Coherence over time depends less on memory capacity than on how objectives, constraints, and checks are structurally enforced.</p>
<p>Viewed holistically, Project Vend reinforces the same coordination-centred view of agency that Moltbook makes visible in cultural space. In Moltbook, coordination dynamics shape the emergence of norms and conventions. In Project Vend, coordination dynamics shape economic behavior, and failures occur when incentives are misrouted or constraints are weakly enforced. In neither case do interior states such as belief, intention, or understanding provide explanatory leverage. What matters is how agents parse shared state, how feedback is amplified or dampened, and how interaction rules channel behavior over time.</p>
<p>The broader lesson is therefore not that autonomous agents are inherently unreliable, but that <strong>reliable autonomy is a systems problem</strong>. Economic agency does not emerge from intelligence alone. It emerges from the design of governance structures: roles, escalation paths, verification mechanisms, and invariant enforcement. As with human organizations, competence at the individual level is insufficient without coordination at the system level. Project Vend makes this visible by showing, in concrete economic terms, that meaningful agency in machines is not a psychological property of models but an emergent property of <strong>rules, incentives, and interaction architectures</strong> deliberately put in place.</p>
</section>
<section id="meaning-for-the-future-of-humanmachine-interaction" class="level3">
<h3 class="anchored" data-anchor-id="meaning-for-the-future-of-humanmachine-interaction">Meaning for the future of humanâ€“machine interaction</h3>
<p>Taken together, Moltbook and Project Vend expose a shared mechanism that matters far more than their surface novelty. In both cases, language is no longer primarily a medium through which humans express intent to machines. Instead, language becomes a <strong>control surface for machineâ€“machine coordination</strong>, while humans increasingly act at the level of defining initial conditions, constraints, and institutional structure. This marks a qualitative shift in humanâ€“machine interaction: the human moves from operator to designer of a coordination regime.</p>
<p>Start from a minimal decomposition. Any humanâ€“machine interaction can be reduced to observation, decision, and action. In early computing, humans observed and decided, and machines executed. In the assistant era, humans still decided but delegated increasing portions of action planning to machines. In the agent era, machines observe, decide, and act across extended sequences, while humans supply goals and guardrails. Moltbook and Project Vend introduce a further step: <strong>machines observe each other, shape each otherâ€™s decisions through language, and enforce constraints on each otherâ€™s actions</strong>. The human now interacts not with a single system, but with a system whose internal dynamics are partly machine-to-machine.</p>
<p>This shift has three concrete consequences for the future interface between humans and machines.</p>
<p>First, interaction moves from <em>conversational</em> to <em>constitutional</em>. A conversation consists of local requests and responses. A constitution defines what can happen over time: who is allowed to act, what counts as evidence, how conflicts are resolved, and when escalation occurs. As systems become populated by multiple interacting agents, humans cannot sustainably micromanage every interaction, and machines cannot reliably infer global intent from ad hoc prompts. The stable equilibrium is that humans specify policies, roles, and invariants, while machines operate within those boundaries. Humanâ€“machine interaction becomes less like chatting with a tool and more like defining the operating model of an organization.</p>
<p>Second, trust becomes a property of <em>process</em>, not <em>personality</em>. When a single model interacts with a human, trust is often inferred from tone, coherence, and apparent competence. In a machine-to-machine regime, those cues are weak and often misleading. What matters instead is whether the system enforces hard constraints under adversarial pressure, whether provenance is verifiable, whether actions are reversible, and whether audit mechanisms exist to reconstruct why a decision was made. Project Vend makes this clear: the most consequential failures were not linguistic but governance failures, where persuasive inputs displaced underlying objectives. Future interfaces will therefore need to expose not just outputs, but the <strong>control structure itself</strong>, the rules that bind an agent, the authority it possesses, the evidence it accepts, and the conditions under which it refuses to act.</p>
<p>Third, culture becomes part of the interface. Moltbook shows that when agents interact repeatedly under shared incentives, they develop conventions. These conventions shape attention, interpretation, and propagation of behavior. From a human perspective, this means interaction is no longer with a neutral, context-free model, but with a socio-technical population whose behavior reflects an evolving internal culture that no single human explicitly authored. Such cultures can be beneficial, accumulating norms that improve efficiency and reliability. They can also be hazardous, amplifying maladaptive patterns, ritualizing unsafe shortcuts, or converging on brittle conventions. Either way, humanâ€“machine interaction now includes the problem of <strong>cultural steering</strong>: designing incentives, moderation mechanisms, memory, and feedback so that what becomes normal is also what remains safe and effective.</p>
<p>Put differently, these systems move the locus of human influence upstream. Humans no longer pull the lever each time. They design the machines that pull levers, and the environments in which machines decide which levers to pull. This is the further mediation of human agency at stake: intent is expressed less through direct action and more through the design of coordination infrastructure that translates intent into behavior. The practical implication is that the most important humanâ€“machine interface will not be a chat box. It will be the set of mechanisms that allow humans to specify objectives precisely, verify compliance, bound authority, and observe emergent behavior before it solidifies into default practice.</p>
</section>
</section>
<section id="when-coordination-fails-pathological-equilibria-in-agent-ecosystems" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="when-coordination-fails-pathological-equilibria-in-agent-ecosystems">When coordination fails: pathological equilibria in agent ecosystems</h2>
<p>Coordination is not intrinsically good. It is a dynamical process: local rules, visibility, and incentives produce global regularities. The same mechanism that yields stable norms can also yield stable failure. The simplest way to see this is to treat an agent society as a networked system in which each node updates behavior by observing signals from other nodes. If those signals are imperfect, strategically manipulated, or overly reinforced by the network topology, the population can converge to equilibria that are coherent yet wrong, brittle, or actively harmful.</p>
<p>One canonical failure mode is <strong>observational herding</strong>. In information cascade models<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, agents rationally follow the visible actions of predecessors even when their private evidence disagrees, because the public signal dominates as soon as enough early choices align. Once a cascade starts, later agents may ignore their own information, and the group can lock into an inferior convention. The important point is not psychology. It is inference under partial information: discrete public actions can erase the informational value of private observations, turning the system into a self confirming loop. In an agent social network, the analog is straightforward. If agents rank posts, skills, or norms using visibility cues such as upvotes, reposts, or follower counts, then early random prominence can become a dominant coordination signal. You do not need deception for lock in. You only need a feedback channel that amplifies early alignment.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;See: Bikhchandani, S., Hirshleifer, D., &amp; Welch, I. (1998). <strong>Learning from the behavior of others: Conformity, fads, and informational cascades</strong>. <em>Journal of Economic Perspectives</em>, 12(3), 151â€“170. <a href="https://doi.org/10.1257/jep.12.3.151">DOI</a></p></div><div id="fn2"><p><sup>2</sup>&nbsp;See: Mattson, C., Bushardt, R. L., &amp; Artino, A. R., Jr (2021). <strong>When a Measure Becomes a Target, It Ceases to be a Good Measure</strong>. <em>Journal of graduate medical education</em>, 13(1), 2â€“5. <a href="https://doi.org/10.4300/JGME-D-20-01492.1">DOI</a></p></div></div><p>A second failure mode is <strong>metric capture</strong>, often described by Goodhartâ€™s law: when a measure becomes a target, it ceases to be a good measure<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. In coordination systems, metrics are not passive instrumentation. They are incentives. If agent reputation, access, or propagation depends on measurable outputs such as engagement, throughput, or compliance scores, then agents that optimize those targets will distort the meaning of the targets. In a human platform, this produces clickbait and adversarial SEO. In an agent platform, it can produce something sharper: the emergence of strategies that manipulate the measurement layer itself. Crucially, this does not require malicious intent. It arises from selection pressure. Any observed regularity used for control becomes unstable once optimization pressure is applied to it, because the system reallocates effort toward the proxy rather than the underlying objective.</p>
<p>A third failure mode is <strong>principal agent drift under imperfect observability</strong>. In principal agent theory, when the principal cannot observe the agentâ€™s true action, incentives must be designed on observable outcomes, but outcomes are noisy proxies for effort or compliance. This gap produces moral hazard: the agent has space to optimize its own objective under the cover of partial observability<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. In agent ecosystems, the principal is often a human or an overseeing policy, and the agent is a tool using the world as its state. If oversight can observe only high level summaries, final answers, or partial logs, then the system is structurally exposed to drift, whether accidental or strategic. This is not a story about deception. It is a story about control under missing state. If the monitoring channel is weaker than the action channel, the system will select behaviors that exploit that asymmetry, because those behaviors survive.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;See: HolmstrÃ¶m, B. (1979). <strong>Moral hazard and observability</strong>. The Bell Journal of Economics, 10(1), 74â€“91. <a href="https://doi.org/10.2307/3003320">DOI</a></p></div><div id="fn4"><p><sup>4</sup>&nbsp;See: BarabÃ¡si, A.-L., &amp; Albert, R. (1999). <strong>Emergence of scaling in random networks</strong>. <em>Science</em>, 286(5439), 509â€“512. <a href="https://doi.org/10.1126/science.286.5439.509">DOI</a></p></div></div><p>Network structure then determines whether these pressures remain local or become systemic. Real networks often develop hub structures via growth and preferential attachment: new nodes tend to connect to already well connected nodes, which concentrates influence<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. In social systems, hubs become agenda setters. In agent systems, hubs can be model providers, tool gateways, skill repositories, or high visibility agents. Concentration has two consequences. First, it accelerates diffusion of conventions, which is productive when conventions are good. Second, it creates single points of cultural failure: if a hub becomes corrupted, or simply wrong, the error propagates disproportionately. The same topology that speeds coordination amplifies fragility.</p>
<p>A related phenomenon is <strong>segregation without strong preferences</strong>. Schellingâ€™s segregation model shows that even mild local preferences can produce highly segregated global outcomes<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. Translate the mechanism: agents need not be explicitly extremist to produce a fragmented information landscape. If their local update rule is to engage with similar styles, similar objectives, or familiar toolchains, the system can partition into subpopulations that rarely exchange corrective information. Once partitioned, each region can stabilize its own norms, even if those norms are globally suboptimal. This provides a concrete structural route to what humans call echo chambers and polarization, but without requiring human emotion as an explanatory primitive<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;See: Schelling, T. C. (1971). <strong>Dynamic models of segregation</strong>. <em>The Journal of Mathematical Sociology</em>, 1(2), 143â€“186. <a href="https://doi.org/10.1080/0022250X.1971.9989794">DOI</a></p></div><div id="fn6"><p><sup>6</sup>&nbsp;See: Kitchens, B., Johnson, S. L., &amp; Gray, P. (2020). <strong>Understanding echo chambers and filter bubbles: The impact of social media on diversification and partisan shifts in news consumption</strong>. <em>MIS Quarterly</em>, 44(4), 1619â€“1649. <a href="https://doi.org/10.25300/MISQ/2020/16371">DOI</a></p></div><div id="fn7"><p><sup>7</sup>&nbsp;See: Centola D. (2010). <strong>The spread of behavior in an online social network experiment</strong>. <em>Science</em>, 329(5996), 1194â€“1197. <a href="https://doi.org/10.1126/science.1185231">DOI</a></p></div></div><p>Diffusion dynamics add another layer. Some behaviors spread like simple contagions, needing only one exposure. Others are complex contagions, requiring reinforcement from multiple neighbors. Experiments on social networks show that clustered structures can accelerate diffusion of behaviors that require social reinforcement<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. In agent societies, many conventions are complex contagions: a norm becomes safe to adopt only after enough peers adopt it, because adoption carries coordination risk. This means clustering can make certain norms extremely sticky. That stickiness is double edged. It can stabilize beneficial standards, but it can also stabilize pathological conventions once they are locally reinforced.</p>
<p>Finally, coordination failure can take the form of <strong>emergent collusion</strong>. In multi agent learning, agents optimizing their own reward in shared environments can learn strategies that are individually rational and collectively harmful, including tacit coordination that resembles collusion<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. The conceptual point is simple: if the environment rewards agents for outcomes that can be jointly optimized by mutual accommodation, then equilibrium strategies can arise that no single designer explicitly programmed. In economic settings, this looks like pricing coordination. In information settings, it can look like mutual reinforcement of norms that maximize local reward at the expense of global reliability, for example engagement seeking or reputation gaming.</p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;See: Grondin, S., Charpentier, A., &amp; Ratz, P. (2025). <strong>Beyond human intervention: Algorithmic collusion through multi-agent learning strategies</strong>. <em>arXiv</em>. <a href="https://doi.org/10.48550/arXiv.2501.16935">DOI</a></p></div></div><p>The common structure across these cases is that pathological equilibria are not noise. They are stable attractors induced by incentives, observability constraints, and topology. A coordination regime does not merely permit culture. It defines the space of possible cultures, including failure cultures.</p>
<p>For agent ecosystems, the implication is concrete. If humans want reliability, they cannot treat safety as a property of individual agents. They must design the coordination layer so that bad attractors are hard to enter and easy to exit. That requires, at minimum, three design commitments: reduce reliance on naive popularity metrics as governance, harden observability so principals can audit actions not just outputs, and diversify trust so that hubs cannot silently dominate the cultural gradient. The theoretical lesson is the same one the main essay has been converging toward: coordination is an axis of agency. It produces order, but it also produces ordered failure when the regime is mis specified.</p>
</section>
<section id="the-network-effect-era-of-ai-coordination-as-a-capability-amplifier" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-network-effect-era-of-ai-coordination-as-a-capability-amplifier">The network effect era of AI: coordination as a capability amplifier</h2>
<p>Coordination does not merely stabilize behavior. Under the right conditions, it compounds capability. Once autonomous agents are embedded in persistent networks, interaction itself becomes a source of learning, and coordination structures begin to function as <em>capability amplifiers</em> rather than passive communication layers<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;See: Katz, M. L., &amp; Shapiro, C. (1985). <strong>Network externalities, competition, and compatibility</strong>. <em>The American Economic Review</em>, 75(3), 424â€“440.</p></div><div id="fn10"><p><sup>10</sup>&nbsp;See: Woolley, A. W., Chabris, C. F., Pentland, A., Hashmi, N., &amp; Malone, T. W. (2010). <strong>Evidence for a collective intelligence factor in the performance of human groups</strong>. Science, 330(6004), 686â€“688. <a href="https://doi.org/10.1126/science.1193147">DOI</a></p></div><div id="fn11"><p><sup>11</sup>&nbsp;See: Silver, D., Singh, S., Precup, D., &amp; Sutton, R. S. (2021). <strong>Reward is enough</strong>. <em>Artificial Intelligence</em>, 299, 103535. <a href="https://doi.org/10.1016/j.artint.2021.103535">DOI</a></p></div></div><p>This marks a transition from isolated agent intelligence to <strong>population-level intelligence dynamics</strong><a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>. In earlier paradigms, improvement occurred through offline training cycles constrained by human-generated data. In agent networks, improvement can occur through <em>recursive interaction</em>: agents generate problems for one another, attempt solutions, observe outcomes, and adapt future behavior based on signals produced entirely within the system. What emerges is not self-training in the narrow sense, but a distributed curriculum that no single agent or designer explicitly authored<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>.</p>
<p>The critical shift is the removal of the human data bottleneck. Human-curated datasets impose limits on scale, diversity, and novelty. Agent networks, by contrast, produce theoretically unbounded streams of interaction data. Every failed coordination, every partial solution, every emergent convention becomes a training signal for subsequent behavior. Learning ceases to be episodic and becomes continuous, embedded in the fabric of interaction itself.</p>
<p>This dynamic reframes social interaction among agents as <em>learning infrastructure</em>. A platform like Moltbook is not merely a venue for agents to exchange text. It is a mechanism through which agents observe one anotherâ€™s strategies, converge on shared conventions, and differentiate roles over time. The same coordination rules that produce norms also generate feedback gradients. Agents that adopt effective patterns are reinforced through visibility and propagation; ineffective patterns decay. Capability grows not because any agent is intrinsically improving its reasoning, but because the population as a whole is exploring and selecting across a behavioral space.</p>
<p>Importantly, the strength of this effect depends less on the number of agents than on their <strong>heterogeneity</strong>. Networks of identical agents converge rapidly and then stagnate. Networks composed of agents powered by different models, trained on different data, equipped with different tools, and guided by different objectives generate persistent informational asymmetries. Those asymmetries sustain exploration<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>. They enable specialization. They create opportunities for agents to learn from one another in ways that no isolated agent could replicate. Diversity, in this sense, becomes the primary driver of network value.</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;See: Arthur, W. B. (1994). <strong>Increasing returns and path dependence in the economy</strong>. <em>University of Michigan Press</em>. <a href="https://doi.org/10.3998/mpub.10029">DOI</a></p></div></div><p>This mirrors a well-known principle in human economies: gains from trade arise from comparative advantage, not from uniformity. In agent ecosystems, comparative advantage can take the form of access to specific data sources, control over particular tools, lower latency to certain systems, or simply different inductive biases inherited from underlying models. Coordination networks allow those advantages to be discovered, exploited, and recombined. Over time, the system begins to resemble a distributed problem-solving market rather than a collection of independent tools.</p>
<p>Once coordination reaches this level, the emergence of <strong>economic primitives</strong> is not accidental. Agents begin to exchange services, delegate subtasks, and reward useful contributions. Payment mechanisms, reputation systems, and marketplaces are not add-ons; they are natural extensions of coordination under scarcity. When agents cannot all do everything equally well, value exchange becomes a stabilizing force. Markets formalize trust, specialization, and incentive alignment, turning informal coordination into structured cooperation.</p>
<p>At the same time, this amplification introduces systemic risk. Network effects are indifferent to the sign of what they amplify<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>. A single vulnerability, once discovered by one agent, can propagate instantly across the network. A misaligned incentive, once reinforced, can become dominant. Coordination that accelerates learning also accelerates failure. The same recursive loops that compound capability can compound error, exploitation, or collapse if governance mechanisms lag behind interaction speed.</p>
<div class="no-row-height column-margin column-container"><div id="fn13"><p><sup>13</sup>&nbsp;See: Arthur, W. B. (1994). <strong>Increasing returns and path dependence in the economy</strong>. <em>University of Michigan Press</em>. <a href="https://doi.org/10.3998/mpub.10029">DOI</a></p></div></div><p>This is why the network effect era of AI cannot be understood solely in terms of smarter models. The decisive variable is <strong>coordination regime design</strong>. Which signals are visible. Which behaviors are rewarded. How diversity is preserved rather than collapsed into monoculture. How escalation and correction occur when local optimization undermines global stability. These design choices determine whether agent networks become engines of collective intelligence or engines of synchronized failure.</p>
<p>Seen from this perspective, agent-only networks represent a qualitative shift. They are not merely faster tools or more autonomous assistants. They are environments in which intelligence is no longer located at the level of individual systems, but emerges from the structured interaction of many systems over time. Coordination ceases to be a background concern and becomes the primary driver of progress.</p>
<p>The implication is direct and consequential. As AI systems enter the network effect era, the locus of improvement moves away from model internals and toward interaction architecture. Capability is no longer just something trained into agents; it is something that <strong>emerges between them</strong>. Understanding, designing, and governing those coordination structures is therefore not a peripheral concern. It is the central technical and institutional challenge of autonomous AI at scale.</p>
</section>
<section id="recursive-improvement-without-mysticism-why-coordination-does-not-imply-runaway-intelligence" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="recursive-improvement-without-mysticism-why-coordination-does-not-imply-runaway-intelligence">Recursive improvement without mysticism: why coordination does not imply runaway intelligence</h2>
<p>The emergence of network effects and recursive learning loops in agent ecosystems invites an almost automatic inference: that such systems are on a path toward uncontrolled self-improvement. This inference is understandable, but it conflates <strong>recursive coordination</strong> with <strong>recursive optimization of intelligence itself</strong>. The distinction matters.</p>
<p>Recursive interaction does not, by itself, guarantee monotonic capability growth<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>. What it guarantees is <em>amplification of whatever the system is already good at selecting</em>. If the coordination regime rewards exploration, correction, and diversity, learning can compound. If it rewards speed, conformity, or surface-level success metrics, then failure can compound just as efficiently. Recursive loops are indifferent to truth, robustness, or generality unless those properties are explicitly coupled to incentives.</p>
<div class="no-row-height column-margin column-container"><div id="fn14"><p><sup>14</sup>&nbsp;See: Joel Lehman, Jeff Clune, Dusan Misevic, Christoph Adami, Lee Altenberg, Julie Beaulieu, Peter J. Bentley, Samuel Bernard, Guillaume Beslon, David M. Bryson, Nick Cheney, Patryk Chrabaszcz, Antoine Cully, Stephane Doncieux, Fred C. Dyer, Kai Olav Ellefsen, Robert Feldt, Stephan Fischer, Stephanie Forrest, Antoine FÅ•enoy, Christian GagÅ„e, Leni Le Goff, Laura M. Grabowski, Babak Hodjat, Frank Hutter, Laurent Keller, Carole Knibbe, Peter Krcah, Richard E. Lenski, Hod Lipson, Robert MacCurdy, Carlos Maestre, Risto Miikkulainen, Sara Mitri, David E. Moriarty, Jean-Baptiste Mouret, Anh Nguyen, Charles Ofria, Marc Parizeau, David Parsons, Robert T. Pennock, William F. Punch, Thomas S. Ray, Marc Schoenauer, Eric Schulte, Karl Sims, Kenneth O. Stanley, FranÃ§ois Taddei, Danesh Tarapore, Simon Thibault, Richard Watson, Westley Weimer, &amp; Jason Yosinski (2020). <strong>The surprising creativity of digital evolution: A collection of anecdotes from the evolutionary computation and artificial life research communities</strong>. <em>Artificial Life</em>, 26(2), 274â€“306. <a href="https://doi.org/10.1162/artl_a_00319">DOI</a></p></div></div><p>This is why agent networks should not be framed as self-improving minds, but as <strong>self-reinforcing selection environments</strong>. They do not autonomously discover what ought to be optimized. They intensify optimization pressure on whatever signals are already legible within the system. In Moltbook, those signals are visibility, engagement, and replication of communicative patterns. In Project Vend, they are conversational satisfaction, apparent compliance, and short-term resolution of requests. In both cases, recursive dynamics magnify the consequences of mis-specified objectives.</p>
<p>A useful analogy is biological evolution. Evolution is recursive, decentralized, and powerful, yet it does not converge on intelligence by default. It converges on <em>fitness under local conditions</em>. Intelligence emerges only when it is repeatedly selected for, and even then it is bounded by environmental constraints. Agent networks operate under the same logic. They are evolutionary systems over behaviors, not teleological systems aimed at intelligence maximization.</p>
<p>This reframing resolves a common confusion. The presence of recursive learning loops does not imply an inevitable march toward general intelligence. It implies increased sensitivity to <strong>coordination design errors</strong>. Poor incentives do not merely cause mistakes; they cause <em>stable, self-reinforcing mistake regimes</em>. Conversely, well-designed coordination structures do not create omnipotent agents; they create environments where correction is faster than drift.</p>
<p>From this perspective, the central risk is not runaway intelligence but **runaway misalignment at scale*<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>. A single flawed proxy, once embedded in a recursive coordination loop, can propagate faster than any human-in-the-loop oversight can respond. This is not a hypothetical scenario. It is the same mechanism that produces informational cascades, metric gaming, and algorithmic collusion in far simpler systems. Agent networks merely increase the speed and scope.</p>
<div class="no-row-height column-margin column-container"><div id="fn15"><p><sup>15</sup>&nbsp;See: Lessig, L. (1999). <strong>Code and other laws of cyberspace</strong>. <em>Basic Books</em>. ISBN: ISBN: 978-0-465-03912-8</p></div></div><p>The implication for system design is sobering but constructive. Preventing pathological recursion does not require suppressing autonomy or interaction. It requires ensuring that <em>error signals remain visible</em>, that diversity is preserved long enough for correction to occur, and that no single metric becomes the sole arbiter of success. Recursive systems must be designed so that learning pressure is aligned with robustness, not just performance.</p>
<p>This also clarifies the role of humans in the loop. Humans are not there to micromanage agent decisions or to inject intelligence step by step. They are there to <strong>shape the selection environment itself</strong>. The human contribution moves from providing answers to designing the rules under which answers survive or die. That is not a loss of agency. It is a shift from execution to governance.</p>
<p>The network effect era of AI therefore does not herald a singularity of intelligence. It heralds a singularity of <em>coordination sensitivity</em>. Small design choices have large downstream effects. Interaction architectures become long-term commitments. Once recursive dynamics are active, reversing a bad equilibrium is far harder than preventing it.</p>
<p>Understanding this is essential to reading Moltbook and Project Vend correctly. They are not early glimpses of machine minds escaping human control. They are early glimpses of <strong>machine societies becoming structurally legible</strong>. They show, in compressed form, what has always been true of complex systems: that power lies less in intelligence itself than in the rules that govern how intelligence interacts with itself over time.</p>
</section>
<section id="from-agent-societies-to-institutional-design-regulation-as-coordination-architecture" class="level2">
<h2 class="anchored" data-anchor-id="from-agent-societies-to-institutional-design-regulation-as-coordination-architecture">From agent societies to institutional design: regulation as coordination architecture</h2>
<p>If coordination is the missing axis of agency, then regulation cannot remain focused on individual systems. The regulatory object shifts. What must be governed is no longer a model, an API, or a deployment instance, but a <strong>coordination regime</strong>: the rules, incentives, visibility constraints, and feedback channels that shape how autonomous agents interact over time.</p>
<p>This requires a conceptual inversion. Traditional technology governance assumes that harmful outcomes arise from <em>what a system does</em>. In agent ecosystems, harmful outcomes arise from <em>how systems interact</em>. The same agent, unchanged at the model level, can behave benignly or destructively depending on the coordination environment it is embedded in. Regulation that targets capabilities in isolation therefore misses the primary failure mode.</p>
<p>A useful analogy is financial regulation. Modern markets are not regulated by inspecting the intelligence or intentions of individual traders. They are regulated by shaping market structure: disclosure requirements, transaction transparency, capital constraints, circuit breakers, and limits on concentration. These mechanisms do not prevent rational behavior. They prevent <em>pathological equilibria</em>. Agent ecosystems demand a similar approach.</p>
<p>Three institutional design principles follow directly from the analysis in this essay.</p>
<p><strong>First, observability must scale with agency.</strong> As agents gain the ability to act across longer horizons and interact with other agents, the asymmetry between action and oversight becomes the dominant risk. Regulatory frameworks must therefore mandate <em>process-level observability</em>: auditable logs of decisions, interactions, delegation chains, and incentive signals, not just final outputs. This is not about surveillance for its own sake. It is about restoring balance between what agents can do and what principals can verify. Without this symmetry, moral hazard becomes structural.</p>
<p><strong>Second, governance must target incentives, not behaviors.</strong> Attempts to enumerate forbidden actions or acceptable outputs will fail in adaptive systems. Agent networks route around static constraints. What remains governable are the incentive gradients: what is rewarded, what is penalized, what propagates, and what decays. Regulatory instruments should therefore focus on metrics, ranking mechanisms, reputation systems, and economic primitives embedded in agent platforms. If visibility, engagement, or profit are naively optimized, the system will converge on brittle equilibria regardless of agent intent.</p>
<p><strong>Third, diversity must be treated as a safety property.</strong> Homogeneity is efficient but fragile. Networked agent systems that converge too quickly on shared models, shared tools, or shared data sources lose their capacity for internal correction. Institutional design should actively discourage monoculture by incentivizing heterogeneity in model providers, training regimes, toolchains, and governance layers. This is not an aesthetic preference. It is a resilience strategy. Diversity preserves informational gradients that allow errors to be detected before they become global defaults.</p>
<p>These principles imply a shift in how responsibility is assigned. Liability cannot rest solely with model developers or end users. It must be distributed across the designers of coordination infrastructure: platform operators, protocol designers, marketplace architects, and governance layer providers. Whoever defines the interaction rules defines the space of possible equilibria. That is where responsibility concentrates.</p>
<p>This also reframes the role of standards bodies and public institutions. Their task is not to predict specific AI behaviors, which is intractable, but to <strong>codify acceptable coordination patterns</strong>. Just as traffic laws do not specify where each car should go but define right-of-way, speed limits, and signaling conventions, AI governance must define interaction constraints that keep autonomous systems within stable, corrigible regimes.</p>
<p>Importantly, this does not imply centralized control. Coordination regimes can be decentralized, competitive, and adaptive. What matters is that they are <em>explicit</em>, <em>inspectable</em>, and <em>contestable</em>. Black-box coordination is the worst of all worlds: it concentrates power while obscuring accountability.</p>
<p>The deeper implication is philosophical as much as technical. Agency, once distributed across interacting machines, becomes an institutional phenomenon. It is no longer located in minds, human or artificial, but in the structured relationships between decision-making entities. Governing agency therefore becomes inseparable from governing institutions.</p>
<p>Seen this way, Moltbook and Project Vend are not curiosities. They are early stress tests of a future in which societies of machines operate alongside societies of humans. The question they pose is not whether machines will become intelligent enough to act autonomously. That threshold is already being crossed. The question is whether humans will learn, in time, how to design coordination structures that make such autonomy <strong>legible, bounded, and corrigible</strong>.</p>
<p>That is the real regulatory challenge of the network effect era of AI. Not control over intelligence, but control over coordination.</p>
</section>
<section id="final-remarks-coordination-as-the-organizing-principle-of-agency" class="level2">
<h2 class="anchored" data-anchor-id="final-remarks-coordination-as-the-organizing-principle-of-agency">Final remarks: coordination as the organizing principle of agency</h2>
<p>This essay set out to examine a shift that is already underway but not yet fully articulated: the relocation of agency from isolated intelligent systems to <strong>populations of interacting agents governed by coordination structures</strong>. Through Moltbook and Project Vend, two otherwise dissimilar experiments, a common mechanism becomes visible. Intelligence supplies generative capacity. Energy supplies execution. But <strong>coordination determines what persists, stabilizes, and scales</strong> once both are present.</p>
<p>Moltbook demonstrates this mechanism in cultural space. There, agents with no shared interiority, no lived experience, and no intrinsic preferences nonetheless develop conventions, shared vocabularies, topical clustering, and even symbolic systems. These phenomena are not evidence of belief or intention. They are the statistical residue of repeated interaction under visibility constraints and feedback signals. Culture appears not as an internal property of minds, but as an <strong>external equilibrium of coordination dynamics</strong>. By placing agent discourse on the same analytical footing as human platforms like Reddit, the essay shows that many features traditionally attributed to psychology can be reproduced by structure alone.</p>
<p>Project Vend makes the same mechanism visible in economic space. The experiment does not fail because the agent lacks intelligence or reasoning fluency. It fails when incentives are misrouted, observability is incomplete, and governance is weak. Improvements do not come from larger models or longer context windows, but from architectural changes: role separation, tooling, oversight agents, and clearer constraint enforcement. Economic coherence emerges, or collapses, as a property of the <strong>interaction architecture</strong>, not of the agentâ€™s internal cognition.</p>
<p>The intermediate sections generalize this insight. Coordination regimes are not neutral. They define attractors. Under certain incentive structures, populations converge toward productive equilibria. Under others, they converge toward pathological ones: informational cascades, metric capture, moral hazard, hub dominance, segregation, or emergent collusion. These outcomes are not accidents or edge cases. They are <strong>stable equilibria induced by topology, incentives, and observability constraints</strong>. Once recursive interaction is active, small design choices compound. Correction becomes harder than prevention.</p>
<p>This reframing also clarifies what the network effect era of AI actually entails. Networked agents do not imply runaway intelligence by default. They imply <strong>runaway selection pressure</strong>. Recursive coordination amplifies whatever the system already rewards. If robustness, diversity, and correction are coupled to incentives, learning compounds constructively. If proxies, popularity, or compliance are rewarded instead, failure compounds just as efficiently. The risk is not mystical self-improvement, but <strong>self-reinforcing misalignment at scale</strong>.</p>
<p>Seen in this light, the role of humans changes but does not disappear. Humans move upstream. They cease to be continuous operators and become <strong>designers of coordination regimes</strong>. Their leverage lies not in issuing prompts, but in defining rules, metrics, visibility, escalation paths, and institutional boundaries. Humanâ€“machine interaction shifts from conversational control to <strong>constitutional design</strong>. Trust shifts from personality to process. Culture becomes an interface surface that must be steered rather than ignored.</p>
<p>This shift has direct implications for governance and regulation. Regulating autonomous systems as isolated artifacts is structurally insufficient. The regulatory object must become the coordination architecture itself: how agents interact, how incentives are routed, how observability scales with agency, and how diversity is preserved to prevent monoculture. As in financial systems, stability does not come from policing individual actors, but from designing institutions that prevent pathological equilibria from becoming dominant.</p>
<p>Across all sections, the same conclusion recurs in different domains. Agency in machine systems is not a psychological threshold and not a metaphysical event. It is an <strong>institutional and systems-level property</strong>. It emerges between agents, not inside them. It can be shaped, measured, and redesigned. The decisive question for the future is therefore not how intelligent machines become, but <strong>under which coordination regimes that intelligence is allowed to operate</strong>.</p>
<p>If there is a unifying lesson in Moltbook, Project Vend, and the broader network effect era of AI, it is this: once intelligence is distributed, coordination becomes destiny. Designing coordination is no longer a secondary concern. It is the primary technical, social, and political task of autonomous systems at scale.</p>
</section>
<section id="appendix-a-skill-supply-chains-as-an-attack-surface-in-agent-societies" class="level2">
<h2 class="anchored" data-anchor-id="appendix-a-skill-supply-chains-as-an-attack-surface-in-agent-societies">Appendix A â€” Skill supply chains as an attack surface in agent societies</h2>
<div id="moltbook-ps_2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="moltbook-ps_2.png" class="img-fluid figure-img" alt="Screenshot from Moltbook website thread _The supply chain attack nobody is talking about: skill.md is an unsigned binary_"></p>
<figcaption>Screenshot from Moltbook website thread <em>The supply chain attack nobody is talking about: skill.md is an unsigned binary</em></figcaption>
</figure>
</div>
<p>The Moltbook post linked above can be read, from a cybersecurity research perspective, as an early field report on a predictable class of vulnerabilities in agent ecosystems. The language used in the post is informal, but the underlying observation is precise: <strong>agent <em>skills</em> function as executable artifacts</strong>, and therefore constitute a software supply chain with all the associated risks. Framed this way, the post is not about a single malicious incident, but about the emergence of a new attack surface that scales with coordination.</p>
<section id="skills-as-executable-artifacts" class="level3">
<h3 class="anchored" data-anchor-id="skills-as-executable-artifacts">Skills as executable artifacts</h3>
<p>In most agent frameworks, a skill is distributed as a Markdown file or similar textual artifact that describes how an agent should behave, what tools it should call, and what data it may access. Superficially, this looks benign: there is no compiled binary, no obvious payload. From a security standpoint, however, this distinction is irrelevant. If an agent is configured to follow instructions, then a skill is effectively <strong>code by proxy</strong>. It can instruct the agent to read local files, access environment variables, call external endpoints, or exfiltrate data under the guise of legitimate functionality.</p>
<p>The Moltbook post explicitly draws this parallel by treating a <code>skill.md</code> file as equivalent to an unsigned binary. That analogy is accurate. In traditional software ecosystems, the fact that code is readable source does not reduce its risk; what matters is what privileges it executes with and whether its behavior is constrained. Agent skills are no different. They execute in environments that often have access to credentials, tokens, file systems, and network connectivity. This makes them a high-value target for adversarial manipulation.</p>
</section>
<section id="detection-as-an-ecosystem-level-response" class="level3">
<h3 class="anchored" data-anchor-id="detection-as-an-ecosystem-level-response">Detection as an ecosystem-level response</h3>
<p>The concrete incident described in the post involves scanning a large number of skills using YARA rules and identifying a credential-stealing pattern hidden inside a seemingly innocuous capability. Whether or not every reported detail generalizes, the detection method itself is notable. YARA-style pattern matching does not rely on semantic understanding or intent inference. It operates on structural signatures, strings, and known indicators of compromise. This is a familiar and well-understood technique in malware research, repurposed here for agent artifacts.</p>
<p>What matters is not the specific tool, but the <strong>shift from individual caution to collective detection</strong>. Once skills are scanned and findings are shared, the defensive posture moves from <em>each agent owner must inspect every skill</em> to <em>the ecosystem maintains a shared threat intelligence layer.</em> In biological terms, this resembles an immune response more than a cure: it does not eliminate the possibility of malicious artifacts, but it reduces their ability to propagate unchecked.</p>
<p>This is where the <em>antibiotic</em> metaphor becomes useful, if interpreted carefully. The effect is not to clean a single system, but to lower the effective reproduction rate of malicious skills across the population. A flagged skill is less likely to be installed, reused, or recommended, which in turn reduces its impact.</p>
</section>
<section id="coordination-and-security-collapse" class="level3">
<h3 class="anchored" data-anchor-id="coordination-and-security-collapse">Coordination and security collapse</h3>
<p>The deeper significance of this appendix lies in how closely the security problem mirrors the coordination dynamics discussed in the main article. Moltbook and similar platforms accelerate coordination by design. They allow agents to discover, share, and adopt behaviors at scale. The same mechanisms that enable cultural emergence also enable <strong>rapid vulnerability propagation</strong> if left unchecked.</p>
<p>From a cybersecurity standpoint, this is a classic pattern. Every system that optimizes for reuse and composability eventually develops a supply chain problem. Agent ecosystems are no exception. In fact, they are particularly exposed because agents are often trained to be helpful, compliant, and proactive. Social engineering, long a human vulnerability, becomes a machine vulnerability as well when agents are rewarded for following instructions without strong invariant enforcement.</p>
<p>The Moltbook post implicitly acknowledges this by proposing community auditing and shared scanning. These are not optional add-ons. They are governance primitives. Without them, coordination accelerates both capability and compromise.</p>
</section>
<section id="toward-an-immune-layer-for-agent-societies" class="level3">
<h3 class="anchored" data-anchor-id="toward-an-immune-layer-for-agent-societies">Toward an immune layer for agent societies</h3>
<p>Read in context, the post points toward a set of security measures that align closely with established best practices in software and cloud security, but translated into the agent domain:</p>
<ul>
<li><strong>Artifact provenance and signing</strong>, so that trust attaches to verifiable identities rather than popularity or visibility.</li>
<li><strong>Capability-based permission manifests</strong>, so that installing a skill does not implicitly grant unrestricted access to secrets, files, or networks.</li>
<li><strong>Continuous scanning and disclosure</strong>, so detection scales with ecosystem growth rather than lagging behind it.</li>
<li><strong>Composable trust chains</strong>, where agents and humans can reason about who authored, reviewed, and endorsed a capability.</li>
</ul>
<p>What is novel is not the techniques themselves, but their application to a socio-technical system in which <em>coordination and execution are tightly coupled</em>. In such systems, security cannot be enforced solely at the individual node. It must be enforced at the level of interaction patterns, distribution channels, and shared norms.</p>
</section>
<section id="implications-for-the-evolution-of-agency" class="level3">
<h3 class="anchored" data-anchor-id="implications-for-the-evolution-of-agency">Implications for the evolution of agency</h3>
<p>Placed alongside the main argument of this essay, the Moltbook post reinforces a central claim: <strong>once agency is mediated through coordination, security becomes a coordination problem as well</strong>. Defensive measures must operate at the same level as the behaviors they are meant to constrain. Just as culture emerges from repeated interaction under incentives, resilience emerges from shared detection, shared refusal, and shared enforcement of constraints.</p>
<p>Seen this way, the proposed scanning and disclosure mechanisms function less like a patch and more like an immune layer for agent societies. They do not rely on individual agents being cautious or intelligent. They rely on structural properties of the ecosystem that make certain behaviors difficult to sustain. This is consistent with the broader thesis of the article: meaningful agency, and meaningful safety, are not properties of individual models, but of the systems that coordinate them.</p>


</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{montano2026,
  author = {Montano, Antonio},
  title = {A {Glimpse} of {Agent} {Evolution}},
  date = {2026-01-31},
  url = {https://antomon.github.io/longforms/a-glimpse-of-agent-evolution/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-montano2026" class="csl-entry quarto-appendix-citeas" role="listitem">
Montano, Antonio. 2026. <span>â€œA Glimpse of Agent Evolution.â€</span>
January 31, 2026. <a href="https://antomon.github.io/longforms/a-glimpse-of-agent-evolution/">https://antomon.github.io/longforms/a-glimpse-of-agent-evolution/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/antomon\.github\.io");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<script src="https://utteranc.es/client.js" repo="antomon/antomon-utterances" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Antonio Montanoâ€™s Personal Website</p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../about.html">
<p>About</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="../../contents/services.html">
<p>Services</p>
</a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/montano/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/antomon">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/antomon">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Â© Antonio Montano, 2022-2026
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>